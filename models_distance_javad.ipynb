{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnwFvxOpBuya",
        "outputId": "1d0670c0-fa81-4a30-9680-a74764220ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from gdown) (4.67.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests[socks]->gdown) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mmroshani/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q-BrQQneGVnm"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from scipy.stats import wasserstein_distance\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Yd_BwJT5pGnQ"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XgHnSmfhG4zF"
      },
      "outputs": [],
      "source": [
        "def get_top_values(arr, p):\n",
        "    # Ensure p is a valid percentage\n",
        "    if not (0 <= p <= 100):\n",
        "        raise ValueError(\"Percentage p must be between 0 and 100.\")\n",
        "\n",
        "    # Calculate the number of elements to retain\n",
        "    num_elements_to_retain = int(len(arr) * (100 - p) / 100)\n",
        "\n",
        "    # If num_elements_to_retain is 0, return an empty array\n",
        "    if num_elements_to_retain == 0:\n",
        "        return np.array([])\n",
        "\n",
        "    # Find the indices of the largest num_elements_to_retain elements\n",
        "    indices_to_retain = np.argpartition(arr, -num_elements_to_retain)[-num_elements_to_retain:]\n",
        "\n",
        "    # Return only the top (100-p)% of elements\n",
        "    return arr[indices_to_retain]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z9fUzKUD19yC"
      },
      "outputs": [],
      "source": [
        "DATASET_TYPE = \"cifar10\"\n",
        "MODEL_TYPE = \"cnn\"\n",
        "\n",
        "DATASET_TYPE=None\n",
        "NUMBER_OF_CLASSES=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NUyaOdY0cMmm"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "    ):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        print(\"made model\")\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5) #!\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = None\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        out = x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tV_GxX0VPg4q"
      },
      "outputs": [],
      "source": [
        "def array_prune(array, P):\n",
        "\n",
        "\n",
        "    array = np.array(array)\n",
        "    n_elements = array.size\n",
        "\n",
        "    num_to_zero = int(P*len(arr))\n",
        "    if num_to_zero == 0:\n",
        "        num_to_zero = 1\n",
        "\n",
        "    # Get the indices of the smallest num_to_zero elements\n",
        "    #smallest_indices = np.argpartition(array, num_to_zero - 1)[:num_to_zero]\n",
        "\n",
        "    # Create a copy and set the smallest elements to zero\n",
        "    #modified_array = array.copy()\n",
        "    #modified_array[smallest_indices] = 0\n",
        "\n",
        "    #return modified_array\n",
        "\n",
        "    threshold_value = np.percentile(array, P * 100)\n",
        "\n",
        "    # Set values below or equal to the threshold to 0\n",
        "    modified_arr = np.where(array <= threshold_value, 0, array)\n",
        "\n",
        "    return modified_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c6FCTXXZGvts"
      },
      "outputs": [],
      "source": [
        "def remove_batchnorm_params(model):\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Create a new dictionary excluding BatchNorm parameters\n",
        "    filtered_state_dict = {key: value for key, value in state_dict.items() if \"running_mean\" not in key and \"running_var\" not in key}\n",
        "\n",
        "    #print(\"Removed BatchNorm parameters:\")\n",
        "    #for key in state_dict.keys():\n",
        "        #if \"running_mean\" in key or \"running_var\" in key:\n",
        "            #print(f\"  - {key}\")\n",
        "\n",
        "    return filtered_state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EwRd5hTvHkUU"
      },
      "outputs": [],
      "source": [
        "def remove_batchnorm_params(state_dict):\n",
        "    # Filter out BatchNorm parameters\n",
        "    filtered_state_dict = {\n",
        "        key: value\n",
        "        for key, value in state_dict.items()\n",
        "        if \"running_mean\" not in key and \"running_var\" not in key and \"bn\" not in key\n",
        "    }\n",
        "\n",
        "    # Print removed BatchNorm parameters for verification\n",
        "    # print(\"Removed BatchNorm parameters:\")\n",
        "    # for key in state_dict.keys():\n",
        "    #     if \"running_mean\" in key or \"running_var\" in key or \"bn\" in key:\n",
        "    #         print(f\"  - {key}\")\n",
        "\n",
        "    return filtered_state_dict\n",
        "def model_parameters_to_numpy(path):\n",
        "    # Load the model's state dictionary\n",
        "    model = torch.load(path, map_location=torch.device('cpu'))\n",
        "    # model.eval()  # Set the model to evaluation mode\n",
        "    #print(\"Model loaded successfully.\")\n",
        "    #model = model.state_dict()\n",
        "\n",
        "    # Initialize an empty list to store parameters\n",
        "    params = []\n",
        "\n",
        "    # Iterate through the model to extract parameters\n",
        "    model = remove_batchnorm_params(model)\n",
        "    for name, param in model.items():\n",
        "        if 'bias' not in name:  # Exclude bias terms\n",
        "            params.append(param.detach().cpu().numpy())  # Convert to numpy array\n",
        "\n",
        "    # Return the parameters as a numpy array\n",
        "    return np.array(params, dtype=object)\n",
        "\n",
        "def load_model_params(model_path):\n",
        "    state_dic = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    \n",
        "    model = Net()\n",
        "    model.train()\n",
        "    model.load_state_dict(state_dic)\n",
        "\n",
        "    # raw_parameters = []\n",
        "    # for name, parameter in model.named_parameters():\n",
        "    #     print(f\"{name}\")\n",
        "    #     grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
        "    # for _, grad in grads:\n",
        "    #     raw_parameters.append(grad)\n",
        "    raw_parameters = torch.cat([param.view(-1) for param in model.parameters()]).detach().cpu().numpy()\n",
        "    return raw_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7cdf9aYYPkpI"
      },
      "outputs": [],
      "source": [
        "def top_to_one_other_zero(arr, P):\n",
        "    flat_arr = arr.flatten()\n",
        "    threshold_value = np.percentile(flat_arr, P * 100)\n",
        "\n",
        "    # Create a new array where values below the threshold are 0 and others are 1\n",
        "    result = np.where(arr <= threshold_value, 0, 1)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhAKXEe5U3DE",
        "outputId": "f27e5ddb-1241-4f5b-bed9-4e671ca106b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18,\n",
              " array([0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]),\n",
              " array([0. , 2.1, 1.8, 0. , 2.1, 0. , 0.7, 1.8, 0. , 2.1, 0. , 0.7, 1.8,\n",
              "        0. , 2.1, 0. , 0.7, 1.8]),\n",
              " 11,\n",
              " 11)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage\n",
        "import numpy as np\n",
        "arr = np.array([0.5, 2.1, 1.8,0.5, 2.1, -3.3, 0.7, 1.8,0.5, 2.1, -3.3, 0.7, 1.8,0.5, 2.1, -3.3, 0.7, 1.8])\n",
        "P = .4\n",
        "result = top_to_one_other_zero(arr, P)\n",
        "result2 = array_prune(arr, P)\n",
        "len(arr), result, result2,np.count_nonzero(result) ,np.count_nonzero(result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7zXeVDAJqXJf"
      },
      "outputs": [],
      "source": [
        "def group_clients_by_cluster(labels):\n",
        "    clusters = {}\n",
        "    for client_id, cluster_id in enumerate(labels):\n",
        "        if cluster_id not in clusters:\n",
        "            clusters[cluster_id] = []\n",
        "        clusters[cluster_id].append(client_id)\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QW_AqkkAuPOv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "def cluster_to_list(arr):\n",
        "    cluster_dict = defaultdict(list)\n",
        "    for index, cluster in enumerate(arr):\n",
        "        cluster_dict[cluster].append(index)\n",
        "    clusters = [indices for _, indices in sorted(cluster_dict.items())]\n",
        "\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzjk3bQW8Rwo"
      },
      "source": [
        "## Load From Lab Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRkxao3oDQ64"
      },
      "source": [
        "## Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6RVAn01YcXwY",
        "outputId": "6875f308-953f-4bbf-ccae-9b4dfcade546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_0_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_1_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_2_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_3_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_4_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_5_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_6_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_7_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_8_round_2_of_clustering.pth\n",
            "made model\n",
            "Successfully loaded: /home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_9_round_2_of_clustering.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36975/3739064455.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dic = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "N=10\n",
        "params=[]\n",
        "NUMBER_OF_EPOCHS = 480 # values are: 6, 12, 18, 24, 30, 36, 42, 48, 480\n",
        "DATASET = \"svhn\"  # values are: cifar10 or svhn\n",
        "\n",
        "sub_path = None\n",
        "pretrained = True\n",
        "new = True\n",
        "\n",
        "\n",
        "for i in range(N):\n",
        "    path = f\"/home/mmroshani/Documents/lab/SAFE-PFL-HE/open-source/safe-pfl/models/node_{i}_round_2_of_clustering.pth\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File {path} does not exist. Skipping...\")\n",
        "        continue\n",
        "    try:\n",
        "        # node = model_parameters_to_numpy(path)\n",
        "        raw_parameters = load_model_params(path)\n",
        "        # param = np.concatenate([p.ravel() for p in node])\n",
        "        params.append(raw_parameters)\n",
        "        print(f\"Successfully loaded: {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "30_BdzGTfM4h",
        "outputId": "b57bf0b4-f175-4a05-9e66-2dac2eeeb44f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.0489625 ,  0.03767579,  0.06528731, ..., -0.18624394,\n",
              "       -0.22135861, -0.1435833 ], shape=(44426,), dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fxe_HfwIsiQs",
        "outputId": "1f0b4e47-cf51-47cb-bd88-bfcbe9aaa331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters (N): 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n",
            "/tmp/ipykernel_36975/1528442470.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))\n"
          ]
        }
      ],
      "source": [
        "N = len(params)\n",
        "print(\"Number of parameters (N):\", N)\n",
        "Cosine_similarity = np.zeros((N, N))\n",
        "for i in range(N):\n",
        "    for j in range(i+1, N):\n",
        "        Cosine_similarity[i][j] = Cosine_similarity[j][i] = cosine_similarity(params[i].reshape(1, -1), params[j].reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VSw4T-Falaq1",
        "outputId": "20b4f561-e770-4e75-a8bb-5e8aa57f62a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.99999976 0.99999976 0.99999976 0.99999976 0.54236591\n",
            "  0.54236591 0.69142139 0.69142139 0.69142139]\n",
            " [0.99999976 0.         0.99999976 0.99999976 0.99999976 0.54236591\n",
            "  0.54236591 0.69142139 0.69142139 0.69142139]\n",
            " [0.99999976 0.99999976 0.         0.99999976 0.99999976 0.54236591\n",
            "  0.54236591 0.69142139 0.69142139 0.69142139]\n",
            " [0.99999976 0.99999976 0.99999976 0.         0.99999976 0.54236591\n",
            "  0.54236591 0.69142139 0.69142139 0.69142139]\n",
            " [0.99999976 0.99999976 0.99999976 0.99999976 0.         0.54236591\n",
            "  0.54236591 0.69142139 0.69142139 0.69142139]\n",
            " [0.54236591 0.54236591 0.54236591 0.54236591 0.54236591 0.\n",
            "  1.         0.6161077  0.6161077  0.6161077 ]\n",
            " [0.54236591 0.54236591 0.54236591 0.54236591 0.54236591 1.\n",
            "  0.         0.6161077  0.6161077  0.6161077 ]\n",
            " [0.69142139 0.69142139 0.69142139 0.69142139 0.69142139 0.6161077\n",
            "  0.6161077  0.         0.99999994 0.99999994]\n",
            " [0.69142139 0.69142139 0.69142139 0.69142139 0.69142139 0.6161077\n",
            "  0.6161077  0.99999994 0.         0.99999994]\n",
            " [0.69142139 0.69142139 0.69142139 0.69142139 0.69142139 0.6161077\n",
            "  0.6161077  0.99999994 0.99999994 0.        ]]\n",
            "Clients clustering based on their dataset: {np.int64(0): [0, 1, 2, 3, 4, 7, 8, 9], np.int64(1): [5, 6]}\n",
            "Cluster labels for each parameter: [0 0 0 0 0 1 1 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Cosine_distance = 1 - Cosine_similarity\n",
        "ap = AffinityPropagation(affinity='precomputed', random_state=0).fit(Cosine_similarity)\n",
        "cosine_labels = ap.labels_\n",
        "print(Cosine_similarity)\n",
        "clusters = group_clients_by_cluster(cosine_labels)\n",
        "\n",
        "print(\"Clients clustering based on their dataset:\", clusters)\n",
        "print(\"Cluster labels for each parameter:\", cosine_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0nhsVmVM9q"
      },
      "source": [
        "**Coordinate-Based**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVRALarFNPEJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CojiEVwuNN5c"
      },
      "source": [
        "#! read from all_model_parameters_ordered_by_importance_for_client_*.csv and cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-vACQUtVBgg"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,N):\n\u001b[0;32m----> 9\u001b[0m     ID_similarity[i][j]\u001b[38;5;241m=\u001b[39m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m ID_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mID_similarity\n\u001b[1;32m     12\u001b[0m ap \u001b[38;5;241m=\u001b[39m AffinityPropagation(affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(ID_distance)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:185\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    176\u001b[0m         X,\n\u001b[1;32m    177\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    195\u001b[0m         Y,\n\u001b[1;32m    196\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "P=0.8\n",
        "coordinates=[]\n",
        "for i in range(N):\n",
        "  tops=top_to_one_other_zero(params[i], P)\n",
        "  coordinates.append(tops)\n",
        "ID_similarity=np.zeros((N,N))\n",
        "for i in range(N):\n",
        "  for j in range(i+1,N):\n",
        "    ID_similarity[i][j]=cosine_similarity(coordinates[i],coordinates[j])\n",
        "\n",
        "ID_distance = -ID_similarity\n",
        "ap = AffinityPropagation(affinity=\"precomputed\", random_state=0).fit(ID_distance)\n",
        "ID_labels = ap.labels_\n",
        "ID_similarity_show = np.round(ID_similarity, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Se8kQnINYQeo",
        "outputId": "37cfc365-43d9-4373-c642-cb66b4acc4f4"
      },
      "outputs": [],
      "source": [
        "Cosine_similarity_show=np.round(Cosine_similarity, 2)\n",
        "print(cosine_labels)\n",
        "Cosine_similarity_show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "854OX-qVYTzu",
        "outputId": "cb8ddc5a-ac9b-41e6-a106-2e3aff83655f"
      },
      "outputs": [],
      "source": [
        "ID_similarity_show=np.round(ID_similarity, 2)\n",
        "\n",
        "print(ID_labels)\n",
        "ID_similarity_show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JB7qTGHbaqAA",
        "outputId": "63ad87ca-c052-4f3e-96bc-1f82d26d4e71"
      },
      "outputs": [],
      "source": [
        "matrix1=Cosine_similarity.flatten()\n",
        "matrix2=ID_similarity.flatten()\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "corr_pearson, _ = pearsonr(matrix1, matrix2)\n",
        "corr_spearman, _ = spearmanr(matrix1, matrix2)\n",
        "mae = np.mean(np.abs(matrix1 - matrix2))\n",
        "diff=matrix1- matrix2\n",
        "min_,max_,avg_=np.min(diff),np.max(diff),np.average(diff)\n",
        "corr_pearson, corr_spearman, mae, min_,max_,avg_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GYVVdJtNh84X",
        "outputId": "3e90ccc1-1d4a-40f9-a7be-33eab5efdd21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def find_regression_coefficients(x, y):\n",
        "    x = np.array(x).reshape(-1, 1)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Create and fit the regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(x, y)\n",
        "\n",
        "    return model.coef_[0], model.intercept_\n",
        "slope, intercept = find_regression_coefficients(matrix1, matrix2)\n",
        "cofficient=f\"cosine(x,y)={round(slope,3)} ID_sim(x,y) {round(intercept,3)}\"\n",
        "cofficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZCnubZLxZ1as",
        "outputId": "59e679e9-1d7c-4a01-bb8c-8fc700a43111"
      },
      "outputs": [],
      "source": [
        "# Filter non-zero values for both matrices\n",
        "non_zero_indices_x = np.nonzero(matrix1)\n",
        "non_zero_indices_y = np.nonzero(matrix2)\n",
        "\n",
        "# Get non-zero values\n",
        "x_non_zero = matrix1[non_zero_indices_x]\n",
        "y_non_zero = matrix2[non_zero_indices_y]\n",
        "\n",
        "# Create scatter plot for non-zero values\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot X values (Cosine Similarity) in blue\n",
        "plt.scatter(range(len(x_non_zero)), x_non_zero, color='blue', alpha=0.7, label='Cosine Similarity (X)')\n",
        "\n",
        "# Plot Y values (Approximation Similarity) in red\n",
        "plt.scatter(range(len(y_non_zero)), y_non_zero, color='red', alpha=0.7, label='Approximation Similarity (Y)')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Data Index', fontsize=12)\n",
        "plt.ylabel('Similarity Values', fontsize=12)\n",
        "plt.title(f\"Pearson Correlation: {round(corr_pearson,3)} Spearman Correlation: {round(corr_spearman,3)} \"+cofficient, fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A__UOfDccF4y"
      },
      "source": [
        "## **Clustering and Silouhette**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WB7lxnU5cEvk",
        "outputId": "686585a3-89cd-4608-dc91-e889f8000289"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "data = np.array([\n",
        "    [4948, 0,5293, 0, 0,0,0,0,0,0,],\n",
        "[0,3466, 0, 0, 0,0,0,0,0, 2330,],\n",
        "[0,3465,5292, 0, 0,0,0,0,0,0,],\n",
        "[0, 0, 0,4249,3729,0,0,0,0,0,],\n",
        "[0,3465, 0, 0,3729,0,0,0,0,0,],\n",
        "[0, 0, 0, 0, 0, 6882,0, 1865,0,0,],\n",
        "[0, 0, 0, 0, 0,0, 2864, 1865,0,0,],\n",
        "[0, 0, 0, 0, 0,0, 2863, 1865,0,0,],\n",
        "[0, 0, 0,4248, 0,0,0,0, 5045,0,],\n",
        "[0,3465, 0, 0, 0,0,0,0,0, 2329,]\n",
        "])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_dist_opt = pairwise_distances(data, metric='cosine')\n",
        "cosine_similarities_opt = -cosine_dist_opt  # Convert distances to negative similarities for AP\n",
        "\n",
        "# Determine the preference based on the cosine similarity matrix\n",
        "preference = np.median(cosine_similarities_opt)\n",
        "\n",
        "# Affinity Propagation with cosine similarity\n",
        "clustering = AffinityPropagation(affinity='precomputed', preference=preference, random_state=0).fit(cosine_similarities_opt)\n",
        "\n",
        "cluster_labels = clustering.labels_\n",
        "# Calculate the silhouette score\n",
        "\n",
        "\n",
        "silhouette_avg_opt = silhouette_score(data, cluster_labels, metric='cosine')\n",
        "silhouette_avg_cosine = silhouette_score(data, cosine_labels, metric='cosine')\n",
        "silhouette_avg_method = silhouette_score(data, ID_labels, metric='cosine')\n",
        "\n",
        "\n",
        "# Organizing the final clusters as [[], [], ...]\n",
        "num_clusters = len(np.unique(cluster_labels))\n",
        "clusters = [[] for _ in range(num_clusters)]\n",
        "for index, label in enumerate(cluster_labels):\n",
        "    clusters[label].append(index)\n",
        "\n",
        "# Output the clusters and silhouette score\n",
        "print(f\"Silhouette Score with[{clusters}]: {silhouette_avg_opt}\")\n",
        "print(f\"Silhouette Score_cosine with [{cluster_to_list(cosine_labels)}]: {silhouette_avg_cosine}\")\n",
        "print(f\"Silhouette Score_ID method with [{cluster_to_list(ID_labels)}]: {silhouette_avg_method}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "39XCdb7mKcIH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR-54vdiHiRY"
      },
      "source": [
        "## Others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DzmvazTDb6rj"
      },
      "outputs": [],
      "source": [
        "similarity_vector=[]\n",
        "for p in range (0,100):\n",
        "    similarity_vector.append(cosine_similarity(params[1], array_prune(params[1], p/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I9Zd8r-ls87z"
      },
      "outputs": [],
      "source": [
        "similarity_vector_ID=[]\n",
        "for p in range (1,100):\n",
        "    similarity_vector_ID.append(cosine_similarity(params[1], top_to_one_other_zero(params[1], p/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jsaAc_1Cb7Vz",
        "outputId": "0292d751-3850-4e02-a6ff-057ae941c0a6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "values = np.random.rand(100)\n",
        "plt.figure(figsize=(10, 5))  # Optional: Adjust the figure size\n",
        "plt.plot(similarity_vector, marker='o', linestyle='-', label='similarity of prun')\n",
        "plt.plot(similarity_vector_ID, marker='o', linestyle='-', label='similarity of ID')\n",
        "plt.title('Plot of 100 Values')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwoKOQ6DV3s"
      },
      "source": [
        "## Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UwxGjpLlDWJP",
        "outputId": "6c7897e4-bf08-4a2b-c4ba-9fbf36da82b2"
      },
      "outputs": [],
      "source": [
        "Eu_similarity=np.zeros((N,N))\n",
        "for i in range(N):\n",
        "    for j in range(i + 1, N):\n",
        "        # Calculate Euclidean distance\n",
        "        Eu_similarity[i][j] =Eu_similarity[j][i] = np.linalg.norm(params[i] - params[j])\n",
        "\n",
        "Eu_distance = -Eu_similarity\n",
        "ap = AffinityPropagation(affinity=\"precomputed\").fit(Eu_distance)\n",
        "labels = ap.labels_\n",
        "\n",
        "print(\"Cluster labels for each prune:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59STLC8EFMA"
      },
      "source": [
        "## Wasserstein (!!!Takes too long!!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8J4nPySEFYv"
      },
      "outputs": [],
      "source": [
        "W_similarity=np.zeros((N,N))\n",
        "for i in range(N):\n",
        "  for j in range(i + 1, N):\n",
        "    W_similarity[i][j] =W_similarity[j][i] = wasserstein_distance(params[i], params[j])\n",
        "\n",
        "W_distance=W_similarity\n",
        "ap = AffinityPropagation(affinity=\"precomputed\").fit(W_distance)\n",
        "labels = ap.labels_\n",
        "\n",
        "print(\"Cluster labels for each prune:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEmE0O-rJrCr"
      },
      "outputs": [],
      "source": [
        "a=params[0]\n",
        "b=params[1]\n",
        "c=params[2]\n",
        "\n",
        "x=np.linalg.norm(b)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip954WqvJ1px"
      },
      "outputs": [],
      "source": [
        "y=np.linalg.norm(c)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6KqLENsJ_5T"
      },
      "outputs": [],
      "source": [
        "z=np.dot(b,c)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77TuKXU3KW6T"
      },
      "outputs": [],
      "source": [
        "print(z,x,y,x*y,z/(x*y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1-H_pIgKm65"
      },
      "outputs": [],
      "source": [
        "z/x*y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7ZI0SWhmD7r"
      },
      "outputs": [],
      "source": [
        "# b=params[0]\n",
        "# #a_=prun_0\n",
        "# #b_=prun_1\n",
        "# eps_a=np.linalg.norm(a)-np.linalg.norm(a_)\n",
        "# eps_b=np.linalg.norm(b)-np.linalg.norm(b_)\n",
        "# print(\"epsilons:\", eps_a, eps_b)\n",
        "# if eps_a<=np.linalg.norm(a-a_):\n",
        "#   print(\"satisfy\")\n",
        "\n",
        "# if eps_b<=np.linalg.norm(b - b_):\n",
        "#   print(\"satisfy\")\n",
        "# delta=cosine_similarity(a,b)-cosine_similarity(a_,b_)\n",
        "# print(delta)\n",
        "\n",
        "# check_delta=eps_a/np.linalg.norm(a)+eps_b/np.linalg.norm(b)+(eps_a*eps_b)/np.linalg.norm(a)*np.linalg.norm(b)\n",
        "# print(check_delta)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
