{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1OA8n1V3Jt_"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Install Pacakges</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:28.381903Z",
     "start_time": "2025-02-01T15:34:17.422692Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:29.849551Z",
     "iopub.status.busy": "2025-01-12T01:55:29.849175Z",
     "iopub.status.idle": "2025-01-12T01:55:33.137544Z",
     "shell.execute_reply": "2025-01-12T01:55:33.136580Z",
     "shell.execute_reply.started": "2025-01-12T01:55:29.849523Z"
    },
    "id": "bRRfcrFG3JuA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets lxml TinyImageNet matplotlib seaborn torch torchvision scipy scikit-learn safe_pfl_utils tabulate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oO1OslR3JuA"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Import Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:56.429560Z",
     "start_time": "2025-02-01T15:34:30.137748Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:33.139159Z",
     "iopub.status.busy": "2025-01-12T01:55:33.138851Z",
     "iopub.status.idle": "2025-01-12T01:55:33.146970Z",
     "shell.execute_reply": "2025-01-12T01:55:33.146040Z",
     "shell.execute_reply.started": "2025-01-12T01:55:33.139130Z"
    },
    "id": "IWgcTDs4vXBk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy as py_copy\n",
    "import gc\n",
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "from typing import Callable, Optional\n",
    "from torch.nn.utils import parameters_to_vector as Params2Vec\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from safe_pfl_utils.config import Config\n",
    "from safe_pfl_utils.constants import (\n",
    "    data_distribution_constants,\n",
    "    datasets_constants,\n",
    "    distances_constants,\n",
    "    models_constants,\n",
    ")\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tabulate import tabulate\n",
    "from tinyimagenet import TinyImageNet\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.model_zoo import tqdm\n",
    "from torchvision.datasets import (\n",
    "    CIFAR10,\n",
    "    CIFAR100,\n",
    "    MNIST,\n",
    "    STL10,\n",
    "    SVHN,\n",
    "    DatasetFolder,\n",
    "    FashionMNIST,\n",
    "    ImageFolder,\n",
    ")\n",
    "from torchvision.datasets.utils import check_integrity, download_file_from_google_drive\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-XrkWV93JuB"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Configs</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:57.502389Z",
     "start_time": "2025-02-01T15:34:57.492389Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:33.838700Z",
     "iopub.status.busy": "2025-01-12T01:55:33.838432Z",
     "iopub.status.idle": "2025-01-12T01:55:33.849684Z",
     "shell.execute_reply": "2025-01-12T01:55:33.848844Z",
     "shell.execute_reply.started": "2025-01-12T01:55:33.838668Z"
    },
    "id": "qVX67JHf3JuB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DESIRED_DISTRIBUTION = [\n",
    "    [2948, 0, 5293, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1000, 0, 2330, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1000, 0, 5292, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 4249, 3729, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 3729, 0, 2465, 0, 0, 0],\n",
    "    [0, 0, 0, 3720, 0, 0, 2145, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 3865, 2864, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1865, 2863, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 5045, 3248],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 3465, 0, 1329],\n",
    "]\n",
    "\n",
    "\"\"\" \n",
    "    CNN-FMNIST configurations\n",
    "\"\"\"\n",
    "configurations = Config(\n",
    "    MODEL_TYPE=models_constants.MODEL_CNN,\n",
    "    DATASET_TYPE=datasets_constants.DATA_SET_FMNIST,\n",
    "    DATA_DISTRIBUTION_KIND=data_distribution_constants.DATA_DISTRIBUTION_FIX,\n",
    "    DISTANCE_METRIC=distances_constants.DISTANCE_COSINE,\n",
    "    DESIRED_DISTRIBUTION=DESIRED_DISTRIBUTION,\n",
    "    CLUSTERING_PERIOD=5,\n",
    "    FEDERATED_LEARNING_ROUNDS=35,\n",
    "    SAVE_BEFORE_AGGREGATION_MODELS=False,\n",
    "    SENSITIVITY_PERCENTAGE=-1,\n",
    "    NUMBER_OF_EPOCHS=1,\n",
    "    TRAIN_BATCH_SIZE=64,\n",
    "    TEST_BATCH_SIZE=64\n",
    ")\n",
    "\n",
    "\"\"\" \n",
    "    ResNet18-SVHN configurations\n",
    "\"\"\"\n",
    "# configurations = Config(\n",
    "#     MODEL_TYPE=models_constants.MODEL_RESNET_18,\n",
    "#     DATASET_TYPE=datasets_constants.DATA_SET_SVHN,\n",
    "#     DATA_DISTRIBUTION_KIND=data_distribution_constants.DATA_DISTRIBUTION_FIX,\n",
    "#     DISTANCE_METRIC=distances_constants.DISTANCE_COSINE,\n",
    "#     DESIRED_DISTRIBUTION=DESIRED_DISTRIBUTION,\n",
    "#     CLUSTERING_PERIOD=5,\n",
    "#     FEDERATED_LEARNING_ROUNDS=35, #! just run 24 FL round is enough for coordinate distance\n",
    "#     SAVE_BEFORE_AGGREGATION_MODELS=True,\n",
    "#     SENSITIVITY_PERCENTAGE=-1,\n",
    "#     NUMBER_OF_EPOCHS=1,\n",
    "#     TRAIN_BATCH_SIZE=256,\n",
    "#     TEST_BATCH_SIZE=256\n",
    "# )\n",
    "\n",
    "\n",
    "SAFE_PFL_CONFIG = configurations.get_config()\n",
    "\n",
    "SAFE_PFL_CONFIG.update(\n",
    "    {\n",
    "        \"DYNAMIC_SENSITIVITY_PERCENTAGE\": True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:57.760382Z",
     "start_time": "2025-02-01T15:34:57.568082Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:33.850966Z",
     "iopub.status.busy": "2025-01-12T01:55:33.850676Z",
     "iopub.status.idle": "2025-01-12T01:55:33.868843Z",
     "shell.execute_reply": "2025-01-12T01:55:33.868055Z",
     "shell.execute_reply.started": "2025-01-12T01:55:33.850937Z"
    },
    "id": "uu3Fu3A3qnPR",
    "outputId": "45cda9ce-b5d6-4d22-8419-861beac9014a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"darkgrid\", font_scale=1.5, rc={\"axes.unicode_minus\": False}\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# to produce reproducible results (like random.seed())\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self):\n",
    "        log_path = datetime.now().strftime(\n",
    "            f'Model={SAFE_PFL_CONFIG[\"MODEL_TYPE\"]}-Dataset={SAFE_PFL_CONFIG[\"DATASET_TYPE\"]}-N={SAFE_PFL_CONFIG[\"PARTITION\"]}-P={SAFE_PFL_CONFIG[\"SENSITIVITY_PERCENTAGE\"]}_on={SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"]}_at=%Y-%m-%d_%H')\n",
    "        log_file = \"logs/\" + log_path + \".log\"\n",
    "\n",
    "        os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "        if os.path.exists(log_file):\n",
    "            try:\n",
    "                os.remove(log_file)\n",
    "                print(f\"Old log file '{log_file}' deleted.\")\n",
    "            except PermissionError as _:\n",
    "                print(\"Log file deletion can cause data lost, if you are sure please restart you session\")\n",
    "                \n",
    "        self.log_instance = logging.getLogger(\"SAFE_PFL_LOGGER\")\n",
    "        self.log_instance.setLevel(logging.DEBUG)\n",
    "        self.log_instance.propagate = False\n",
    "\n",
    "        formatter = logging.Formatter(\n",
    "            fmt='%(asctime)s, line: %(lineno)d %(levelname)8s | %(message)s',\n",
    "            datefmt='%Y/%m/%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        # Create a file handler\n",
    "        file_handler = logging.FileHandler(log_file, mode='a')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        self.log_instance.addHandler(file_handler)\n",
    "\n",
    "        # Create a stream handler (for console output)\n",
    "        screen_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "        screen_handler.setFormatter(formatter)\n",
    "        self.log_instance.addHandler(screen_handler)\n",
    "\n",
    "        self.log_instance.info(\"Logger object created successfully...\")\n",
    "        self.log_instance.warning(f\"The {log_file} will be truncated at each run\")\n",
    "\n",
    "    def info(self, info: str):\n",
    "        self.log_instance.info(info)\n",
    "        self.flush()\n",
    "\n",
    "    def warn(self, warn: str):\n",
    "        self.log_instance.warning(warn)\n",
    "        self.flush()\n",
    "\n",
    "    def debug(self, debug: str):\n",
    "        self.log_instance.debug(debug)\n",
    "        self.flush()\n",
    "\n",
    "    def critical(self, critical: str):\n",
    "        self.log_instance.critical(critical)\n",
    "        self.flush()\n",
    "\n",
    "    def error(self, error: str):\n",
    "        self.log_instance.error(error)\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        for handler in self.log_instance.handlers:\n",
    "            if hasattr(handler, 'flush'):\n",
    "                handler.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.log_instance.handlers.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = [[key, value] for key, value in SAFE_PFL_CONFIG.items()]\n",
    "log.info(tabulate(table_data, headers=[\"Config Key\", \"Value\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Garbage Collection</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "def print_gpu_memory():\n",
    "    log.info(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB\")\n",
    "    log.info(f\"Cached memory: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "\n",
    "log.info(\"before memory cleaning\")\n",
    "print_gpu_memory()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "log.info(\"after memory cleaning\")\n",
    "print_gpu_memory()\n",
    "\n",
    "# ----------- manually clear memory in case of any error\n",
    "#!sudo fuser -v /dev/nvidia* or nvidia-smi\n",
    "# remove all python process ids from gpu\n",
    "#!sudo kill -9 PID.\n",
    "\n",
    "#* Make directories\n",
    "MODEL_SAVING_PATH = os.path.join('./models', SAFE_PFL_CONFIG[\"MODEL_TYPE\"], SAFE_PFL_CONFIG[\"DATASET_TYPE\"]) + '/'\n",
    "if not os.path.exists(MODEL_SAVING_PATH):\n",
    "    os.makedirs(MODEL_SAVING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSl3rZx23JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Model Network</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:57.836152Z",
     "start_time": "2025-02-01T15:34:57.827935Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:33.871421Z",
     "iopub.status.busy": "2025-01-12T01:55:33.871170Z",
     "iopub.status.idle": "2025-01-12T01:55:33.883394Z",
     "shell.execute_reply": "2025-01-12T01:55:33.882638Z",
     "shell.execute_reply.started": "2025-01-12T01:55:33.871402Z"
    },
    "id": "evEmrviBwIoH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "            self, _model_type: str, _number_of_classes: int\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self._model_type = _model_type\n",
    "        self._number_of_classes = _number_of_classes\n",
    "        self.final_layer_name = None\n",
    "\n",
    "        if self._model_type == \"resnet18\":\n",
    "            self.resnet = models.resnet18(pretrained=False)\n",
    "            self.resnet.fc = nn.Linear(\n",
    "                self.resnet.fc.in_features, self._number_of_classes\n",
    "            )\n",
    "            self.final_layer_name = \"resnet.fc.weight\"\n",
    "        elif self._model_type == \"resnet50\":\n",
    "            self.resnet = models.resnet50(pretrained=False)\n",
    "            self.resnet.fc = nn.Linear(self.resnet.fc.in_features, self._number_of_classes)\n",
    "            self.final_layer_name = \"resnet.fc.weight\"\n",
    "        elif self._model_type == \"cnn\":\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Input: 1x28x28, Output: 32x28x28\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Input: 32x28x28, Output: 64x28x28\n",
    "            # Max pooling layer\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Reduces spatial dimensions by half\n",
    "            # Fully connected layers\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Input: 64x7x7, Output: 128\n",
    "            self.fc2 = nn.Linear(128, self._number_of_classes)  \n",
    "            self.final_layer_name = \"fc2.weight\"\n",
    "        elif self._model_type == \"mobilenet\":\n",
    "            self.mobilenet = models.mobilenet_v2(pretrained=False)\n",
    "            self.mobilenet.classifier[3] = nn.Linear(self.mobilenet.classifier[3].in_features, self._number_of_classes)\n",
    "            self.final_layer_name = \"mobilenet.classifier.3.weight\"\n",
    "        elif self._model_type == \"alexnet\":\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "\n",
    "            self._to_linear = 128 * (128 // 8) * (128 // 8)\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(self._to_linear, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(512, self._number_of_classes),\n",
    "            )\n",
    "            self.final_layer_name = \"classifier.3.weight\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "\n",
    "        if self._model_type in [\"resnet18\", \"resnet50\"]:\n",
    "            out = self.resnet(x)\n",
    "        elif self._model_type == \"cnn\":\n",
    "            x = F.relu(self.conv1(x))  # Output: 32x28x28\n",
    "            x = self.pool(x)  # Output: 32x14x14\n",
    "            x = F.relu(self.conv2(x))  # Output: 64x14x14\n",
    "            x = self.pool(x)  # Output: 64x7x7\n",
    "            # Flatten the output for fully connected layers\n",
    "            x = x.view(x.size(0), -1)  # Flatten to (batch_size, 64*7*7)\n",
    "            # Fully connected layers\n",
    "            x = F.relu(self.fc1(x))  # Output: 128\n",
    "            x = self.fc2(x)  # Output: num_classes\n",
    "            return x\n",
    "        elif self._model_type == \"mobilenet\":\n",
    "            out = self.mobilenet(x)\n",
    "\n",
    "        elif self._model_type == \"alexnet\":\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            out = x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSKd2tLw3JuD"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Loading & Saving</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.011740Z",
     "start_time": "2025-02-01T15:34:58.005177Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.003709Z",
     "iopub.status.busy": "2025-01-12T01:55:34.003519Z",
     "iopub.status.idle": "2025-01-12T01:55:34.019859Z",
     "shell.execute_reply": "2025-01-12T01:55:34.019127Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.003684Z"
    },
    "id": "LazN3rY5xDiZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_torch_model(node_id):\n",
    "    model_path = f\"models/node_{node_id}.pth\"\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_torch_model_before_agg(node_id):\n",
    "    model_path = f\"models/before_aggregation/node_{node_id}.pth\"\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_torch_model_before_agg(model, client_id: str):\n",
    "    model_path = f\"models/before_aggregation/node_{client_id}.pth\"\n",
    "    torch.save(model, model_path)\n",
    "\n",
    "\n",
    "def save_torch_model(model, node_id):\n",
    "    model_path = f\"models/node_{node_id}.pth\"\n",
    "    torch.save(model, model_path)\n",
    "\n",
    "\n",
    "def save_model_param(model, node_id, round_number):\n",
    "    model_path = f\"models/node_{node_id}_round_{round_number}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq920RVv3JuD"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Non-IID Distribution</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.106624Z",
     "start_time": "2025-02-01T15:34:58.044482Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.021016Z",
     "iopub.status.busy": "2025-01-12T01:55:34.020791Z",
     "iopub.status.idle": "2025-01-12T01:55:34.088120Z",
     "shell.execute_reply": "2025-01-12T01:55:34.087297Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.020987Z"
    },
    "id": "eGjDwC9x3JuD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = (\n",
    "    \".jpg\",\n",
    "    \".jpeg\",\n",
    "    \".png\",\n",
    "    \".ppm\",\n",
    "    \".bmp\",\n",
    "    \".pgm\",\n",
    "    \".tif\",\n",
    "    \".tiff\",\n",
    "    \".webp\",\n",
    ")\n",
    "\n",
    "\n",
    "def mkdirs(dirpath):\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except Exception as _:\n",
    "        pass\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, \"rb\") as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert(\"RGB\")\n",
    "\n",
    "class CustomTensorDataset(data.TensorDataset):\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors) + (index,)\n",
    "\n",
    "\n",
    "class MNIST_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        mnist_dataobj = MNIST(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = mnist_dataobj.data\n",
    "        target = mnist_dataobj.targets\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class FashionMNIST_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        mnist_dataobj = FashionMNIST(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = mnist_dataobj.data\n",
    "        target = mnist_dataobj.targets\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class SVHN_custom(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "        if self.train is True:\n",
    "\n",
    "            svhn_dataobj = SVHN(\n",
    "                self.root, \"train\", self.transform, self.target_transform, self.download\n",
    "            )\n",
    "            data = svhn_dataobj.data\n",
    "            target = svhn_dataobj.labels\n",
    "        else:\n",
    "            svhn_dataobj = SVHN(\n",
    "                self.root, \"test\", self.transform, self.target_transform, self.download\n",
    "            )\n",
    "            data = svhn_dataobj.data\n",
    "            target = svhn_dataobj.labels\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "# torchvision CelebA\n",
    "class CelebA_custom(VisionDataset):\n",
    "    \"\"\"`Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where images are downloaded to.\n",
    "        split (string): One of {'train', 'valid', 'test', 'all'}.\n",
    "            Accordingly dataset is selected.\n",
    "        target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
    "            or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
    "            The targets represent:\n",
    "                ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
    "                ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
    "                ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
    "                ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
    "                    righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
    "            Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "\n",
    "    base_folder = \"celeba\"\n",
    "    # There currently does not appear to be a easy way to extract 7z in python (without introducing additional\n",
    "    # dependencies). The \"in-the-wild\" (not aligned+cropped) images are only in 7z, so they are not available\n",
    "    # right now.\n",
    "    file_list = [\n",
    "        # File ID                         MD5 Hash                            Filename\n",
    "        (\n",
    "            \"0B7EVK8r0v71pZjFTYXZWM3FlRnM\",\n",
    "            \"00d2c5bc6d35e252742224ab0c1e8fcb\",\n",
    "            \"img_align_celeba.zip\",\n",
    "        ),\n",
    "        # (\"0B7EVK8r0v71pbWNEUjJKdDQ3dGc\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_align_celeba_png.7z\"),\n",
    "        # (\"0B7EVK8r0v71peklHb0pGdDl6R28\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_celeba.7z\"),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pblRyaVFSWGxPY0U\",\n",
    "            \"75e246fa4810816ffd6ee81facbd244c\",\n",
    "            \"list_attr_celeba.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\",\n",
    "            \"32bd1bd63d3c78cd57e08160ec5ed1e2\",\n",
    "            \"identity_CelebA.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pbThiMVRxWXZ4dU0\",\n",
    "            \"00566efa6fedff7a56946cd1c10f1c16\",\n",
    "            \"list_bbox_celeba.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pd0FJY3Blby1HUTQ\",\n",
    "            \"cc24ecafdb5b50baae59b03474781f8c\",\n",
    "            \"list_landmarks_align_celeba.txt\",\n",
    "        ),\n",
    "        # (\"0B7EVK8r0v71pTzJIdlJWdHczRlU\", \"063ee6ddb681f96bc9ca28c6febb9d1a\", \"list_landmarks_celeba.txt\"),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pY0NSMzRuSXJEVkk\",\n",
    "            \"d32c9cbf5e040fd4025c592c306e6668\",\n",
    "            \"list_eval_partition.txt\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            split=\"train\",\n",
    "            target_type=\"attr\",\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "        import pandas\n",
    "\n",
    "        super(CelebA_custom, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.split = split\n",
    "        if isinstance(target_type, list):\n",
    "            self.target_type = target_type\n",
    "        else:\n",
    "            self.target_type = [target_type]\n",
    "\n",
    "        if not self.target_type and self.target_transform is not None:\n",
    "            raise RuntimeError(\"target_transform is specified but target_type is empty\")\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found or corrupted.\"\n",
    "                + \" You can use download=True to download it\"\n",
    "            )\n",
    "\n",
    "        split_map = {\n",
    "            \"train\": 0,\n",
    "            \"valid\": 1,\n",
    "            \"test\": 2,\n",
    "            \"all\": None,\n",
    "        }\n",
    "        split = split_map[split.lower()]\n",
    "\n",
    "        fn = partial(os.path.join, self.root, self.base_folder)\n",
    "        splits = pandas.read_csv(\n",
    "            fn(\"list_eval_partition.txt\"),\n",
    "            delim_whitespace=True,\n",
    "            header=None,\n",
    "            index_col=0,\n",
    "        )\n",
    "        identity = pandas.read_csv(\n",
    "            fn(\"identity_CelebA.txt\"), delim_whitespace=True, header=None, index_col=0\n",
    "        )\n",
    "        bbox = pandas.read_csv(\n",
    "            fn(\"list_bbox_celeba.txt\"), delim_whitespace=True, header=1, index_col=0\n",
    "        )\n",
    "        landmarks_align = pandas.read_csv(\n",
    "            fn(\"list_landmarks_align_celeba.txt\"), delim_whitespace=True, header=1\n",
    "        )\n",
    "        attr = pandas.read_csv(\n",
    "            fn(\"list_attr_celeba.txt\"), delim_whitespace=True, header=1\n",
    "        )\n",
    "\n",
    "        mask = slice(None) if split is None else (splits[1] == split)\n",
    "\n",
    "        self.filename = splits[mask].index.values\n",
    "        self.identity = torch.as_tensor(identity[mask].values)\n",
    "        self.bbox = torch.as_tensor(bbox[mask].values)\n",
    "        self.landmarks_align = torch.as_tensor(landmarks_align[mask].values)\n",
    "        self.attr = torch.as_tensor(attr[mask].values)\n",
    "        self.attr = (self.attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
    "        self.attr_names = list(attr.columns)\n",
    "        self.gender_index = self.attr_names.index(\"Male\")\n",
    "        self.dataidxs = dataidxs\n",
    "        if self.dataidxs is None:\n",
    "            self.target = self.attr[\n",
    "                          :, self.gender_index: self.gender_index + 1\n",
    "                          ].reshape(-1)\n",
    "        else:\n",
    "            self.target = self.attr[\n",
    "                          self.dataidxs, self.gender_index: self.gender_index + 1\n",
    "                          ].reshape(-1)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        for _, md5, filename in self.file_list:\n",
    "            fpath = os.path.join(self.root, self.base_folder, filename)\n",
    "            _, ext = os.path.splitext(filename)\n",
    "            # Allow original archive to be deleted (zip and 7z)\n",
    "            # Only need the extracted images\n",
    "            if ext not in [\".zip\", \".7z\"] and not check_integrity(fpath, md5):\n",
    "                return False\n",
    "\n",
    "        # Should check a hash of the images\n",
    "        return os.path.isdir(\n",
    "            os.path.join(self.root, self.base_folder, \"img_align_celeba\")\n",
    "        )\n",
    "\n",
    "    def download(self):\n",
    "        import zipfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print(\"Files already downloaded and verified\")\n",
    "            return\n",
    "\n",
    "        for file_id, md5, filename in self.file_list:\n",
    "            download_file_from_google_drive(\n",
    "                file_id, os.path.join(self.root, self.base_folder), filename, md5\n",
    "            )\n",
    "\n",
    "        with zipfile.ZipFile(\n",
    "                os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\"\n",
    "        ) as f:\n",
    "            f.extractall(os.path.join(self.root, self.base_folder))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataidxs is None:\n",
    "            X = PIL.Image.open(\n",
    "                os.path.join(\n",
    "                    self.root,\n",
    "                    self.base_folder,\n",
    "                    \"img_align_celeba\",\n",
    "                    self.filename[index],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            target = []\n",
    "            for t in self.target_type:\n",
    "                if t == \"attr\":\n",
    "                    target.append(self.attr[index, self.gender_index])\n",
    "                elif t == \"identity\":\n",
    "                    target.append(self.identity[index, 0])\n",
    "                elif t == \"bbox\":\n",
    "                    target.append(self.bbox[index, :])\n",
    "                elif t == \"landmarks\":\n",
    "                    target.append(self.landmarks_align[index, :])\n",
    "                else:\n",
    "                    # TODO: refactor with utils.verify_str_arg\n",
    "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
    "        else:\n",
    "            X = PIL.Image.open(\n",
    "                os.path.join(\n",
    "                    self.root,\n",
    "                    self.base_folder,\n",
    "                    \"img_align_celeba\",\n",
    "                    self.filename[self.dataidxs[index]],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            target = []\n",
    "            for t in self.target_type:\n",
    "                if t == \"attr\":\n",
    "                    target.append(self.attr[self.dataidxs[index], self.gender_index])\n",
    "                elif t == \"identity\":\n",
    "                    target.append(self.identity[self.dataidxs[index], 0])\n",
    "                elif t == \"bbox\":\n",
    "                    target.append(self.bbox[self.dataidxs[index], :])\n",
    "                elif t == \"landmarks\":\n",
    "                    target.append(self.landmarks_align[self.dataidxs[index], :])\n",
    "                else:\n",
    "                    # TODO: refactor with utils.verify_str_arg\n",
    "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        # print(\"target[0]:\", target[0])\n",
    "        if target:\n",
    "            target = tuple(target) if len(target) > 1 else target[0]\n",
    "\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "        else:\n",
    "            target = None\n",
    "        # print(\"celeba target:\", target)\n",
    "        return X, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.dataidxs is None:\n",
    "            return len(self.attr)\n",
    "        else:\n",
    "            return len(self.dataidxs)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
    "        return \"\\n\".join(lines).format(**self.__dict__)\n",
    "\n",
    "\n",
    "class STL10_truncated(data.Dataset):\n",
    "    def __init__(self, root, dataidxs=None, split=\"train\", transform=None, target_transform=None, download=False):\n",
    "        \"\"\"\n",
    "        Custom STL10 dataset with support for data indexing.\n",
    "        Args:\n",
    "            root (str): Dataset root directory.\n",
    "            dataidxs (list, optional): Indices for data partitioning. Defaults to None.\n",
    "            split (str, optional): Dataset split ('train', 'test', 'unlabeled'). Defaults to 'train'.\n",
    "            transform (callable, optional): Transformations for the input data. Defaults to None.\n",
    "            target_transform (callable, optional): Transformations for the target labels. Defaults to None.\n",
    "            download (bool, optional): Whether to download the dataset. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "        stl10_dataobj = STL10(\n",
    "            self.root, split=self.split, transform=self.transform, target_transform=self.target_transform,\n",
    "            download=self.download\n",
    "        )\n",
    "        data = stl10_dataobj.data\n",
    "        target = np.array(stl10_dataobj.labels)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is the class index.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        # Ensure the image has the correct shape and dtype for PIL\n",
    "        img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "        img = img.astype(np.uint8)  # Ensure dtype is uint8 for PIL compatibility\n",
    "        img = Image.fromarray(img)  # Convert to PIL Image\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class CIFAR10_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        cifar_dataobj = CIFAR10(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = cifar_dataobj.data\n",
    "        target = np.array(cifar_dataobj.targets)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            if isinstance(self.dataidxs, (list, np.ndarray, tuple)):\n",
    "                self.dataidxs = np.array(self.dataidxs, dtype=np.int64)\n",
    "                data = data[self.dataidxs]\n",
    "                target = target[self.dataidxs]\n",
    "            else:\n",
    "                raise TypeError(\"dataidxs must be a list, numpy array, or None.\")\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def truncate_channel(self, index):\n",
    "        for i in range(index.shape[0]):\n",
    "            gs_index = index[i]\n",
    "            self.data[gs_index, :, :, 1] = 0.0\n",
    "            self.data[gs_index, :, :, 2] = 0.0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        # print(\"cifar10 img:\", img)\n",
    "        # print(\"cifar10 target:\", target)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def gen_bar_updater() -> Callable[[int, int, int], None]:\n",
    "    pbar = tqdm(total=None)\n",
    "\n",
    "    def bar_update(count, block_size, total_size):\n",
    "        if pbar.total is None and total_size:\n",
    "            pbar.total = total_size\n",
    "        progress_bytes = count * block_size\n",
    "        pbar.update(progress_bytes - pbar.n)\n",
    "\n",
    "    return bar_update\n",
    "\n",
    "\n",
    "def download_url(\n",
    "        url: str, root: str, filename: Optional[str] = None, md5: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"Download a file from a url and place it in root.\n",
    "    Args:\n",
    "        url (str): URL to download file from\n",
    "        root (str): Directory to place downloaded file in\n",
    "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
    "        md5 (str, optional): MD5 checksum of the download. If None, do not check\n",
    "    \"\"\"\n",
    "    import urllib\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "\n",
    "    # check if file is already present locally\n",
    "    if check_integrity(fpath, md5):\n",
    "        print(\"Using downloaded and verified file: \" + fpath)\n",
    "    else:  # download the file\n",
    "        try:\n",
    "            print(\"Downloading \" + url + \" to \" + fpath)\n",
    "            urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
    "        except (urllib.error.URLError, IOError) as e:  # type: ignore[attr-defined]\n",
    "            if url[:5] == \"https\":\n",
    "                url = url.replace(\"https:\", \"http:\")\n",
    "                print(\n",
    "                    \"Failed download. Trying https -> http instead.\"\n",
    "                    \" Downloading \" + url + \" to \" + fpath\n",
    "                )\n",
    "                urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
    "            else:\n",
    "                raise e\n",
    "        # check integrity of downloaded file\n",
    "        if not check_integrity(fpath, md5):\n",
    "            raise RuntimeError(\"File not found or corrupted.\")\n",
    "\n",
    "\n",
    "def _is_tarxz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar.xz\")\n",
    "\n",
    "\n",
    "def _is_tar(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar\")\n",
    "\n",
    "\n",
    "def _is_targz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar.gz\")\n",
    "\n",
    "\n",
    "def _is_tgz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tgz\")\n",
    "\n",
    "\n",
    "def _is_gzip(filename: str) -> bool:\n",
    "    return filename.endswith(\".gz\") and not filename.endswith(\".tar.gz\")\n",
    "\n",
    "\n",
    "def _is_zip(filename: str) -> bool:\n",
    "    return filename.endswith(\".zip\")\n",
    "\n",
    "\n",
    "def extract_archive(\n",
    "        from_path: str, to_path: Optional[str] = None, remove_finished: bool = False\n",
    ") -> None:\n",
    "    if to_path is None:\n",
    "        to_path = os.path.dirname(from_path)\n",
    "\n",
    "    if _is_tar(from_path):\n",
    "        with tarfile.open(from_path, \"r\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_targz(from_path) or _is_tgz(from_path):\n",
    "        with tarfile.open(from_path, \"r:gz\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_tarxz(from_path):\n",
    "        with tarfile.open(from_path, \"r:xz\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_gzip(from_path):\n",
    "        to_path = os.path.join(\n",
    "            to_path, os.path.splitext(os.path.basename(from_path))[0]\n",
    "        )\n",
    "        with open(to_path, \"wb\") as out_f, gzip.GzipFile(from_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "    elif _is_zip(from_path):\n",
    "        with zipfile.ZipFile(from_path, \"r\") as z:\n",
    "            z.extractall(to_path)\n",
    "    else:\n",
    "        raise ValueError(\"Extraction of {} not supported\".format(from_path))\n",
    "\n",
    "    if remove_finished:\n",
    "        os.remove(from_path)\n",
    "\n",
    "\n",
    "def download_and_extract_archive(\n",
    "        url: str,\n",
    "        download_root: str,\n",
    "        extract_root: Optional[str] = None,\n",
    "        filename: Optional[str] = None,\n",
    "        md5: Optional[str] = None,\n",
    "        remove_finished: bool = False,\n",
    ") -> None:\n",
    "    download_root = os.path.expanduser(download_root)\n",
    "    if extract_root is None:\n",
    "        extract_root = download_root\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "\n",
    "    download_url(url, download_root, filename, md5)\n",
    "\n",
    "    archive = os.path.join(download_root, filename)\n",
    "    print(\"Extracting {} to {}\".format(archive, extract_root))\n",
    "    extract_archive(archive, extract_root, remove_finished)\n",
    "\n",
    "\n",
    "class FEMNIST(MNIST):\n",
    "    \"\"\"\n",
    "    This dataset is derived from the Leaf repository\n",
    "    (https://github.com/TalwalkarLab/leaf) pre-processing of the Extended MNIST\n",
    "    dataset, grouping examples by writer. Details about Leaf were published in\n",
    "    \"LEAF: A Benchmark for Federated Settings\" https://arxiv.org/abs/1812.01097.\n",
    "    \"\"\"\n",
    "\n",
    "    resources = [\n",
    "        (\n",
    "            \"https://raw.githubusercontent.com/tao-shen/FEMNIST_pytorch/master/femnist.tar.gz\",\n",
    "            \"59c65cec646fc57fe92d27d83afdf0ed\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "        super(MNIST, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.train = train\n",
    "        self.dataidxs = dataidxs\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found.\" + \" You can use download=True to download it\"\n",
    "            )\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "\n",
    "        self.data, self.targets, self.users_index = torch.load(\n",
    "            os.path.join(self.processed_folder, data_file)\n",
    "        )\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            self.data = self.data[self.dataidxs]\n",
    "            self.targets = self.targets[self.dataidxs]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.numpy(), mode=\"F\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the FEMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        import shutil\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        mkdirs(self.raw_folder)\n",
    "        mkdirs(self.processed_folder)\n",
    "\n",
    "        # download files\n",
    "        for url, md5 in self.resources:\n",
    "            filename = url.rpartition(\"/\")[2]\n",
    "            download_and_extract_archive(\n",
    "                url, download_root=self.raw_folder, filename=filename, md5=md5\n",
    "            )\n",
    "\n",
    "        # process and save as torch files\n",
    "        print(\"Processing...\")\n",
    "        shutil.move(\n",
    "            os.path.join(self.raw_folder, self.training_file), self.processed_folder\n",
    "        )\n",
    "        shutil.move(\n",
    "            os.path.join(self.raw_folder, self.test_file), self.processed_folder\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(\n",
    "            check_integrity(\n",
    "                os.path.join(\n",
    "                    self.raw_folder,\n",
    "                    os.path.splitext(os.path.basename(url))[0]\n",
    "                    + os.path.splitext(os.path.basename(url))[1],\n",
    "                )\n",
    "            )\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "\n",
    "class Generated(MNIST):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "        super(MNIST, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.train = train\n",
    "        self.dataidxs = dataidxs\n",
    "\n",
    "        if self.train:\n",
    "            self.data = np.load(\"data/generated/X_train.npy\")\n",
    "            self.targets = np.load(\"data/generated/y_train.npy\")\n",
    "        else:\n",
    "            self.data = np.load(\"data/generated/X_test.npy\")\n",
    "            self.targets = np.load(\"data/generated/y_test.npy\")\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            self.data = self.data[self.dataidxs]\n",
    "            self.targets = self.targets[self.dataidxs]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.data[index], self.targets[index]\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class genData(MNIST):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.data[index], self.targets[index]\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class CIFAR100_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        cifar_dataobj = CIFAR100(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        if torchvision.__version__ == \"0.2.1\":\n",
    "            if self.train:\n",
    "                data, target = cifar_dataobj.train_data, np.array(\n",
    "                    cifar_dataobj.train_labels\n",
    "                )\n",
    "            else:\n",
    "                data, target = cifar_dataobj.test_data, np.array(\n",
    "                    cifar_dataobj.test_labels\n",
    "                )\n",
    "        else:\n",
    "            data = cifar_dataobj.data\n",
    "            target = np.array(cifar_dataobj.targets)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "        img = Image.fromarray(img)\n",
    "        # print(\"cifar10 img:\", img)\n",
    "        # print(\"cifar10 target:\", target)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class ImageFolder_custom(DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dataidxs=None,\n",
    "            train=True,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "            download=None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        imagefolder_obj = ImageFolder(self.root, self.transform, self.target_transform)\n",
    "        self.loader = imagefolder_obj.loader\n",
    "        if self.dataidxs is not None:\n",
    "            self.samples = np.array(imagefolder_obj.samples)[self.dataidxs]\n",
    "        else:\n",
    "            self.samples = np.array(imagefolder_obj.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index][0]\n",
    "        target = self.samples[index][1]\n",
    "        target = int(target)\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.dataidxs is None:\n",
    "            return len(self.samples)\n",
    "        else:\n",
    "            return len(self.dataidxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.180294Z",
     "start_time": "2025-02-01T15:34:58.164557Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.089328Z",
     "iopub.status.busy": "2025-01-12T01:55:34.089036Z",
     "iopub.status.idle": "2025-01-12T01:55:34.135474Z",
     "shell.execute_reply": "2025-01-12T01:55:34.134693Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.089307Z"
    },
    "id": "27nyJr8n3JuE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mkdirs(dirpath):\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except Exception as _:\n",
    "        pass\n",
    "\n",
    "\n",
    "def load_mnist_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train_ds = MNIST_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    mnist_test_ds = MNIST_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
    "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_fmnist_data(datadir):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    mnist_train_ds = FashionMNIST_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    mnist_test_ds = FashionMNIST_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
    "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_svhn_data(datadir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    svhn_train_ds = SVHN_custom(datadir, train=True, download=True, transform=transform)\n",
    "    svhn_test_ds = SVHN_custom(datadir, train=False, download=True, transform=transform)\n",
    "    X_train, y_train = svhn_train_ds.data, svhn_train_ds.target\n",
    "    X_test, y_test = svhn_test_ds.data, svhn_test_ds.target\n",
    "    # X_train = X_train.data.numpy()\n",
    "    # y_train = y_train.data.numpy()\n",
    "    # X_test = X_test.data.numpy()\n",
    "    # y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_cifar10_data(datadir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    cifar10_train_ds = CIFAR10_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    cifar10_test_ds = CIFAR10_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = cifar10_train_ds.data, cifar10_train_ds.target\n",
    "    X_test, y_test = cifar10_test_ds.data, cifar10_test_ds.target\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_celeba_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    celeba_train_ds = CelebA_custom(\n",
    "        datadir, split=\"train\", target_type=\"attr\", download=True, transform=transform\n",
    "    )\n",
    "    celeba_test_ds = CelebA_custom(\n",
    "        datadir, split=\"test\", target_type=\"attr\", download=True, transform=transform\n",
    "    )\n",
    "    gender_index = celeba_train_ds.attr_names.index(\"Male\")\n",
    "    y_train = celeba_train_ds.attr[:, gender_index: gender_index + 1].reshape(-1)\n",
    "    y_test = celeba_test_ds.attr[:, gender_index: gender_index + 1].reshape(-1)\n",
    "    # y_train = y_train.numpy()\n",
    "    # y_test = y_test.numpy()\n",
    "    return (None, y_train, None, y_test)\n",
    "\n",
    "\n",
    "def load_femnist_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train_ds = FEMNIST(datadir, train=True, transform=transform, download=True)\n",
    "    mnist_test_ds = FEMNIST(datadir, train=False, transform=transform, download=True)\n",
    "    X_train, y_train, u_train = (\n",
    "        mnist_train_ds.data,\n",
    "        mnist_train_ds.targets,\n",
    "        mnist_train_ds.users_index,\n",
    "    )\n",
    "    X_test, y_test, u_test = (\n",
    "        mnist_test_ds.data,\n",
    "        mnist_test_ds.targets,\n",
    "        mnist_test_ds.users_index,\n",
    "    )\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    u_train = np.array(u_train)\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    u_test = np.array(u_test)\n",
    "    return (X_train, y_train, u_train, X_test, y_test, u_test)\n",
    "\n",
    "\n",
    "def load_cifar100_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    cifar100_train_ds = CIFAR100_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    cifar100_test_ds = CIFAR100_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = cifar100_train_ds.data, cifar100_train_ds.target\n",
    "    X_test, y_test = cifar100_test_ds.data, cifar100_test_ds.target\n",
    "    # y_train = y_train.numpy()\n",
    "    # y_test = y_test.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_tinyimagenet_data(datadir):\n",
    "    split = \"val\"\n",
    "    TinyImageNet(datadir, split=split)\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "        transforms.RandomRotation(15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "    # transform = transforms.Compose([transforms.ToTensor()])\n",
    "    xray_train_ds = ImageFolder_custom(\n",
    "        datadir + \"tiny-imagenet-200/train/\", transform=transform_train\n",
    "    )\n",
    "    xray_test_ds = ImageFolder_custom(\n",
    "        datadir + \"tiny-imagenet-200/val/\", transform=transform_test\n",
    "    )\n",
    "    X_train, y_train = np.array([s[0] for s in xray_train_ds.samples]), np.array(\n",
    "        [int(s[1]) for s in xray_train_ds.samples]\n",
    "    )\n",
    "    X_test, y_test = np.array([s[0] for s in xray_test_ds.samples]), np.array(\n",
    "        [int(s[1]) for s in xray_test_ds.samples]\n",
    "    )\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_stl10_data(datadir):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    stl10_train_ds = STL10_truncated(datadir, split=\"train\", transform=transform_train, download=True)\n",
    "    stl10_test_ds = STL10_truncated(datadir, split=\"test\", transform=transform_test, download=True)\n",
    "\n",
    "    X_train, y_train = stl10_train_ds.data, stl10_train_ds.target\n",
    "    X_test, y_test = stl10_test_ds.data, stl10_test_ds.target\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def record_net_data_stats(y_train, net_dataidx_map, logdir):\n",
    "    net_cls_counts = {}\n",
    "    for net_i, dataidx in net_dataidx_map.items():\n",
    "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
    "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
    "        net_cls_counts[net_i] = tmp\n",
    "    log.info(\"Data statistics: %s\" % str(net_cls_counts))\n",
    "    return net_cls_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.236480Z",
     "start_time": "2025-02-01T15:34:58.221212Z"
    }
   },
   "outputs": [],
   "source": [
    "def partition_data(dataset, datadir, logdir, partition, n_parties, beta=0.1):\n",
    "    test_dataidx_map = {}\n",
    "\n",
    "    # Load dataset\n",
    "    if dataset == \"mnist\":\n",
    "        X_train, y_train, X_test, y_test = load_mnist_data(datadir)\n",
    "    elif dataset == \"fmnist\":\n",
    "        X_train, y_train, X_test, y_test = load_fmnist_data(datadir)\n",
    "    elif dataset == \"cifar10\":\n",
    "        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)\n",
    "    elif dataset == \"svhn\":\n",
    "        X_train, y_train, X_test, y_test = load_svhn_data(datadir)\n",
    "    elif dataset == \"celeba\":\n",
    "        X_train, y_train, X_test, y_test = load_celeba_data(datadir)\n",
    "    elif dataset == \"femnist\":\n",
    "        X_train, y_train, u_train, X_test, y_test, u_test = load_femnist_data(datadir)\n",
    "    elif dataset == \"cifar100\":\n",
    "        X_train, y_train, X_test, y_test = load_cifar100_data(datadir)\n",
    "    elif dataset == \"tinyimagenet\":\n",
    "        X_train, y_train, X_test, y_test = load_tinyimagenet_data(datadir)\n",
    "    elif dataset == \"stl10\":\n",
    "        X_train, y_train, X_test, y_test = load_stl10_data(datadir)\n",
    "    elif dataset == \"generated\":\n",
    "        # Code for generated dataset (omitted for brevity)\n",
    "        pass\n",
    "    # Add other datasets if needed\n",
    "\n",
    "    n_train = y_train.shape[0]\n",
    "\n",
    "    # Partition the data\n",
    "    if partition == \"homo\":\n",
    "        # Homogeneous data partition\n",
    "        idxs = np.random.permutation(n_train)\n",
    "        batch_idxs = np.array_split(idxs, n_parties)\n",
    "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
    "\n",
    "    elif partition == \"noniid-labeldir\":\n",
    "        min_size = 0\n",
    "        min_require_size = 10  # Minimum number required for each party\n",
    "        if dataset == \"cifar100\":\n",
    "            K = 100  # Number of classes\n",
    "        else:\n",
    "            k = 10\n",
    "\n",
    "        N = y_train.shape[0]\n",
    "        net_dataidx_map = {}\n",
    "        test_dataidx_map = {}  # Make sure to initialize this\n",
    "\n",
    "        while min_size < min_require_size:\n",
    "            idx_batch = [[] for _ in range(n_parties)]\n",
    "            for k in range(K):\n",
    "                idx_k = np.where(y_train == k)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
    "                proportions = np.array(\n",
    "                    [\n",
    "                        p * (len(idx_j) < N / n_parties)\n",
    "                        for p, idx_j in zip(proportions, idx_batch)\n",
    "                    ]\n",
    "                )\n",
    "                proportions = proportions / proportions.sum()  # Normalize\n",
    "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                idx_batch = [\n",
    "                    idx_j + idx.tolist()\n",
    "                    for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))\n",
    "                ]\n",
    "\n",
    "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "\n",
    "        for j in range(n_parties):\n",
    "            np.random.shuffle(idx_batch[j])\n",
    "            net_dataidx_map[j] = idx_batch[j]\n",
    "\n",
    "            # Initialize test_dataidx_map for current party\n",
    "            test_dataidx_map[j] = []\n",
    "\n",
    "            # Gather test indices for current party based on labels in net_dataidx_map[j]\n",
    "            for k in range(K):\n",
    "                if k in y_train[net_dataidx_map[j]]:\n",
    "                    # Access test indices for class k\n",
    "                    idx_test_k = np.where(y_test == k)[0]\n",
    "                    np.random.shuffle(idx_test_k)\n",
    "\n",
    "                    # The number of sample for each party based on training set size\n",
    "                    n_samples = int(len(net_dataidx_map[j]) * len(idx_test_k) / N)\n",
    "                    test_dataidx_map[j].extend(idx_test_k[:n_samples])\n",
    "\n",
    "            test_dataidx_map[j] = np.array(test_dataidx_map[j])\n",
    "\n",
    "        # Cleanup to avoid empty concatenation error\n",
    "        for j in range(n_parties):\n",
    "            if len(test_dataidx_map[j]) == 0:\n",
    "                test_dataidx_map[j] = np.array(\n",
    "                    []\n",
    "                )  # Set to an empty array to avoid errors later\n",
    "\n",
    "    elif partition == \"noniid-fix\":\n",
    "        # Custom fixed distribution logic\n",
    "        desired_distribution = SAFE_PFL_CONFIG[\"DESIRED_DISTRIBUTION\"]\n",
    "\n",
    "        # Number of clients and classes\n",
    "        num_clients = len(desired_distribution)\n",
    "        num_classes = len(desired_distribution[0])\n",
    "\n",
    "        assert num_clients == SAFE_PFL_CONFIG[\"NUMBER_OF_CLIENTS\"]\n",
    "        assert num_classes == SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]\n",
    "\n",
    "        ##Initialize the data indices for each client\n",
    "        net_dataidx_map = {i: [] for i in range(num_clients)}\n",
    "        # Iterate over each class and assign samples to clients based on the desired distribution\n",
    "        for class_idx in range(num_classes):\n",
    "            # Get the indices of all samples belonging to the current class\n",
    "            class_indices = np.where(y_train == class_idx)[0]\n",
    "\n",
    "            # Shuffle the indices to ensure randomness\n",
    "            np.random.shuffle(class_indices)\n",
    "\n",
    "            # Assign samples to clients based on the desired distribution\n",
    "            start_idx = 0\n",
    "            for client_idx in range(num_clients):\n",
    "                num_samples = desired_distribution[client_idx][class_idx]\n",
    "                if num_samples > 0:\n",
    "                    end_idx = start_idx + num_samples\n",
    "                    net_dataidx_map[client_idx].extend(class_indices[start_idx:end_idx])\n",
    "                    start_idx = end_idx\n",
    "\n",
    "        # Initialize test_dataidx_map for each client\n",
    "        for j in range(num_clients):\n",
    "            test_dataidx_map[j] = []\n",
    "\n",
    "            # Gather test indices for current party based on labels in net_dataidx_map[j]\n",
    "            for k in range(num_classes):\n",
    "                if k in y_train[net_dataidx_map[j]]:\n",
    "                    # Access test indices for class k\n",
    "                    idx_test_k = np.where(y_test == k)[0]\n",
    "                    np.random.shuffle(idx_test_k)\n",
    "\n",
    "                    # The number of samples for each party based on training set size\n",
    "                    n_samples = int(len(net_dataidx_map[j]) * len(idx_test_k) / n_train)\n",
    "                    test_dataidx_map[j].extend(idx_test_k[:n_samples])\n",
    "\n",
    "            test_dataidx_map[j] = np.array(test_dataidx_map[j])\n",
    "\n",
    "        # Cleanup to avoid empty concatenation error\n",
    "        for j in range(num_clients):\n",
    "            if len(test_dataidx_map[j]) == 0:\n",
    "                test_dataidx_map[j] = np.array(\n",
    "                    []\n",
    "                )  # Set to an empty array to avoid errors later\n",
    "\n",
    "    elif partition.startswith(\"noniid-#label\") and partition[13:].isdigit():\n",
    "        # Existing logic for noniid-#label partitioning\n",
    "        num = int(partition[13:])\n",
    "        if dataset in (\"celeba\", \"covtype\", \"a9a\", \"rcv1\", \"SUSY\"):\n",
    "            num = 1\n",
    "            K = 2\n",
    "        else:\n",
    "            if dataset == \"cifar100\":\n",
    "                K = 100\n",
    "            elif dataset == \"tinyimagenet\":\n",
    "                K = 200\n",
    "            else:\n",
    "                K = 10\n",
    "        if num == K:\n",
    "            # IID partition\n",
    "            net_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            for i in range(K):\n",
    "                idx_k = np.where(y_train == i)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                split = np.array_split(idx_k, n_parties)\n",
    "                for j in range(n_parties):\n",
    "                    net_dataidx_map[j] = np.append(net_dataidx_map[j], split[j])\n",
    "        else:\n",
    "            times = [0 for _ in range(K)]\n",
    "            contain = []\n",
    "            for i in range(n_parties):\n",
    "                current = [i % K]\n",
    "                times[i % K] += 1\n",
    "                j = 1\n",
    "                while j < num:\n",
    "                    ind = random.randint(0, K - 1)\n",
    "                    if ind not in current:\n",
    "                        j += 1\n",
    "                        current.append(ind)\n",
    "                        times[ind] += 1\n",
    "                contain.append(current)\n",
    "            net_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            test_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            for i in range(K):\n",
    "                if times[i] > 0:\n",
    "                    idx_k = np.where(y_train == i)[0]\n",
    "                    idx_t = np.where(y_test == i)[0]\n",
    "                    np.random.shuffle(idx_k)\n",
    "                    np.random.shuffle(idx_t)\n",
    "                    split = np.array_split(idx_k, times[i])\n",
    "                    splitt = np.array_split(idx_t, times[i])\n",
    "                    ids = 0\n",
    "                    for j in range(n_parties):\n",
    "                        if i in contain[j]:\n",
    "                            net_dataidx_map[j] = np.append(\n",
    "                                net_dataidx_map[j], split[ids]\n",
    "                            )\n",
    "                            test_dataidx_map[j] = np.append(\n",
    "                                test_dataidx_map[j], splitt[ids]\n",
    "                            )\n",
    "                            ids += 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown partition method: {partition}\")\n",
    "\n",
    "    # Record the data statistics\n",
    "    traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)\n",
    "\n",
    "    return (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        net_dataidx_map,\n",
    "        test_dataidx_map,\n",
    "        traindata_cls_counts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.296280Z",
     "start_time": "2025-02-01T15:34:58.284280Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0, net_id=None, total=0):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.net_id = net_id\n",
    "        self.num = int(sqrt(total))\n",
    "        if self.num * self.num < total:\n",
    "            self.num = self.num + 1\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if self.net_id is None:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            tmp = torch.randn(tensor.size())\n",
    "            filt = torch.zeros(tensor.size())\n",
    "            size = int(28 / self.num)\n",
    "            row = int(self.net_id / size)\n",
    "            col = self.net_id % size\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    filt[:, row * size + i, col * size + j] = 1\n",
    "            tmp = tmp * filt\n",
    "            return tensor + tmp * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"(mean={0}, std={1})\".format(\n",
    "            self.mean, self.std\n",
    "        )\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "        dataset,\n",
    "        datadir,\n",
    "        train_bs,\n",
    "        test_bs,\n",
    "        dataidxs=None,\n",
    "        testidxs=None,\n",
    "        noise_level=0,\n",
    "        net_id=None,\n",
    "        total=0,\n",
    "):\n",
    "    if dataset in (\n",
    "            \"mnist\",\n",
    "            \"femnist\",\n",
    "            \"fmnist\",\n",
    "            \"cifar10\",\n",
    "            \"svhn\",\n",
    "            \"generated\",\n",
    "            \"covtype\",\n",
    "            \"a9a\",\n",
    "            \"rcv1\",\n",
    "            \"SUSY\",\n",
    "            \"cifar100\",\n",
    "            \"tinyimagenet\",\n",
    "            \"stl10\"\n",
    "    ):\n",
    "        if dataset == \"mnist\":\n",
    "            dl_obj = MNIST_truncated\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"femnist\":\n",
    "            dl_obj = FEMNIST\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"fmnist\":\n",
    "            dl_obj = FashionMNIST_truncated\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"svhn\":\n",
    "            dl_obj = SVHN_custom\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "\n",
    "        elif dataset == \"cifar10\":\n",
    "            dl_obj = CIFAR10_truncated\n",
    "            log.warn(\"test me please! CIFAR10_truncated\")\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    # transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Lambda(\n",
    "                        lambda x: F.pad(\n",
    "                            Variable(x.unsqueeze(0), requires_grad=False),\n",
    "                            (4, 4, 4, 4),\n",
    "                            mode=\"reflect\",\n",
    "                        ).data.squeeze()\n",
    "                    ),\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.RandomCrop(32),\n",
    "                    transforms.ToTensor(),\n",
    "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"cifar100\":\n",
    "            print(\"in 100\")\n",
    "            dl_obj = CIFAR100_truncated\n",
    "            normalize = transforms.Normalize(\n",
    "                mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n",
    "                std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404],\n",
    "            )\n",
    "\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    # transforms.ToPILImage(),\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomRotation(15),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ]\n",
    "            )\n",
    "            # data prep for test set\n",
    "            transform_test = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "        elif dataset == \"tinyimagenet\":\n",
    "            dl_obj = ImageFolder_custom\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
    "                transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "                transforms.RandomRotation(15),  # Random rotation\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
    "            ])\n",
    "\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
    "            ])\n",
    "        elif dataset == \"stl10\":\n",
    "            dl_obj = STL10_truncated\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.Resize((SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"], SAFE_PFL_CONFIG[\"TRANSFORM_INPUT_SIZE\"])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        else:\n",
    "            dl_obj = Generated\n",
    "            transform_train = None\n",
    "            transform_test = None\n",
    "        if dataset == \"tinyimagenet\":\n",
    "            train_ds = dl_obj(\n",
    "                datadir + \"tiny-imagenet-200/train/\",\n",
    "                dataidxs=dataidxs,\n",
    "                transform=transform_train,\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir + \"tiny-imagenet-200/val/\",\n",
    "                dataidxs=testidxs,\n",
    "                transform=transform_test\n",
    "            )\n",
    "        elif dataset == \"stl10\":\n",
    "            train_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=dataidxs,\n",
    "                split=\"train\",\n",
    "                transform=transform_train,\n",
    "                download=True\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=testidxs,\n",
    "                split=\"test\",\n",
    "                transform=transform_test,\n",
    "                download=True\n",
    "            )\n",
    "        else:\n",
    "            print(\"dir\", datadir)\n",
    "            train_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=dataidxs,\n",
    "                train=True,\n",
    "                transform=transform_train,\n",
    "                download=True,\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=testidxs,\n",
    "                train=False,\n",
    "                transform=transform_test,\n",
    "                download=True,\n",
    "            )\n",
    "        train_dl = data.DataLoader(\n",
    "            dataset=train_ds, batch_size=train_bs, shuffle=True, drop_last=False\n",
    "        )\n",
    "        test_dl = data.DataLoader(\n",
    "            dataset=test_ds, batch_size=test_bs, shuffle=False, drop_last=False\n",
    "        )\n",
    "    return train_dl, test_dl, train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.337199Z",
     "start_time": "2025-02-01T15:34:58.330777Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.136620Z",
     "iopub.status.busy": "2025-01-12T01:55:34.136333Z",
     "iopub.status.idle": "2025-01-12T01:55:34.153399Z",
     "shell.execute_reply": "2025-01-12T01:55:34.152636Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.136591Z"
    },
    "id": "eizGyXaA3JuE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_loaders():\n",
    "    (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        net_dataidx_map,\n",
    "        test_dataidx_map,\n",
    "        traindata_cls_counts,\n",
    "    ) = partition_data(\n",
    "        dataset=SAFE_PFL_CONFIG[\"DATASET_TYPE\"],\n",
    "        datadir=\"./data/\",\n",
    "        logdir=\"./logs/\",\n",
    "        partition=SAFE_PFL_CONFIG[\"PARTITION\"],\n",
    "        n_parties=10,\n",
    "    )\n",
    "    train_loaders = []\n",
    "    test_loaders = []\n",
    "    for client_id in range(SAFE_PFL_CONFIG[\"NUMBER_OF_CLIENTS\"]):\n",
    "        dataidxs = net_dataidx_map[client_id]\n",
    "        testidxs = test_dataidx_map[client_id]\n",
    "\n",
    "        train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(\n",
    "            dataset=SAFE_PFL_CONFIG[\"DATASET_TYPE\"],\n",
    "            datadir=\"./data/\",\n",
    "            train_bs=SAFE_PFL_CONFIG[\"TRAIN_BATCH_SIZE\"],\n",
    "            test_bs=SAFE_PFL_CONFIG[\"TEST_BATCH_SIZE\"],\n",
    "            dataidxs=dataidxs,\n",
    "            testidxs=testidxs,\n",
    "        )\n",
    "        train_loaders.append(train_dl_local)\n",
    "        test_loaders.append(test_dl_local)\n",
    "\n",
    "    return train_loaders, test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:58.352471Z",
     "start_time": "2025-02-01T15:34:58.348457Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.154291Z",
     "iopub.status.busy": "2025-01-12T01:55:34.154045Z",
     "iopub.status.idle": "2025-01-12T01:55:34.166443Z",
     "shell.execute_reply": "2025-01-12T01:55:34.165775Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.154260Z"
    },
    "id": "-IvzdpYcxGZx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    train_loaders, test_loaders = get_loaders()\n",
    "    return train_loaders, test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:59.236021Z",
     "start_time": "2025-02-01T15:34:58.368023Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:55:34.167345Z",
     "iopub.status.busy": "2025-01-12T01:55:34.167107Z",
     "iopub.status.idle": "2025-01-12T01:57:34.302831Z",
     "shell.execute_reply": "2025-01-12T01:57:34.302034Z",
     "shell.execute_reply.started": "2025-01-12T01:55:34.167318Z"
    },
    "id": "ORJsNkg1xMY4",
    "outputId": "9769a96f-c6b6-46c1-ebf6-2eff0f483bf2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loaders, test_loaders = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CrFoxva3JuE"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Data Visualization & Silhouette</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.628185Z",
     "start_time": "2025-02-01T15:34:59.262895Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:57:34.329557Z",
     "iopub.status.busy": "2025-01-12T01:57:34.329338Z",
     "iopub.status.idle": "2025-01-12T01:57:34.339954Z",
     "shell.execute_reply": "2025-01-12T01:57:34.339325Z",
     "shell.execute_reply.started": "2025-01-12T01:57:34.329538Z"
    },
    "id": "TigBlX7z3JuE",
    "outputId": "31693f42-3347-4e01-e61c-3ab36ebfbdfb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_label_distribution(dataloader, loader_name: str):\n",
    "    label_counts = np.zeros(SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"])\n",
    "    for _, labels in dataloader:\n",
    "        for label in labels.numpy():\n",
    "            label_counts[label] += 1\n",
    "\n",
    "    log.info(f\"client {loader_name} label distribution is: {label_counts}\")\n",
    "    return label_counts\n",
    "\n",
    "\n",
    "def plot_client_distributions(distributions):\n",
    "    num_clients = len(distributions)\n",
    "    cols = 3\n",
    "    rows = (num_clients + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, label_counts in enumerate(distributions):\n",
    "        axes[i].bar(range(SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]), label_counts, color='skyblue')\n",
    "        axes[i].set_xlabel('Class Labels')\n",
    "        axes[i].set_ylabel('Number of Samples')\n",
    "        axes[i].set_title(f'Client {i}')\n",
    "        axes[i].set_xticks(range(SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]))\n",
    "        axes[i].set_xticklabels([f'Class {j}' for j in range(SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"])])\n",
    "        axes[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.suptitle('Label Distribution for Each Client')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_similarity_matrix(distributions):\n",
    "    similarity_matrix = cosine_similarity(distributions)\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def cluster_clients(similarity_matrix):\n",
    "    clustering = AffinityPropagation(affinity='precomputed', random_state=42)\n",
    "    clustering.fit(similarity_matrix)\n",
    "    return clustering.labels_\n",
    "\n",
    "\n",
    "def group_clients_by_cluster(labels):\n",
    "    clusters = {}\n",
    "    for client_id, cluster_id in enumerate(labels):\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(client_id)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def compute_silhouette_score(similarity_matrix, cluster_labels):\n",
    "    distance_matrix = 2 - (similarity_matrix + 1)\n",
    "    score = silhouette_score(distance_matrix, cluster_labels, metric='precomputed')\n",
    "    return score\n",
    "\n",
    "\n",
    "log.info(\"clients train loader label distribution\")\n",
    "train_label_distributions = [calculate_label_distribution(loader, \"train\") for loader in train_loaders]\n",
    "\n",
    "log.info(\"clients test loader label distribution\")\n",
    "test_label_distributions = [calculate_label_distribution(loader, \"test\") for loader in test_loaders]\n",
    "\n",
    "train_similarity_matrix = compute_similarity_matrix(train_label_distributions)\n",
    "test_similarity_matrix = compute_similarity_matrix(test_label_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.708501Z",
     "start_time": "2025-02-01T15:35:04.701360Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:57:34.341221Z",
     "iopub.status.busy": "2025-01-12T01:57:34.340933Z",
     "iopub.status.idle": "2025-01-12T01:57:34.357306Z",
     "shell.execute_reply": "2025-01-12T01:57:34.356553Z",
     "shell.execute_reply.started": "2025-01-12T01:57:34.341190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cluster_labels = cluster_clients(train_similarity_matrix)\n",
    "# log.info(\"Clients train loader clustering label based on their dataset\")\n",
    "# log.info(cluster_labels)\n",
    "# clusters = group_clients_by_cluster(cluster_labels)\n",
    "# log.info(\"Clients train loader clustering based on their dataset\")\n",
    "# log.info(clusters)\n",
    "\n",
    "# cluster_labels = cluster_clients(test_similarity_matrix)\n",
    "# log.info(\"Clients test loader clustering label based on their dataset\")\n",
    "# log.info(cluster_labels)\n",
    "# clusters = group_clients_by_cluster(cluster_labels)\n",
    "# log.info(\"Clients test loader clustering based on their dataset\")\n",
    "# log.info(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.727604Z",
     "start_time": "2025-02-01T15:35:04.724505Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T01:57:34.358286Z",
     "iopub.status.busy": "2025-01-12T01:57:34.358066Z",
     "iopub.status.idle": "2025-01-12T01:57:34.376974Z",
     "shell.execute_reply": "2025-01-12T01:57:34.376224Z",
     "shell.execute_reply.started": "2025-01-12T01:57:34.358257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# silhouette_cosine = compute_silhouette_score(similarity_matrix, [0, 1, 0, 2, 2, 3, 3, 3, 2, 1])\n",
    "# print(f\"Silhouette score for data clustering is: {silhouette_cosine}\")\n",
    "\n",
    "# silhouette_cosine = compute_silhouette_score(similarity_matrix, [2, 0, 1, 1, 1, 1, 2, 2, 1, 0,])\n",
    "# print(f\"Silhouette score for cosine is: {silhouette_cosine}\")\n",
    "\n",
    "# silhouette_cosine_less_sig_pruned = compute_silhouette_score(similarity_matrix, [0, 3, 0, 1, 1, 3, 2, 2, 3, 3,])\n",
    "# print(f\"Silhouette score for cosine (optimal) common less sig pruned is: {silhouette_cosine_less_sig_pruned}\")\n",
    "\n",
    "# silhouette_coordinate = compute_silhouette_score(similarity_matrix, [0, 3, 0, 1, 1, 3, 2, 2, 0, 3,])\n",
    "# print(f\"Silhouette score for coordinate is: {silhouette_coordinate}\")\n",
    "\n",
    "# silhouette_euclidean = compute_silhouette_score(similarity_matrix, [3, 0, 3, 1, 0, 3, 3, 3, 2, 0,])\n",
    "# print(f\"Silhouette score for euclidean is: {silhouette_euclidean}\")\n",
    "\n",
    "# silhouette_wasserstein = compute_silhouette_score(similarity_matrix, [2, 0, 2, 2, 2, 0, 2, 2, 1, 0,])\n",
    "# print(f\"Silhouette score for wasserstein is: {silhouette_wasserstein}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFgZGqbk3JuE"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Utils</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.785720Z",
     "start_time": "2025-02-01T15:35:04.777426Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorise_model(model):\n",
    "    return Params2Vec(model.parameters())\n",
    "\n",
    "def display_train_stats(cfl_stats, communication_rounds, output_clarence_status=False):\n",
    "    if output_clarence_status:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    acc_mean = np.mean(cfl_stats.acc_clients, axis=1)\n",
    "    acc_std = np.std(cfl_stats.acc_clients, axis=1)\n",
    "    plt.fill_between(\n",
    "        cfl_stats.rounds, acc_mean - acc_std, acc_mean + acc_std, alpha=0.5, color=\"C0\"\n",
    "    )\n",
    "    plt.plot(cfl_stats.rounds, acc_mean, color=\"C0\")\n",
    "\n",
    "    if \"split\" in cfl_stats.__dict__:\n",
    "        for s in cfl_stats.split:\n",
    "            plt.axvline(x=s, linestyle=\"-\", color=\"k\", label=r\"Split\")\n",
    "\n",
    "    plt.text(\n",
    "        x=communication_rounds,\n",
    "        y=1,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        s=\"Clusters: {}\".format([x for x in cfl_stats.clusters[-1]]),\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Communication Rounds\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.xlim(0, communication_rounds)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class ExperimentLogger:\n",
    "    def log(self, values):\n",
    "        for k, v in values.items():\n",
    "            if k not in self.__dict__:\n",
    "                self.__dict__[k] = [v]\n",
    "            else:\n",
    "                self.__dict__[k] += [v]\n",
    "\n",
    "\n",
    "def copy(target, source):\n",
    "    for name in target:\n",
    "        target[name].data = source[name].data.clone()\n",
    "\n",
    "\n",
    "def subtract_(target, minuend, subtrahend):\n",
    "    for name in target:\n",
    "        target[name].data = minuend[name].data.clone() - subtrahend[name].data.clone()\n",
    "\n",
    "\n",
    "def reduce_add_average(targets, sources):\n",
    "    for target in targets:\n",
    "        for name in target:\n",
    "            tmp = torch.mean(\n",
    "                torch.stack([source[name].data for source in sources]), dim=0\n",
    "            ).clone()\n",
    "            target[name].data += tmp / len(sources)\n",
    "\n",
    "\n",
    "def visualize_clusters(similarities, labels):\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    sns.heatmap(similarities, annot=True, cmap=\"viridis\")\n",
    "    plt.title(f\"Cluster Labels: {labels}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def flatten(source):\n",
    "    return torch.cat([value.flatten() for value in source.values()])\n",
    "\n",
    "\n",
    "def pairwise_cosine_similarity(clients):\n",
    "    model_vectors = [vectorise_model(client.model).detach().cpu().numpy() \n",
    "                    for client in clients]\n",
    "\n",
    "    n = len(clients)\n",
    "    similarities = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        vi = model_vectors[i]\n",
    "        norm_i = np.linalg.norm(vi)\n",
    "        \n",
    "        for j in range(n):\n",
    "            vj = model_vectors[j]\n",
    "            norm_j = np.linalg.norm(vj)\n",
    "            if norm_i == 0 or norm_j == 0:\n",
    "                similarities[i][j] = 0.0\n",
    "            else:\n",
    "                similarities[i][j] = np.dot(vi, vj) / (norm_i * norm_j)\n",
    "\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def pairwise_coordinate_similarity(gradients):\n",
    "    _top_sensitive_gradients = []\n",
    "\n",
    "    for index, grads in enumerate(gradients):\n",
    "\n",
    "        _top_gradients_count = int(\n",
    "            np.ceil(SAFE_PFL_CONFIG[\"SENSITIVITY_PERCENTAGE\"] * len(grads) / 100)\n",
    "        )\n",
    "\n",
    "        _sorted_grads_with_ids = sorted(\n",
    "            grads.items(), key=lambda item: item[1], reverse=True\n",
    "        )\n",
    "\n",
    "        _top_sensitive_gradients.append(\n",
    "            [key[1] for key, value in _sorted_grads_with_ids[:_top_gradients_count]]\n",
    "        )\n",
    "\n",
    "        log.info(\n",
    "            f\"the length of top gradients for client {index} is : {len(_sorted_grads_with_ids[:_top_gradients_count])}\"\n",
    "        )\n",
    "\n",
    "    gradients_length = len(gradients)\n",
    "    del gradients\n",
    "\n",
    "    assert len(_top_sensitive_gradients) == gradients_length\n",
    "\n",
    "    _similarities = np.zeros((gradients_length, gradients_length))\n",
    "    for i in range(gradients_length):\n",
    "        for j in range(i + 1, gradients_length):\n",
    "            i_values = _top_sensitive_gradients[i]\n",
    "            j_values = _top_sensitive_gradients[j]\n",
    "            assert len(i_values) == len(j_values)\n",
    "\n",
    "            _similarity = len(set(i_values).intersection(set(j_values)))\n",
    "\n",
    "            _similarities[i][j] = _similarity\n",
    "            _similarities[j][i] = _similarity\n",
    "\n",
    "    _top_sensitive_gradients = []\n",
    "    return _similarities\n",
    "\n",
    "\n",
    "def pairwise_wasserstein_similarity(clients):\n",
    "    updates = [flatten(client.W).detach().cpu().numpy() for client in clients]\n",
    "\n",
    "    distances = np.zeros((len(clients), len(clients)))\n",
    "\n",
    "    for i in range(len(clients)):\n",
    "        for j in range(len(clients)):\n",
    "            distances[i][j] = wasserstein_distance(updates[i], updates[j])\n",
    "\n",
    "    similarities = 1 / (1 + distances)\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def pairwise_euclidean_similarity(clients):\n",
    "    updates = [flatten(client.W).detach().cpu().numpy() for client in clients]\n",
    "\n",
    "    n = len(clients)\n",
    "    similarities = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distance = np.linalg.norm(updates[i] - updates[j])\n",
    "\n",
    "            similarities[i][j] = 1 / (1 + distance)\n",
    "\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def eval_op(model, loader):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total = 0, 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train_op(model, loader, optimizer, epochs=1):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if epoch > 1:\n",
    "            log.info(f\"[{epoch + 1}] loss: {running_loss / len(loader):.3f}\")\n",
    "\n",
    "    return model, running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Federated Learning Components</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedTrainingDevice(object):\n",
    "    def __init__(self, model_fn):\n",
    "        self.model = model_fn(\n",
    "            SAFE_PFL_CONFIG[\"MODEL_TYPE\"], SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def evaluate(self):\n",
    "        _loss, _accuracy = eval_op(self.model, self.eval_loader)\n",
    "\n",
    "        if _loss < 1.0 and _accuracy > 0.6:\n",
    "            log.info(\n",
    "                f\"testing done for client no {self.id} with accuracy of {_accuracy} and loss of {_loss} [GOOD]\"\n",
    "            )\n",
    "        elif _loss < 2.0 and _accuracy > 0.4:\n",
    "            log.warn(\n",
    "                f\"testing done for client no {self.id} with accuracy of {_accuracy} and loss of {_loss} [MODERATE]\"\n",
    "            )\n",
    "        else:\n",
    "            log.warn(\n",
    "                f\"testing done for client no {self.id} with accuracy of {_accuracy} and loss of {_loss} [POOR]\"\n",
    "            )\n",
    "\n",
    "        return _accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.796267Z",
     "start_time": "2025-02-01T15:35:04.789231Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client(FederatedTrainingDevice):\n",
    "    def __init__(\n",
    "        self, model_fn, optimizer_fn, id_num, train_data_loader, evaluation_data_loader\n",
    "    ):\n",
    "        super().__init__(model_fn)\n",
    "        self.optimizer = optimizer_fn(self.model.parameters())\n",
    "\n",
    "        self.train_loader = train_data_loader\n",
    "        self.eval_loader = evaluation_data_loader\n",
    "\n",
    "        self.id = id_num\n",
    "\n",
    "        log.info(f\"client no: {self.id} initialized\")\n",
    "\n",
    "    def synchronize_with_server(self, server):\n",
    "        self.model.load_state_dict(server.model.state_dict())\n",
    "\n",
    "    def compute_weight_update(\n",
    "        self,\n",
    "        be_ready_for_clustering,\n",
    "        epochs=SAFE_PFL_CONFIG[\"ROUND_EPOCHS\"],\n",
    "        loader=None,\n",
    "    ):\n",
    "        self.model, train_stats = train_op(\n",
    "            self.model,\n",
    "            self.train_loader if not loader else loader,\n",
    "            self.optimizer,\n",
    "            epochs,\n",
    "        )\n",
    "\n",
    "        log.info(f\"training done for client no {self.id} with loss of {train_stats}\")\n",
    "\n",
    "        gradients = {}\n",
    "\n",
    "        if be_ready_for_clustering:\n",
    "            log.info(\"analyzing the gradients...\")\n",
    "            inputs, labels = next(iter(self.train_loader))\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            _model = py_copy.deepcopy(self.model)\n",
    "            inputs.requires_grad = True\n",
    "            outputs = _model(inputs)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            _model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            for name, parameter in _model.named_parameters():\n",
    "                if (\n",
    "                    # \"bias\" not in name #!!! DO NOT UNCOMMENT THIS!!!\n",
    "                    parameter.requires_grad\n",
    "                    and parameter.grad is not None\n",
    "                ):\n",
    "                    grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
    "                    for i, grad in enumerate(grads):\n",
    "                        gradients[(name, i)] = grad\n",
    "\n",
    "            log.info(f\"analyzing the gradients done with length of {len(gradients)}\")\n",
    "            del _model\n",
    "        return train_stats, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:04.813075Z",
     "start_time": "2025-02-01T15:35:04.807060Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server(FederatedTrainingDevice):\n",
    "    def __init__(self, model_fn):\n",
    "        super().__init__(model_fn)\n",
    "        self.model_cache = []\n",
    "        self.last_participating_clients = []\n",
    "\n",
    "    def select_clients(self, clients, frac=1.0):\n",
    "        return sorted(clients, key=lambda x: x.id)[: int(len(clients) * frac)]\n",
    "\n",
    "    def compute_pairwise_similarities(self, grads):\n",
    "        if SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"] == distances_constants.DISTANCE_COSINE:\n",
    "            return pairwise_cosine_similarity(self.last_participating_clients) #! cosine on parameters\n",
    "        elif (\n",
    "            SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"]\n",
    "            == distances_constants.DISTANCE_COORDINATE\n",
    "        ):\n",
    "            return pairwise_coordinate_similarity(grads)\n",
    "        elif (\n",
    "            SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"]\n",
    "            == distances_constants.DISTANCE_WASSERSTEIN\n",
    "        ):\n",
    "            return pairwise_wasserstein_similarity(grads)\n",
    "        elif (\n",
    "            SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"] == distances_constants.DISTANCE_EUCLIDEAN\n",
    "        ):\n",
    "            return pairwise_euclidean_similarity(grads)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'unsupported distance metric {SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"]}'\n",
    "            )\n",
    "\n",
    "    def cluster_clients(self, similarities):\n",
    "\n",
    "        log.info(\"similarity matrix is that feeds the clustering\")\n",
    "        log.info(similarities)\n",
    "\n",
    "        clustering = AffinityPropagation(\n",
    "            affinity=\"precomputed\",\n",
    "            random_state=42,\n",
    "        ).fit(similarities)\n",
    "\n",
    "        del similarities\n",
    "        log.info(f\"Cluster labels: {clustering.labels_}\")\n",
    "\n",
    "        return clustering\n",
    "\n",
    "    def aggregate(self, models):\n",
    "        print(\"model numbers:\", len(models))\n",
    "\n",
    "        device = next(models[0].parameters()).device\n",
    "        for model in models:\n",
    "            model.to(device)\n",
    "        avg_model = Net(\n",
    "            SAFE_PFL_CONFIG[\"MODEL_TYPE\"], SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for param_name, avg_param in avg_model.named_parameters():\n",
    "                temp = torch.zeros_like(avg_param)\n",
    "                for model in models:\n",
    "                    model_param = dict(model.named_parameters())[param_name]\n",
    "                    temp += model_param.data\n",
    "                avg_param.copy_(temp / len(models))\n",
    "        return avg_model\n",
    "\n",
    "    def aggregate_clusterwise(self, client_clusters):\n",
    "        for cluster in client_clusters:\n",
    "            if len(cluster) < 2:\n",
    "                continue\n",
    "\n",
    "            idcs = [client.id for client in cluster]\n",
    "            log.info(f\"Aggregating clients: {idcs}\")\n",
    "\n",
    "            cluster_models = [client.model for client in cluster]\n",
    "\n",
    "            avg_model = self.aggregate(cluster_models)\n",
    "\n",
    "            for client in cluster:\n",
    "                client.model.load_state_dict(avg_model.state_dict())\n",
    "\n",
    "    def cache_model(self, idc, params, accuracies):\n",
    "        self.model_cache += [\n",
    "            (\n",
    "                idc,\n",
    "                {name: params[name].data.clone() for name in params},\n",
    "                [accuracies[i] for i in idc],\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Calculating Optimal Sensitivity Percentage (A.K.A `P`)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cosine_similarity(base_weights, model_weights):\n",
    "    \"\"\"Calculate the cosine similairty between two vectors\"\"\"\n",
    "    return torch.nan_to_num(\n",
    "        torch.clip(\n",
    "            torch.dot(base_weights, model_weights)\n",
    "            / (torch.linalg.norm(base_weights) * torch.linalg.norm(model_weights)),\n",
    "            -1,\n",
    "            1,\n",
    "        ),\n",
    "        0,\n",
    "    )\n",
    "\n",
    "def global_prune_without_masks(model, amount):\n",
    "    \"\"\"Global Unstructured Pruning of model.\"\"\"\n",
    "    parameters_to_prune = []\n",
    "    for mod in model.modules():\n",
    "        if hasattr(mod, \"weight\"):\n",
    "            if isinstance(mod.weight, torch.nn.Parameter):\n",
    "                parameters_to_prune.append((mod, \"weight\"))\n",
    "        if hasattr(mod, \"bias\"):\n",
    "            if isinstance(mod.bias, torch.nn.Parameter):\n",
    "                parameters_to_prune.append((mod, \"bias\"))\n",
    "    parameters_to_prune = tuple(parameters_to_prune)\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=amount,\n",
    "    )\n",
    "    for mod in model.modules():\n",
    "        if hasattr(mod, \"weight_orig\"):\n",
    "            if isinstance(mod.weight_orig, torch.nn.Parameter):\n",
    "                prune.remove(mod, \"weight\")\n",
    "        if hasattr(mod, \"bias_orig\"):\n",
    "            if isinstance(mod.bias_orig, torch.nn.Parameter):\n",
    "                prune.remove(mod, \"bias\")\n",
    "\n",
    "\n",
    "def calculate_optimal_sensitivity_percentage(example_client_model):\n",
    "    prune_rate = torch.linspace(0, 1, 101)\n",
    "    cosine_sim = []\n",
    "    base_vec = vectorise_model(example_client_model)\n",
    "    prune_net = Net(\n",
    "        SAFE_PFL_CONFIG[\"MODEL_TYPE\"], SAFE_PFL_CONFIG[\"NUMBER_OF_CLASSES\"]\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    for p in prune_rate:\n",
    "        p = float(p)\n",
    "        prune_net.load_state_dict(example_client_model.state_dict())\n",
    "        global_prune_without_masks(prune_net, p)\n",
    "        prune_net_vec = vectorise_model(prune_net)\n",
    "        cosine_sim.append(cosine_similarity(base_vec, prune_net_vec).item())\n",
    "\n",
    "    c = torch.vstack((torch.Tensor(cosine_sim), prune_rate))\n",
    "    d = c.T\n",
    "    dists = []\n",
    "    for i in d:\n",
    "        dists.append(torch.dist(i, torch.Tensor([1, 1])))\n",
    "    min = torch.argmin(torch.Tensor(dists))\n",
    "    \n",
    "    del dists\n",
    "\n",
    "    plt.plot(prune_rate, cosine_sim, label=f'{SAFE_PFL_CONFIG[\"MODEL_TYPE\"]} Parateo Front')\n",
    "    plt.xlim(0, 1.05)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.scatter(1, 1, label=\"Utopia\", c=\"red\", marker=\"*\", s=150)\n",
    "    plt.scatter(\n",
    "        prune_rate[min], cosine_sim[min], color=\"k\", marker=\"o\", label=\"Optima\"\n",
    "    )\n",
    "    plt.xlabel(xlabel=\"pruning rate\")\n",
    "    plt.ylabel(ylabel=\"cosine similarity\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    del cosine_sim\n",
    "    del base_vec\n",
    "    del prune_net\n",
    "\n",
    "    optimal_sensitivity_percentage = (1.0 - prune_rate[min]) * 100\n",
    "    del prune_rate\n",
    "\n",
    "    return optimal_sensitivity_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Executing</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:05.183145Z",
     "start_time": "2025-02-01T15:35:04.826590Z"
    }
   },
   "outputs": [],
   "source": [
    "client_list = [i for i in range(SAFE_PFL_CONFIG[\"NUMBER_OF_CLIENTS\"])]\n",
    "assert len(client_list) == SAFE_PFL_CONFIG[\"NUMBER_OF_CLIENTS\"]\n",
    "\n",
    "clients = [Client(\n",
    "    Net,\n",
    "    # lambda x : torch.optim.Adam(x, lr=SAFE_PFL_CONFIG[\"LEARNING_RATE\"]),\n",
    "    lambda x : torch.optim.SGD(x, lr=0.001, momentum=0.9),  #! we have to use SGD since our base papers also tested their methods via SGD\n",
    "    i,\n",
    "    train_loaders[i],\n",
    "    test_loaders[i]\n",
    "    ) for i in client_list]\n",
    "\n",
    "server = Server(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:05.826887Z",
     "start_time": "2025-02-01T15:35:05.201153Z"
    }
   },
   "outputs": [],
   "source": [
    "for client in [clients[0], clients[3]]:\n",
    "    x, y = next(iter(client.train_loader))\n",
    "\n",
    "    log.info(\"Client {}:\".format(client.id))\n",
    "    plt.figure(figsize=(15,1))\n",
    "    for i in range(10):\n",
    "        plt.subplot(1,10,i+1)\n",
    "        plt.imshow(x[i,0].numpy().T, cmap=\"Greys\")\n",
    "\n",
    "    del x\n",
    "    del y\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:35:26.201255Z",
     "start_time": "2025-02-01T15:35:05.860359Z"
    }
   },
   "outputs": [],
   "source": [
    "cfl_stats = ExperimentLogger()\n",
    "cluster_indices = [np.arange(len(clients)).astype(\"int\")]\n",
    "participating_clients_grads = []\n",
    "\n",
    "for c_round in range(1, SAFE_PFL_CONFIG[\"FEDERATED_LEARNING_ROUNDS\"] + 1):\n",
    "    if c_round == 1:\n",
    "        for client in clients:\n",
    "            client.synchronize_with_server(server)\n",
    "\n",
    "    TRIGGER_CLUSTERING = c_round % SAFE_PFL_CONFIG[\"CLUSTERING_PERIOD\"] == 0\n",
    "\n",
    "    participating_clients = server.select_clients(clients, frac=1.0)\n",
    "    for index, client in enumerate(participating_clients):\n",
    "        _, grads = client.compute_weight_update(\n",
    "            be_ready_for_clustering=TRIGGER_CLUSTERING,\n",
    "            epochs=SAFE_PFL_CONFIG[\"ROUND_EPOCHS\"],\n",
    "        )\n",
    "        if len(grads) != 0:\n",
    "            participating_clients_grads.append(grads)\n",
    "\n",
    "    if (\n",
    "        c_round == 1\n",
    "        and SAFE_PFL_CONFIG[\"DISTANCE_METRIC\"]\n",
    "        == distances_constants.DISTANCE_COORDINATE\n",
    "        and SAFE_PFL_CONFIG[\"DYNAMIC_SENSITIVITY_PERCENTAGE\"]\n",
    "    ):\n",
    "        log.info(\"starting calculating optimal sensitivity percentage...\")\n",
    "        SAFE_PFL_CONFIG.update(\n",
    "            {\n",
    "                \"SENSITIVITY_PERCENTAGE\": calculate_optimal_sensitivity_percentage(\n",
    "                    clients[0].model\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        log.info(\n",
    "            f'done calculating optimal sensitivity percentage with value of {SAFE_PFL_CONFIG[\"SENSITIVITY_PERCENTAGE\"]}'\n",
    "        )\n",
    "\n",
    "    server.last_participating_clients = participating_clients.copy()\n",
    "\n",
    "    if TRIGGER_CLUSTERING:\n",
    "        full_similarities = server.compute_pairwise_similarities(\n",
    "            participating_clients_grads\n",
    "        )\n",
    "        participating_clients_grads = []\n",
    "        log.warn(f\"Global clustering triggered {c_round}\")\n",
    "        log.info(\"similarity matrix\")\n",
    "        log.info(full_similarities)\n",
    "\n",
    "        clustering = server.cluster_clients(full_similarities)\n",
    "        del full_similarities\n",
    "\n",
    "        cluster_indices = []\n",
    "        for label in np.unique(clustering.labels_):\n",
    "            cluster_indices.append(np.where(clustering.labels_ == label)[0].tolist())\n",
    "\n",
    "        if SAFE_PFL_CONFIG[\"SAVE_BEFORE_AGGREGATION_MODELS\"]:\n",
    "            for client in participating_clients:\n",
    "                torch.save(\n",
    "                    client.model.state_dict(),\n",
    "                    MODEL_SAVING_PATH + f\"client_{client.id}_model.pt\",\n",
    "                )\n",
    "\n",
    "    client_clusters = [\n",
    "        [server.last_participating_clients[i] for i in idc] for idc in cluster_indices\n",
    "    ]\n",
    "\n",
    "    acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "    server.aggregate_clusterwise(client_clusters)\n",
    "\n",
    "    cfl_stats.log(\n",
    "        {\n",
    "            \"acc_clients\": acc_clients,\n",
    "            \"rounds\": c_round,\n",
    "            \"clusters\": cluster_indices,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    display_train_stats(\n",
    "        cfl_stats,\n",
    "        SAFE_PFL_CONFIG[\"FEDERATED_LEARNING_ROUNDS\"],\n",
    "        output_clarence_status=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6072062,
     "sourceId": 9887519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
