{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets lxml TinyImageNet --quiet"
      ],
      "metadata": {
        "id": "Rq2Q6uNyOTqD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q-BrQQneGVnm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from scipy.stats import wasserstein_distance\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import csv\n",
        "import gc\n",
        "import logging\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "import tarfile\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from math import sqrt\n",
        "from typing import Callable, List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from scipy.spatial.distance import cosine, euclidean, jensenshannon\n",
        "from scipy.stats import wasserstein_distance\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tinyimagenet import TinyImageNet\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.model_zoo import tqdm\n",
        "from torchvision.datasets import (CIFAR10, CIFAR100, MNIST, STL10, SVHN,\n",
        "                                  DatasetFolder, FashionMNIST, ImageFolder)\n",
        "from torchvision.datasets.utils import (check_integrity,\n",
        "                                        download_file_from_google_drive)\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.transforms import Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yd_BwJT5pGnQ"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XgHnSmfhG4zF"
      },
      "outputs": [],
      "source": [
        "def get_top_values(arr, p):\n",
        "    # Ensure p is a valid percentage\n",
        "    if not (0 <= p <= 100):\n",
        "        raise ValueError(\"Percentage p must be between 0 and 100.\")\n",
        "\n",
        "    # Calculate the number of elements to retain\n",
        "    num_elements_to_retain = int(len(arr) * (100 - p) / 100)\n",
        "\n",
        "    # If num_elements_to_retain is 0, return an empty array\n",
        "    if num_elements_to_retain == 0:\n",
        "        return np.array([])\n",
        "\n",
        "    # Find the indices of the largest num_elements_to_retain elements\n",
        "    indices_to_retain = np.argpartition(arr, -num_elements_to_retain)[-num_elements_to_retain:]\n",
        "\n",
        "    # Return only the top (100-p)% of elements\n",
        "    return arr[indices_to_retain]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z9fUzKUD19yC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "|MODEL_TYPE |  DATASET_TYPE    | NUMBER_OF_CLASSES| PARTITION      | ROUND_EPOCHS| SENSITIVITY_PERCENTAGE   | TRAIN/TEST_BATCH_SIZE | TRANSFORM_INPUT_SIZE  |\n",
        "|-----------|------------------|------------------|----------------|-------------|--------------------------|-----------------------|-----------------------|\n",
        "|cnn        |  fmnist          | 10               | noniid-#label2 | 1           | 10                       | 128                   | 128                   |\n",
        "|resnet18   |  cifar10         | 10               | noniid-#label2 | 1           | 10                       | 128                   | 128                   |\n",
        "|resnet50   |  cifar100        | 100              | noniid-#label20| 10          | 10                       | 128                   | 32                    |\n",
        "|mobilenet  |  svhn            | 10               | noniid-#label2 | 1           | 10                       | 64                    | 224                   |\n",
        "|alexnet    |  stl10           | 10               | noniid-#label10| 10          | 10                       | 128                    | 128                   |\n",
        "|-----------|------------------|------------------|----------------|-------------|--------------------------|-----------------------|-----------------------|\n",
        "\"\"\"\n",
        "\"\"\" LEARNING HYPERPARAMETERS\"\"\"\n",
        "MODEL_TYPE = \"alexnet\"\n",
        "TRAIN_BATCH_SIZE=128\n",
        "TEST_BATCH_SIZE=128\n",
        "# by default set to 0.001 and for AlexNet set to 0.0001\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY=1e-4\n",
        "NUMBER_OF_CLIENTS = 10\n",
        "# set to 10 for AlexNet\n",
        "ROUND_EPOCHS = 6\n",
        "\"\"\" DATA DISTRIBUTION \"\"\"\n",
        "DATASET_TYPE = \"svhn\"\n",
        "PARTITION = \"noniid-\" + \"fix\"       # the second part accepted format is: \"labeldir\" (Dirichlet), \"#label20\", noniid-fix\n",
        "DIRICHLET_BETA=0.1\n",
        "NUMBER_OF_CLASSES = 10\n",
        "TRANSFORM_INPUT_SIZE=128    # just works for svhn/stl10 dataset transformer\n",
        "DESIRED_DISTRIBUTION = [\n",
        "            [2948,    0, 5293,    0,    0,    0,    0,    0,    0,    0],\n",
        "            [   0, 3466, 2330,    0,    0,    0,    0,    0,    0,    0],\n",
        "            [2000,    0, 5292,    0,    0,    0,    0,    0,    0,    0],\n",
        "            [   0,    0,    0, 4249, 3729,    0,    0,    0,    0,    0],\n",
        "            [   0,    0,    0,    0, 3729,    0, 2465,    0,    0,    0],\n",
        "            [   0,    0,    0, 3720,    0,    0, 2145,    0,    0,    0],\n",
        "            [   0,    0,    0,    0,    0, 3865, 2864,    0,    0,    0],\n",
        "            [   0,    0,    0,    0,    0,    0,    0, 1865, 2863,    0],\n",
        "            [   0,    0,    0,    0,    0,    0,    0,    0, 5045, 3248],\n",
        "            [   0,    0,    0,    0,    0,    0,    0, 3465,    0, 1329]\n",
        "        ]\n",
        "\n",
        "\"\"\"\n",
        "SAFE-PFL\n",
        "DISTANCE_METRIC values are:\n",
        "- coordinate\n",
        "- cosine\n",
        "- euclidean\n",
        "- jensen-shannon\n",
        "- wasserstein\n",
        "\"\"\"\n",
        "SAVE_BEFORE_AGGREGATION_MODELS=True\n",
        "DO_CLUSTER=True\n",
        "CLUSTERING_PERIOD = 1           # Set to 1 to run simple Federated Learning with out clustering\n",
        "FEDERATED_LEARNING_ROUNDS = 1   # The round in with Federated Learning will be executed\n",
        "# set to 20 for ResNet50\n",
        "SENSITIVITY_PERCENTAGE = 10\n",
        "DISTANCE_METRIC = \"coordinate\"\n",
        "# cosine similarity options\n",
        "JUST_COMPARE_SIGNIFICANCE=False\n",
        "ZERO_INSIGNIFICANT_IN_BOTH=False\n",
        "COMPARE_MOST_SIGNIFICANCE_ONE=False\n",
        "COMPARE_LESS_SIGNIFICANCE_ZERO=False   # Set to True for Selective Parameter Cosine when DISTANCE_METRIC is cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwY1QBDkJfk3"
      },
      "source": [
        "# Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yhn15HPNLN9H"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "IMG_EXTENSIONS = (\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".png\",\n",
        "    \".ppm\",\n",
        "    \".bmp\",\n",
        "    \".pgm\",\n",
        "    \".tif\",\n",
        "    \".tiff\",\n",
        "    \".webp\",\n",
        ")\n",
        "\n",
        "\n",
        "def mkdirs(dirpath):\n",
        "    try:\n",
        "        os.makedirs(dirpath)\n",
        "    except Exception as _:\n",
        "        pass\n",
        "\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, \"rb\") as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert(\"RGB\")\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "\n",
        "    if get_image_backend() == \"accimage\":\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "class CustomTensorDataset(data.TensorDataset):\n",
        "    def __getitem__(self, index):\n",
        "        return tuple(tensor[index] for tensor in self.tensors) + (index,)\n",
        "\n",
        "\n",
        "class MNIST_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        mnist_dataobj = MNIST(\n",
        "            self.root, self.train, self.transform, self.target_transform, self.download\n",
        "        )\n",
        "\n",
        "        data = mnist_dataobj.data\n",
        "        target = mnist_dataobj.targets\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class FashionMNIST_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        mnist_dataobj = FashionMNIST(\n",
        "            self.root, self.train, self.transform, self.target_transform, self.download\n",
        "        )\n",
        "\n",
        "        data = mnist_dataobj.data\n",
        "        target = mnist_dataobj.targets\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class SVHN_custom(data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "        if self.train is True:\n",
        "\n",
        "            svhn_dataobj = SVHN(\n",
        "                self.root, \"train\", self.transform, self.target_transform, self.download\n",
        "            )\n",
        "            data = svhn_dataobj.data\n",
        "            target = svhn_dataobj.labels\n",
        "        else:\n",
        "            svhn_dataobj = SVHN(\n",
        "                self.root, \"test\", self.transform, self.target_transform, self.download\n",
        "            )\n",
        "            data = svhn_dataobj.data\n",
        "            target = svhn_dataobj.labels\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "# torchvision CelebA\n",
        "class CelebA_custom(VisionDataset):\n",
        "    \"\"\"`Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where images are downloaded to.\n",
        "        split (string): One of {'train', 'valid', 'test', 'all'}.\n",
        "            Accordingly dataset is selected.\n",
        "        target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
        "            or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
        "            The targets represent:\n",
        "                ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
        "                ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
        "                ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
        "                ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
        "                    righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
        "            Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "    \"\"\"\n",
        "\n",
        "    base_folder = \"celeba\"\n",
        "    # There currently does not appear to be a easy way to extract 7z in python (without introducing additional\n",
        "    # dependencies). The \"in-the-wild\" (not aligned+cropped) images are only in 7z, so they are not available\n",
        "    # right now.\n",
        "    file_list = [\n",
        "        # File ID                         MD5 Hash                            Filename\n",
        "        (\n",
        "            \"0B7EVK8r0v71pZjFTYXZWM3FlRnM\",\n",
        "            \"00d2c5bc6d35e252742224ab0c1e8fcb\",\n",
        "            \"img_align_celeba.zip\",\n",
        "        ),\n",
        "        # (\"0B7EVK8r0v71pbWNEUjJKdDQ3dGc\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_align_celeba_png.7z\"),\n",
        "        # (\"0B7EVK8r0v71peklHb0pGdDl6R28\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_celeba.7z\"),\n",
        "        (\n",
        "            \"0B7EVK8r0v71pblRyaVFSWGxPY0U\",\n",
        "            \"75e246fa4810816ffd6ee81facbd244c\",\n",
        "            \"list_attr_celeba.txt\",\n",
        "        ),\n",
        "        (\n",
        "            \"1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\",\n",
        "            \"32bd1bd63d3c78cd57e08160ec5ed1e2\",\n",
        "            \"identity_CelebA.txt\",\n",
        "        ),\n",
        "        (\n",
        "            \"0B7EVK8r0v71pbThiMVRxWXZ4dU0\",\n",
        "            \"00566efa6fedff7a56946cd1c10f1c16\",\n",
        "            \"list_bbox_celeba.txt\",\n",
        "        ),\n",
        "        (\n",
        "            \"0B7EVK8r0v71pd0FJY3Blby1HUTQ\",\n",
        "            \"cc24ecafdb5b50baae59b03474781f8c\",\n",
        "            \"list_landmarks_align_celeba.txt\",\n",
        "        ),\n",
        "        # (\"0B7EVK8r0v71pTzJIdlJWdHczRlU\", \"063ee6ddb681f96bc9ca28c6febb9d1a\", \"list_landmarks_celeba.txt\"),\n",
        "        (\n",
        "            \"0B7EVK8r0v71pY0NSMzRuSXJEVkk\",\n",
        "            \"d32c9cbf5e040fd4025c592c306e6668\",\n",
        "            \"list_eval_partition.txt\",\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        split=\"train\",\n",
        "        target_type=\"attr\",\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "        import pandas\n",
        "\n",
        "        super(CelebA_custom, self).__init__(\n",
        "            root, transform=transform, target_transform=target_transform\n",
        "        )\n",
        "        self.split = split\n",
        "        if isinstance(target_type, list):\n",
        "            self.target_type = target_type\n",
        "        else:\n",
        "            self.target_type = [target_type]\n",
        "\n",
        "        if not self.target_type and self.target_transform is not None:\n",
        "            raise RuntimeError(\"target_transform is specified but target_type is empty\")\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\n",
        "                \"Dataset not found or corrupted.\"\n",
        "                + \" You can use download=True to download it\"\n",
        "            )\n",
        "\n",
        "        split_map = {\n",
        "            \"train\": 0,\n",
        "            \"valid\": 1,\n",
        "            \"test\": 2,\n",
        "            \"all\": None,\n",
        "        }\n",
        "        split = split_map[split.lower()]\n",
        "\n",
        "        fn = partial(os.path.join, self.root, self.base_folder)\n",
        "        splits = pandas.read_csv(\n",
        "            fn(\"list_eval_partition.txt\"),\n",
        "            delim_whitespace=True,\n",
        "            header=None,\n",
        "            index_col=0,\n",
        "        )\n",
        "        identity = pandas.read_csv(\n",
        "            fn(\"identity_CelebA.txt\"), delim_whitespace=True, header=None, index_col=0\n",
        "        )\n",
        "        bbox = pandas.read_csv(\n",
        "            fn(\"list_bbox_celeba.txt\"), delim_whitespace=True, header=1, index_col=0\n",
        "        )\n",
        "        landmarks_align = pandas.read_csv(\n",
        "            fn(\"list_landmarks_align_celeba.txt\"), delim_whitespace=True, header=1\n",
        "        )\n",
        "        attr = pandas.read_csv(\n",
        "            fn(\"list_attr_celeba.txt\"), delim_whitespace=True, header=1\n",
        "        )\n",
        "\n",
        "        mask = slice(None) if split is None else (splits[1] == split)\n",
        "\n",
        "        self.filename = splits[mask].index.values\n",
        "        self.identity = torch.as_tensor(identity[mask].values)\n",
        "        self.bbox = torch.as_tensor(bbox[mask].values)\n",
        "        self.landmarks_align = torch.as_tensor(landmarks_align[mask].values)\n",
        "        self.attr = torch.as_tensor(attr[mask].values)\n",
        "        self.attr = (self.attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
        "        self.attr_names = list(attr.columns)\n",
        "        self.gender_index = self.attr_names.index(\"Male\")\n",
        "        self.dataidxs = dataidxs\n",
        "        if self.dataidxs is None:\n",
        "            self.target = self.attr[\n",
        "                :, self.gender_index : self.gender_index + 1\n",
        "            ].reshape(-1)\n",
        "        else:\n",
        "            self.target = self.attr[\n",
        "                self.dataidxs, self.gender_index : self.gender_index + 1\n",
        "            ].reshape(-1)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        for _, md5, filename in self.file_list:\n",
        "            fpath = os.path.join(self.root, self.base_folder, filename)\n",
        "            _, ext = os.path.splitext(filename)\n",
        "            # Allow original archive to be deleted (zip and 7z)\n",
        "            # Only need the extracted images\n",
        "            if ext not in [\".zip\", \".7z\"] and not check_integrity(fpath, md5):\n",
        "                return False\n",
        "\n",
        "        # Should check a hash of the images\n",
        "        return os.path.isdir(\n",
        "            os.path.join(self.root, self.base_folder, \"img_align_celeba\")\n",
        "        )\n",
        "\n",
        "    def download(self):\n",
        "        import zipfile\n",
        "\n",
        "        if self._check_integrity():\n",
        "            print(\"Files already downloaded and verified\")\n",
        "            return\n",
        "\n",
        "        for file_id, md5, filename in self.file_list:\n",
        "            download_file_from_google_drive(\n",
        "                file_id, os.path.join(self.root, self.base_folder), filename, md5\n",
        "            )\n",
        "\n",
        "        with zipfile.ZipFile(\n",
        "            os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\"\n",
        "        ) as f:\n",
        "            f.extractall(os.path.join(self.root, self.base_folder))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.dataidxs is None:\n",
        "            X = PIL.Image.open(\n",
        "                os.path.join(\n",
        "                    self.root,\n",
        "                    self.base_folder,\n",
        "                    \"img_align_celeba\",\n",
        "                    self.filename[index],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            target = []\n",
        "            for t in self.target_type:\n",
        "                if t == \"attr\":\n",
        "                    target.append(self.attr[index, self.gender_index])\n",
        "                elif t == \"identity\":\n",
        "                    target.append(self.identity[index, 0])\n",
        "                elif t == \"bbox\":\n",
        "                    target.append(self.bbox[index, :])\n",
        "                elif t == \"landmarks\":\n",
        "                    target.append(self.landmarks_align[index, :])\n",
        "                else:\n",
        "                    # TODO: refactor with utils.verify_str_arg\n",
        "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
        "        else:\n",
        "            X = PIL.Image.open(\n",
        "                os.path.join(\n",
        "                    self.root,\n",
        "                    self.base_folder,\n",
        "                    \"img_align_celeba\",\n",
        "                    self.filename[self.dataidxs[index]],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            target = []\n",
        "            for t in self.target_type:\n",
        "                if t == \"attr\":\n",
        "                    target.append(self.attr[self.dataidxs[index], self.gender_index])\n",
        "                elif t == \"identity\":\n",
        "                    target.append(self.identity[self.dataidxs[index], 0])\n",
        "                elif t == \"bbox\":\n",
        "                    target.append(self.bbox[self.dataidxs[index], :])\n",
        "                elif t == \"landmarks\":\n",
        "                    target.append(self.landmarks_align[self.dataidxs[index], :])\n",
        "                else:\n",
        "                    # TODO: refactor with utils.verify_str_arg\n",
        "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        # print(\"target[0]:\", target[0])\n",
        "        if target:\n",
        "            target = tuple(target) if len(target) > 1 else target[0]\n",
        "\n",
        "            if self.target_transform is not None:\n",
        "                target = self.target_transform(target)\n",
        "        else:\n",
        "            target = None\n",
        "        # print(\"celeba target:\", target)\n",
        "        return X, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.dataidxs is None:\n",
        "            return len(self.attr)\n",
        "        else:\n",
        "            return len(self.dataidxs)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
        "        return \"\\n\".join(lines).format(**self.__dict__)\n",
        "\n",
        "\n",
        "class STL10_truncated(data.Dataset):\n",
        "    def __init__(self, root, dataidxs=None, split=\"train\", transform=None, target_transform=None, download=False):\n",
        "        \"\"\"\n",
        "        Custom STL10 dataset with support for data indexing.\n",
        "        Args:\n",
        "            root (str): Dataset root directory.\n",
        "            dataidxs (list, optional): Indices for data partitioning. Defaults to None.\n",
        "            split (str, optional): Dataset split ('train', 'test', 'unlabeled'). Defaults to 'train'.\n",
        "            transform (callable, optional): Transformations for the input data. Defaults to None.\n",
        "            target_transform (callable, optional): Transformations for the target labels. Defaults to None.\n",
        "            download (bool, optional): Whether to download the dataset. Defaults to False.\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "        stl10_dataobj = STL10(\n",
        "            self.root, split=self.split, transform=self.transform, target_transform=self.target_transform, download=self.download\n",
        "        )\n",
        "        data = stl10_dataobj.data\n",
        "        target = np.array(stl10_dataobj.labels)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is the class index.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        # Ensure the image has the correct shape and dtype for PIL\n",
        "        img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
        "        img = img.astype(np.uint8)          # Ensure dtype is uint8 for PIL compatibility\n",
        "        img = Image.fromarray(img)          # Convert to PIL Image\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class CIFAR10_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        cifar_dataobj = CIFAR10(\n",
        "            self.root, self.train, self.transform, self.target_transform, self.download\n",
        "        )\n",
        "\n",
        "        data = cifar_dataobj.data\n",
        "        target = np.array(cifar_dataobj.targets)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def truncate_channel(self, index):\n",
        "        for i in range(index.shape[0]):\n",
        "            gs_index = index[i]\n",
        "            self.data[gs_index, :, :, 1] = 0.0\n",
        "            self.data[gs_index, :, :, 2] = 0.0\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        # print(\"cifar10 img:\", img)\n",
        "        # print(\"cifar10 target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def gen_bar_updater() -> Callable[[int, int, int], None]:\n",
        "    pbar = tqdm(total=None)\n",
        "\n",
        "    def bar_update(count, block_size, total_size):\n",
        "        if pbar.total is None and total_size:\n",
        "            pbar.total = total_size\n",
        "        progress_bytes = count * block_size\n",
        "        pbar.update(progress_bytes - pbar.n)\n",
        "\n",
        "    return bar_update\n",
        "\n",
        "\n",
        "def download_url(\n",
        "    url: str, root: str, filename: Optional[str] = None, md5: Optional[str] = None\n",
        ") -> None:\n",
        "    \"\"\"Download a file from a url and place it in root.\n",
        "    Args:\n",
        "        url (str): URL to download file from\n",
        "        root (str): Directory to place downloaded file in\n",
        "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
        "        md5 (str, optional): MD5 checksum of the download. If None, do not check\n",
        "    \"\"\"\n",
        "    import urllib\n",
        "\n",
        "    root = os.path.expanduser(root)\n",
        "    if not filename:\n",
        "        filename = os.path.basename(url)\n",
        "    fpath = os.path.join(root, filename)\n",
        "\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "\n",
        "    # check if file is already present locally\n",
        "    if check_integrity(fpath, md5):\n",
        "        print(\"Using downloaded and verified file: \" + fpath)\n",
        "    else:  # download the file\n",
        "        try:\n",
        "            print(\"Downloading \" + url + \" to \" + fpath)\n",
        "            urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
        "        except (urllib.error.URLError, IOError) as e:  # type: ignore[attr-defined]\n",
        "            if url[:5] == \"https\":\n",
        "                url = url.replace(\"https:\", \"http:\")\n",
        "                print(\n",
        "                    \"Failed download. Trying https -> http instead.\"\n",
        "                    \" Downloading \" + url + \" to \" + fpath\n",
        "                )\n",
        "                urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
        "            else:\n",
        "                raise e\n",
        "        # check integrity of downloaded file\n",
        "        if not check_integrity(fpath, md5):\n",
        "            raise RuntimeError(\"File not found or corrupted.\")\n",
        "\n",
        "\n",
        "def _is_tarxz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar.xz\")\n",
        "\n",
        "\n",
        "def _is_tar(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar\")\n",
        "\n",
        "\n",
        "def _is_targz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar.gz\")\n",
        "\n",
        "\n",
        "def _is_tgz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tgz\")\n",
        "\n",
        "\n",
        "def _is_gzip(filename: str) -> bool:\n",
        "    return filename.endswith(\".gz\") and not filename.endswith(\".tar.gz\")\n",
        "\n",
        "\n",
        "def _is_zip(filename: str) -> bool:\n",
        "    return filename.endswith(\".zip\")\n",
        "\n",
        "\n",
        "def extract_archive(\n",
        "    from_path: str, to_path: Optional[str] = None, remove_finished: bool = False\n",
        ") -> None:\n",
        "    if to_path is None:\n",
        "        to_path = os.path.dirname(from_path)\n",
        "\n",
        "    if _is_tar(from_path):\n",
        "        with tarfile.open(from_path, \"r\") as tar:\n",
        "\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_targz(from_path) or _is_tgz(from_path):\n",
        "        with tarfile.open(from_path, \"r:gz\") as tar:\n",
        "\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_tarxz(from_path):\n",
        "        with tarfile.open(from_path, \"r:xz\") as tar:\n",
        "\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_gzip(from_path):\n",
        "        to_path = os.path.join(\n",
        "            to_path, os.path.splitext(os.path.basename(from_path))[0]\n",
        "        )\n",
        "        with open(to_path, \"wb\") as out_f, gzip.GzipFile(from_path) as zip_f:\n",
        "            out_f.write(zip_f.read())\n",
        "    elif _is_zip(from_path):\n",
        "        with zipfile.ZipFile(from_path, \"r\") as z:\n",
        "            z.extractall(to_path)\n",
        "    else:\n",
        "        raise ValueError(\"Extraction of {} not supported\".format(from_path))\n",
        "\n",
        "    if remove_finished:\n",
        "        os.remove(from_path)\n",
        "\n",
        "\n",
        "def download_and_extract_archive(\n",
        "    url: str,\n",
        "    download_root: str,\n",
        "    extract_root: Optional[str] = None,\n",
        "    filename: Optional[str] = None,\n",
        "    md5: Optional[str] = None,\n",
        "    remove_finished: bool = False,\n",
        ") -> None:\n",
        "    download_root = os.path.expanduser(download_root)\n",
        "    if extract_root is None:\n",
        "        extract_root = download_root\n",
        "    if not filename:\n",
        "        filename = os.path.basename(url)\n",
        "\n",
        "    download_url(url, download_root, filename, md5)\n",
        "\n",
        "    archive = os.path.join(download_root, filename)\n",
        "    print(\"Extracting {} to {}\".format(archive, extract_root))\n",
        "    extract_archive(archive, extract_root, remove_finished)\n",
        "\n",
        "\n",
        "class FEMNIST(MNIST):\n",
        "    \"\"\"\n",
        "    This dataset is derived from the Leaf repository\n",
        "    (https://github.com/TalwalkarLab/leaf) pre-processing of the Extended MNIST\n",
        "    dataset, grouping examples by writer. Details about Leaf were published in\n",
        "    \"LEAF: A Benchmark for Federated Settings\" https://arxiv.org/abs/1812.01097.\n",
        "    \"\"\"\n",
        "\n",
        "    resources = [\n",
        "        (\n",
        "            \"https://raw.githubusercontent.com/tao-shen/FEMNIST_pytorch/master/femnist.tar.gz\",\n",
        "            \"59c65cec646fc57fe92d27d83afdf0ed\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "        super(MNIST, self).__init__(\n",
        "            root, transform=transform, target_transform=target_transform\n",
        "        )\n",
        "        self.train = train\n",
        "        self.dataidxs = dataidxs\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError(\n",
        "                \"Dataset not found.\" + \" You can use download=True to download it\"\n",
        "            )\n",
        "        if self.train:\n",
        "            data_file = self.training_file\n",
        "        else:\n",
        "            data_file = self.test_file\n",
        "\n",
        "        self.data, self.targets, self.users_index = torch.load(\n",
        "            os.path.join(self.processed_folder, data_file)\n",
        "        )\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            self.data = self.data[self.dataidxs]\n",
        "            self.targets = self.targets[self.dataidxs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "        img = Image.fromarray(img.numpy(), mode=\"F\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the FEMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
        "        import shutil\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        mkdirs(self.raw_folder)\n",
        "        mkdirs(self.processed_folder)\n",
        "\n",
        "        # download files\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition(\"/\")[2]\n",
        "            download_and_extract_archive(\n",
        "                url, download_root=self.raw_folder, filename=filename, md5=md5\n",
        "            )\n",
        "\n",
        "        # process and save as torch files\n",
        "        print(\"Processing...\")\n",
        "        shutil.move(\n",
        "            os.path.join(self.raw_folder, self.training_file), self.processed_folder\n",
        "        )\n",
        "        shutil.move(\n",
        "            os.path.join(self.raw_folder, self.test_file), self.processed_folder\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return all(\n",
        "            check_integrity(\n",
        "                os.path.join(\n",
        "                    self.raw_folder,\n",
        "                    os.path.splitext(os.path.basename(url))[0]\n",
        "                    + os.path.splitext(os.path.basename(url))[1],\n",
        "                )\n",
        "            )\n",
        "            for url, _ in self.resources\n",
        "        )\n",
        "\n",
        "\n",
        "class Generated(MNIST):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "        super(MNIST, self).__init__(\n",
        "            root, transform=transform, target_transform=target_transform\n",
        "        )\n",
        "        self.train = train\n",
        "        self.dataidxs = dataidxs\n",
        "\n",
        "        if self.train:\n",
        "            self.data = np.load(\"data/generated/X_train.npy\")\n",
        "            self.targets = np.load(\"data/generated/y_train.npy\")\n",
        "        else:\n",
        "            self.data = np.load(\"data/generated/X_test.npy\")\n",
        "            self.targets = np.load(\"data/generated/y_test.npy\")\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            self.data = self.data[self.dataidxs]\n",
        "            self.targets = self.targets[self.dataidxs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.data[index], self.targets[index]\n",
        "        return data, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class genData(MNIST):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.data[index], self.targets[index]\n",
        "        return data, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class CIFAR100_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=False,\n",
        "    ):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        cifar_dataobj = CIFAR100(\n",
        "            self.root, self.train, self.transform, self.target_transform, self.download\n",
        "        )\n",
        "\n",
        "        if torchvision.__version__ == \"0.2.1\":\n",
        "            if self.train:\n",
        "                data, target = cifar_dataobj.train_data, np.array(\n",
        "                    cifar_dataobj.train_labels\n",
        "                )\n",
        "            else:\n",
        "                data, target = cifar_dataobj.test_data, np.array(\n",
        "                    cifar_dataobj.test_labels\n",
        "                )\n",
        "        else:\n",
        "            data = cifar_dataobj.data\n",
        "            target = np.array(cifar_dataobj.targets)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "        img = Image.fromarray(img)\n",
        "        # print(\"cifar10 img:\", img)\n",
        "        # print(\"cifar10 target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageFolder_custom(DatasetFolder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        dataidxs=None,\n",
        "        train=True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download=None,\n",
        "    ):\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        imagefolder_obj = ImageFolder(self.root, self.transform, self.target_transform)\n",
        "        self.loader = imagefolder_obj.loader\n",
        "        if self.dataidxs is not None:\n",
        "            self.samples = np.array(imagefolder_obj.samples)[self.dataidxs]\n",
        "        else:\n",
        "            self.samples = np.array(imagefolder_obj.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.samples[index][0]\n",
        "        target = self.samples[index][1]\n",
        "        target = int(target)\n",
        "        sample = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return sample, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.dataidxs is None:\n",
        "            return len(self.samples)\n",
        "        else:\n",
        "            return len(self.dataidxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zwHGp4PpJfk4"
      },
      "outputs": [],
      "source": [
        "def mkdirs(dirpath):\n",
        "    try:\n",
        "        os.makedirs(dirpath)\n",
        "    except Exception as _:\n",
        "        pass\n",
        "\n",
        "\n",
        "def load_mnist_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    mnist_train_ds = MNIST_truncated(\n",
        "        datadir, train=True, download=True, transform=transform\n",
        "    )\n",
        "    mnist_test_ds = MNIST_truncated(\n",
        "        datadir, train=False, download=True, transform=transform\n",
        "    )\n",
        "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
        "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_fmnist_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    mnist_train_ds = FashionMNIST_truncated(\n",
        "        datadir, train=True, download=True, transform=transform\n",
        "    )\n",
        "    mnist_test_ds = FashionMNIST_truncated(\n",
        "        datadir, train=False, download=True, transform=transform\n",
        "    )\n",
        "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
        "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_svhn_data(datadir):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "    svhn_train_ds = SVHN_custom(datadir, train=True, download=True, transform=transform)\n",
        "    svhn_test_ds = SVHN_custom(datadir, train=False, download=True, transform=transform)\n",
        "    X_train, y_train = svhn_train_ds.data, svhn_train_ds.target\n",
        "    X_test, y_test = svhn_test_ds.data, svhn_test_ds.target\n",
        "    # X_train = X_train.data.numpy()\n",
        "    # y_train = y_train.data.numpy()\n",
        "    # X_test = X_test.data.numpy()\n",
        "    # y_test = y_test.data.numpy()\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_cifar10_data(datadir):\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )\n",
        "    cifar10_train_ds = CIFAR10_truncated(\n",
        "        datadir, train=True, download=True, transform=transform\n",
        "    )\n",
        "    cifar10_test_ds = CIFAR10_truncated(\n",
        "        datadir, train=False, download=True, transform=transform\n",
        "    )\n",
        "    X_train, y_train = cifar10_train_ds.data, cifar10_train_ds.target\n",
        "    X_test, y_test = cifar10_test_ds.data, cifar10_test_ds.target\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_celeba_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    celeba_train_ds = CelebA_custom(\n",
        "        datadir, split=\"train\", target_type=\"attr\", download=True, transform=transform\n",
        "    )\n",
        "    celeba_test_ds = CelebA_custom(\n",
        "        datadir, split=\"test\", target_type=\"attr\", download=True, transform=transform\n",
        "    )\n",
        "    gender_index = celeba_train_ds.attr_names.index(\"Male\")\n",
        "    y_train = celeba_train_ds.attr[:, gender_index : gender_index + 1].reshape(-1)\n",
        "    y_test = celeba_test_ds.attr[:, gender_index : gender_index + 1].reshape(-1)\n",
        "    # y_train = y_train.numpy()\n",
        "    # y_test = y_test.numpy()\n",
        "    return (None, y_train, None, y_test)\n",
        "\n",
        "\n",
        "def load_femnist_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    mnist_train_ds = FEMNIST(datadir, train=True, transform=transform, download=True)\n",
        "    mnist_test_ds = FEMNIST(datadir, train=False, transform=transform, download=True)\n",
        "    X_train, y_train, u_train = (\n",
        "        mnist_train_ds.data,\n",
        "        mnist_train_ds.targets,\n",
        "        mnist_train_ds.users_index,\n",
        "    )\n",
        "    X_test, y_test, u_test = (\n",
        "        mnist_test_ds.data,\n",
        "        mnist_test_ds.targets,\n",
        "        mnist_test_ds.users_index,\n",
        "    )\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    u_train = np.array(u_train)\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "    u_test = np.array(u_test)\n",
        "    return (X_train, y_train, u_train, X_test, y_test, u_test)\n",
        "\n",
        "\n",
        "def load_cifar100_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    cifar100_train_ds = CIFAR100_truncated(\n",
        "        datadir, train=True, download=True, transform=transform\n",
        "    )\n",
        "    cifar100_test_ds = CIFAR100_truncated(\n",
        "        datadir, train=False, download=True, transform=transform\n",
        "    )\n",
        "    X_train, y_train = cifar100_train_ds.data, cifar100_train_ds.target\n",
        "    X_test, y_test = cifar100_test_ds.data, cifar100_test_ds.target\n",
        "    # y_train = y_train.numpy()\n",
        "    # y_test = y_test.numpy()\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_tinyimagenet_data(datadir):\n",
        "    split = \"val\"\n",
        "    TinyImageNet(datadir, split=split)\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
        "        transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
        "        transforms.RandomRotation(15),  # Random rotation\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
        "    ])\n",
        "    # transform = transforms.Compose([transforms.ToTensor()])\n",
        "    xray_train_ds = ImageFolder_custom(\n",
        "        datadir + \"tiny-imagenet-200/train/\", transform=transform_train\n",
        "    )\n",
        "    xray_test_ds = ImageFolder_custom(\n",
        "        datadir + \"tiny-imagenet-200/val/\", transform=transform_test\n",
        "    )\n",
        "    X_train, y_train = np.array([s[0] for s in xray_train_ds.samples]), np.array(\n",
        "        [int(s[1]) for s in xray_train_ds.samples]\n",
        "    )\n",
        "    X_test, y_test = np.array([s[0] for s in xray_test_ds.samples]), np.array(\n",
        "        [int(s[1]) for s in xray_test_ds.samples]\n",
        "    )\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "def load_stl10_data(datadir):\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "    transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    stl10_train_ds = STL10_truncated(datadir, split=\"train\", transform=transform_train, download=True)\n",
        "    stl10_test_ds = STL10_truncated(datadir, split=\"test\", transform=transform_test, download=True)\n",
        "\n",
        "    X_train, y_train = stl10_train_ds.data, stl10_train_ds.target\n",
        "    X_test, y_test = stl10_test_ds.data, stl10_test_ds.target\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def record_net_data_stats(y_train, net_dataidx_map, logdir):\n",
        "    net_cls_counts = {}\n",
        "    for net_i, dataidx in net_dataidx_map.items():\n",
        "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
        "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
        "        net_cls_counts[net_i] = tmp\n",
        "    logger.info(\"Data statistics: %s\" % str(net_cls_counts))\n",
        "    return net_cls_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5M0snBfhJfk4"
      },
      "outputs": [],
      "source": [
        "def partition_data(dataset, datadir, logdir, partition, n_parties, beta=0.1):\n",
        "    # Optional: set random seeds for reproducibility\n",
        "    np.random.seed(2020)\n",
        "    torch.manual_seed(2020)\n",
        "\n",
        "    # Initialize test data index map\n",
        "    test_dataidx_map = {}\n",
        "\n",
        "    # Load dataset\n",
        "    if dataset == \"mnist\":\n",
        "        X_train, y_train, X_test, y_test = load_mnist_data(datadir)\n",
        "    elif dataset == \"fmnist\":\n",
        "        X_train, y_train, X_test, y_test = load_fmnist_data(datadir)\n",
        "    elif dataset == \"cifar10\":\n",
        "        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)\n",
        "    elif dataset == \"svhn\":\n",
        "        X_train, y_train, X_test, y_test = load_svhn_data(datadir)\n",
        "    elif dataset == \"celeba\":\n",
        "        X_train, y_train, X_test, y_test = load_celeba_data(datadir)\n",
        "    elif dataset == \"femnist\":\n",
        "        X_train, y_train, u_train, X_test, y_test, u_test = load_femnist_data(datadir)\n",
        "    elif dataset == \"cifar100\":\n",
        "        X_train, y_train, X_test, y_test = load_cifar100_data(datadir)\n",
        "    elif dataset == \"tinyimagenet\":\n",
        "        X_train, y_train, X_test, y_test = load_tinyimagenet_data(datadir)\n",
        "    elif dataset == \"stl10\":\n",
        "        X_train, y_train, X_test, y_test = load_stl10_data(datadir)\n",
        "    elif dataset == \"generated\":\n",
        "        # Code for generated dataset (omitted for brevity)\n",
        "        pass\n",
        "    # Add other datasets if needed\n",
        "\n",
        "    n_train = y_train.shape[0]\n",
        "\n",
        "    # Partition the data\n",
        "    if partition == \"homo\":\n",
        "        # Homogeneous data partition\n",
        "        idxs = np.random.permutation(n_train)\n",
        "        batch_idxs = np.array_split(idxs, n_parties)\n",
        "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
        "\n",
        "    elif partition == \"noniid-labeldir\":\n",
        "        # Existing non-IID logic using Dirichlet distribution\n",
        "        min_size = 0\n",
        "        min_require_size = 10  # Minimum number required for each party\n",
        "        K = 10  # Number of classes\n",
        "\n",
        "        N = y_train.shape[0]\n",
        "        net_dataidx_map = {}\n",
        "        test_dataidx_map = {}  # Make sure to initialize this\n",
        "\n",
        "        while min_size < min_require_size:\n",
        "            idx_batch = [[] for _ in range(n_parties)]\n",
        "            for k in range(K):\n",
        "                idx_k = np.where(y_train == k)[0]\n",
        "                np.random.shuffle(idx_k)\n",
        "                proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
        "                proportions = np.array([p * (len(idx_j) < N / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n",
        "                proportions = proportions / proportions.sum()  # Normalize\n",
        "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
        "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
        "\n",
        "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
        "\n",
        "        for j in range(n_parties):\n",
        "            np.random.shuffle(idx_batch[j])\n",
        "            net_dataidx_map[j] = idx_batch[j]\n",
        "\n",
        "            # Initialize test_dataidx_map for current party\n",
        "            test_dataidx_map[j] = []\n",
        "\n",
        "            # Gather test indices for current party based on labels in net_dataidx_map[j]\n",
        "            for k in range(K):\n",
        "                if k in y_train[net_dataidx_map[j]]:\n",
        "                    # Access test indices for class k\n",
        "                    idx_test_k = np.where(y_test == k)[0]\n",
        "                    np.random.shuffle(idx_test_k)\n",
        "\n",
        "                    # The number of sample for each party based on training set size\n",
        "                    n_samples = int(len(net_dataidx_map[j]) * len(idx_test_k) / N)\n",
        "                    test_dataidx_map[j].extend(idx_test_k[:n_samples])\n",
        "\n",
        "            test_dataidx_map[j] = np.array(test_dataidx_map[j])\n",
        "\n",
        "        # Cleanup to avoid empty concatenation error\n",
        "        for j in range(n_parties):\n",
        "            if len(test_dataidx_map[j]) == 0:\n",
        "                test_dataidx_map[j] = np.array([])  # Set to an empty array to avoid errors later\n",
        "\n",
        "    elif partition == \"noniid-fix\":\n",
        "        # Custom fixed distribution logic\n",
        "        desired_distribution = DESIRED_DISTRIBUTION\n",
        "\n",
        "        # Number of clients and classes\n",
        "        num_clients = len(desired_distribution)\n",
        "        num_classes = len(desired_distribution[0])\n",
        "\n",
        "        assert num_clients == NUMBER_OF_CLIENTS\n",
        "        assert num_classes == NUMBER_OF_CLASSES\n",
        "\n",
        "        # Initialize the data indices for each client\n",
        "        net_dataidx_map = {i: [] for i in range(num_clients)}\n",
        "\n",
        "        # Iterate over each class and assign samples to clients based on the desired distribution\n",
        "        for class_idx in range(num_classes):\n",
        "            # Get the indices of all samples belonging to the current class\n",
        "            class_indices = np.where(y_train == class_idx)[0]\n",
        "\n",
        "            # Shuffle the indices to ensure randomness\n",
        "            np.random.shuffle(class_indices)\n",
        "\n",
        "            # Assign samples to clients based on the desired distribution\n",
        "            start_idx = 0\n",
        "            for client_idx in range(num_clients):\n",
        "                num_samples = desired_distribution[client_idx][class_idx]\n",
        "                if num_samples > 0:\n",
        "                    end_idx = start_idx + num_samples\n",
        "                    net_dataidx_map[client_idx].extend(class_indices[start_idx:end_idx])\n",
        "                    start_idx = end_idx\n",
        "\n",
        "        # Initialize test_dataidx_map for each client\n",
        "        for j in range(num_clients):\n",
        "            test_dataidx_map[j] = []\n",
        "\n",
        "            # Gather test indices for current party based on labels in net_dataidx_map[j]\n",
        "            for k in range(num_classes):\n",
        "                if k in y_train[net_dataidx_map[j]]:\n",
        "                    # Access test indices for class k\n",
        "                    idx_test_k = np.where(y_test == k)[0]\n",
        "                    np.random.shuffle(idx_test_k)\n",
        "\n",
        "                    # The number of samples for each party based on training set size\n",
        "                    n_samples = int(len(net_dataidx_map[j]) * len(idx_test_k) / n_train)\n",
        "                    test_dataidx_map[j].extend(idx_test_k[:n_samples])\n",
        "\n",
        "            test_dataidx_map[j] = np.array(test_dataidx_map[j])\n",
        "\n",
        "        # Cleanup to avoid empty concatenation error\n",
        "        for j in range(num_clients):\n",
        "            if len(test_dataidx_map[j]) == 0:\n",
        "                test_dataidx_map[j] = np.array([])  # Set to an empty array to avoid errors later\n",
        "\n",
        "    elif partition.startswith(\"noniid-#label\") and partition[13:].isdigit():\n",
        "        # Existing logic for noniid-#label partitioning\n",
        "        num = int(partition[13:])\n",
        "        if dataset in (\"celeba\", \"covtype\", \"a9a\", \"rcv1\", \"SUSY\"):\n",
        "            num = 1\n",
        "            K = 2\n",
        "        else:\n",
        "            if dataset == \"cifar100\":\n",
        "                K = 100\n",
        "            elif dataset == \"tinyimagenet\":\n",
        "                K = 200\n",
        "            else:\n",
        "                K = 10\n",
        "        if num == K:\n",
        "            # IID partition\n",
        "            net_dataidx_map = {\n",
        "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
        "            }\n",
        "            for i in range(K):\n",
        "                idx_k = np.where(y_train == i)[0]\n",
        "                np.random.shuffle(idx_k)\n",
        "                split = np.array_split(idx_k, n_parties)\n",
        "                for j in range(n_parties):\n",
        "                    net_dataidx_map[j] = np.append(net_dataidx_map[j], split[j])\n",
        "        else:\n",
        "            times = [0 for _ in range(K)]\n",
        "            contain = []\n",
        "            for i in range(n_parties):\n",
        "                current = [i % K]\n",
        "                times[i % K] += 1\n",
        "                j = 1\n",
        "                while j < num:\n",
        "                    ind = random.randint(0, K - 1)\n",
        "                    if ind not in current:\n",
        "                        j += 1\n",
        "                        current.append(ind)\n",
        "                        times[ind] += 1\n",
        "                contain.append(current)\n",
        "            net_dataidx_map = {\n",
        "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
        "            }\n",
        "            test_dataidx_map = {\n",
        "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
        "            }\n",
        "            for i in range(K):\n",
        "                if times[i] > 0:\n",
        "                    idx_k = np.where(y_train == i)[0]\n",
        "                    idx_t = np.where(y_test == i)[0]\n",
        "                    np.random.shuffle(idx_k)\n",
        "                    np.random.shuffle(idx_t)\n",
        "                    split = np.array_split(idx_k, times[i])\n",
        "                    splitt = np.array_split(idx_t, times[i])\n",
        "                    ids = 0\n",
        "                    for j in range(n_parties):\n",
        "                        if i in contain[j]:\n",
        "                            net_dataidx_map[j] = np.append(\n",
        "                                net_dataidx_map[j], split[ids]\n",
        "                            )\n",
        "                            test_dataidx_map[j] = np.append(\n",
        "                                test_dataidx_map[j], splitt[ids]\n",
        "                            )\n",
        "                            ids += 1\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown partition method: {partition}\")\n",
        "\n",
        "    # Record the data statistics\n",
        "    traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)\n",
        "\n",
        "    return (\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        net_dataidx_map,\n",
        "        test_dataidx_map,\n",
        "        traindata_cls_counts,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9Abxqf_CJfk4"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=1.0, net_id=None, total=0):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        self.net_id = net_id\n",
        "        self.num = int(sqrt(total))\n",
        "        if self.num * self.num < total:\n",
        "            self.num = self.num + 1\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        if self.net_id is None:\n",
        "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "        else:\n",
        "            tmp = torch.randn(tensor.size())\n",
        "            filt = torch.zeros(tensor.size())\n",
        "            size = int(28 / self.num)\n",
        "            row = int(self.net_id / size)\n",
        "            col = self.net_id % size\n",
        "            for i in range(size):\n",
        "                for j in range(size):\n",
        "                    filt[:, row * size + i, col * size + j] = 1\n",
        "            tmp = tmp * filt\n",
        "            return tensor + tmp * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"(mean={0}, std={1})\".format(\n",
        "            self.mean, self.std\n",
        "        )\n",
        "\n",
        "\n",
        "def get_dataloader(\n",
        "    dataset,\n",
        "    datadir,\n",
        "    train_bs,\n",
        "    test_bs,\n",
        "    dataidxs=None,\n",
        "    testidxs=None,\n",
        "    noise_level=0,\n",
        "    net_id=None,\n",
        "    total=0,\n",
        "):\n",
        "    if dataset in (\n",
        "        \"mnist\",\n",
        "        \"femnist\",\n",
        "        \"fmnist\",\n",
        "        \"cifar10\",\n",
        "        \"svhn\",\n",
        "        \"generated\",\n",
        "        \"covtype\",\n",
        "        \"a9a\",\n",
        "        \"rcv1\",\n",
        "        \"SUSY\",\n",
        "        \"cifar100\",\n",
        "        \"tinyimagenet\",\n",
        "        \"stl10\"\n",
        "    ):\n",
        "        if dataset == \"mnist\":\n",
        "            dl_obj = MNIST_truncated\n",
        "            transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "            transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "        elif dataset == \"femnist\":\n",
        "            dl_obj = FEMNIST\n",
        "            transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "            transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "        elif dataset == \"fmnist\":\n",
        "            dl_obj = FashionMNIST_truncated\n",
        "            transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "            transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "        elif dataset == \"svhn\":\n",
        "            dl_obj = SVHN_custom\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "            ])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "            ])\n",
        "\n",
        "        elif dataset == \"cifar10\":\n",
        "            print(\"in cifar10\")\n",
        "            dl_obj = CIFAR10_truncated\n",
        "            transform_train = transforms.Compose(\n",
        "                [\n",
        "                    # transforms.Resize((224,224)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Lambda(\n",
        "                        lambda x: F.pad(\n",
        "                            Variable(x.unsqueeze(0), requires_grad=False),\n",
        "                            (4, 4, 4, 4),\n",
        "                            mode=\"reflect\",\n",
        "                        ).data.squeeze()\n",
        "                    ),\n",
        "                    transforms.ToPILImage(),\n",
        "                    transforms.RandomCrop(32),\n",
        "                    transforms.ToTensor(),\n",
        "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "            # data prep for test set\n",
        "            transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
        "                ]\n",
        "            )\n",
        "        elif dataset == \"cifar100\":\n",
        "            print(\"in 100\")\n",
        "            dl_obj = CIFAR100_truncated\n",
        "            normalize = transforms.Normalize(\n",
        "                mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n",
        "                std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404],\n",
        "            )\n",
        "\n",
        "            transform_train = transforms.Compose(\n",
        "                [\n",
        "                    # transforms.ToPILImage(),\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomRotation(15),\n",
        "                    transforms.ToTensor(),\n",
        "                    normalize,\n",
        "                ]\n",
        "            )\n",
        "            # data prep for test set\n",
        "            transform_test = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "        elif dataset == \"tinyimagenet\":\n",
        "            dl_obj = ImageFolder_custom\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
        "                transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
        "                transforms.RandomRotation(15),  # Random rotation\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
        "            ])\n",
        "\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
        "            ])\n",
        "        elif dataset == \"stl10\":\n",
        "            dl_obj = STL10_truncated\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "        else:\n",
        "            dl_obj = Generated\n",
        "            transform_train = None\n",
        "            transform_test = None\n",
        "        if dataset == \"tinyimagenet\":\n",
        "            train_ds = dl_obj(\n",
        "                datadir + \"tiny-imagenet-200/train/\",\n",
        "                dataidxs=dataidxs,\n",
        "                transform=transform_train,\n",
        "            )\n",
        "            test_ds = dl_obj(\n",
        "                datadir + \"tiny-imagenet-200/val/\",\n",
        "                dataidxs=testidxs,\n",
        "                transform=transform_test\n",
        "            )\n",
        "        elif dataset == \"stl10\":\n",
        "            train_ds = dl_obj(\n",
        "                datadir,\n",
        "                dataidxs=dataidxs,\n",
        "                split=\"train\",\n",
        "                transform=transform_train,\n",
        "                download=True\n",
        "            )\n",
        "            test_ds = dl_obj(\n",
        "                datadir,\n",
        "                dataidxs=testidxs,\n",
        "                split=\"test\",\n",
        "                transform=transform_test,\n",
        "                download=True\n",
        "            )\n",
        "        else:\n",
        "            print(\"dir\", datadir)\n",
        "            train_ds = dl_obj(\n",
        "                datadir,\n",
        "                dataidxs=dataidxs,\n",
        "                train=True,\n",
        "                transform=transform_train,\n",
        "                download=True,\n",
        "            )\n",
        "            test_ds = dl_obj(\n",
        "                datadir,\n",
        "                dataidxs=testidxs,\n",
        "                train=False,\n",
        "                transform=transform_test,\n",
        "                download=True,\n",
        "            )\n",
        "        train_dl = data.DataLoader(\n",
        "            dataset=train_ds, batch_size=train_bs, shuffle=True, drop_last=False\n",
        "        )\n",
        "        test_dl = data.DataLoader(\n",
        "            dataset=test_ds, batch_size=test_bs, shuffle=False, drop_last=False\n",
        "        )\n",
        "        print(train_ds, \"train ds\")\n",
        "    return train_dl, test_dl, train_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yEtLybp7Jfk4"
      },
      "outputs": [],
      "source": [
        "def get_loaders(NUMBER_OF_CLIENTS):\n",
        "\n",
        "    (\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        net_dataidx_map,\n",
        "        test_dataidx_map,\n",
        "        traindata_cls_counts,\n",
        "    ) = partition_data(\n",
        "        dataset=DATASET_TYPE,\n",
        "        datadir=\"./data/\",\n",
        "        logdir=\"./logs/\",\n",
        "        partition=PARTITION,\n",
        "        n_parties=10,\n",
        "    )\n",
        "    print(\"shapes\", X_train.shape, y_train.shape)\n",
        "    train_loaders = []\n",
        "    test_loaders = []\n",
        "    for client_id in range(NUMBER_OF_CLIENTS):\n",
        "\n",
        "        dataidxs = net_dataidx_map[client_id]\n",
        "        testidxs = test_dataidx_map[client_id]\n",
        "\n",
        "        train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(\n",
        "            dataset=DATASET_TYPE,\n",
        "            datadir=\"./data/\",\n",
        "            train_bs=TRAIN_BATCH_SIZE,\n",
        "            test_bs=TEST_BATCH_SIZE,\n",
        "            dataidxs=dataidxs,\n",
        "            testidxs=testidxs,\n",
        "        )\n",
        "        train_loaders.append(train_dl_local)\n",
        "        test_loaders.append(test_dl_local)\n",
        "\n",
        "    return train_loaders, test_loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S3b66P1iJfk5"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_data():\n",
        "    train_loaders, test_loaders = get_loaders(10)\n",
        "    return train_loaders, test_loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a5Riu3BeJfk5",
        "outputId": "043867c6-2337-4842-82d3-f996e1637d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Data statistics: {0: {0: 2948, 2: 5293}, 1: {1: 3466, 2: 2330}, 2: {0: 2000, 2: 2962}, 3: {3: 4249, 4: 3729}, 4: {4: 3729, 6: 2465}, 5: {3: 3720, 6: 2145}, 6: {5: 3865, 6: 1117}, 7: {7: 1865, 8: 2863}, 8: {8: 2182, 9: 3248}, 9: {7: 3465, 9: 1329}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes (73257, 3, 32, 32) (73257,)\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a10f8a35120> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df530a0> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df52e60> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df531f0> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df51990> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df506d0> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df50be0> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101df504f0> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101e1e5510> train ds\n",
            "dir ./data/\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "<__main__.SVHN_custom object at 0x7a101e1e7220> train ds\n"
          ]
        }
      ],
      "source": [
        "train_loaders, test_loaders = load_and_prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download('https://drive.google.com/file/d/1iQ_rUFeSYerCM_4O4EkgnPlw2o9kHKcI/view?usp=drive_link', './node_0.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1Fig4VlVQqakq7LgJ_inbciLt6qIWqhuE/view?usp=drive_link', './node_1.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1UDBswYJXbd6aimlQek-qsiPTRD7H-Gmw/view?usp=drive_link', './node_2.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1Ux3Xx5o9RwPhpE6ikkot6APnUEg1hzTC/view?usp=drive_link', './node_3.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1VDfqqI2JyGVXXjwhz7JEd2eGs1sym78y/view?usp=drive_link', './node_4.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1rSaoong2Wrtl55f1ewwoyE4z-JOX-7M-/view?usp=drive_link', './node_5.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1nk_T2_iaO0jJkjorvxnRC1SkBpCvMAbt/view?usp=drive_link', './node_6.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1xUJ8C7k_--U56pVAnzcI5lofNMuqukh0/view?usp=drive_link', './node_7.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/18ywhNBRkesxrL2UMEn0iuE6Kl5DEE4Nu/view?usp=drive_link', './node_8.pth', quiet=True,fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1AfY9qtHRhUG4PX9F4_kjhLS29DQ173ss/view?usp=drive_link', './node_9.pth', quiet=True,fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "woND0MYzN0M8",
        "outputId": "af31911a-dd80-4ede-bf77-9403e95d01a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./node_9.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lo14Ek4Jfk5"
      },
      "source": [
        "# Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NUyaOdY0cMmm"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):  # Corrected: usage of double underscores\n",
        "        super(Net, self).__init__()  # Call the parent class constructor\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Calculate the size of the output from the last convolutional layer\n",
        "        self._to_linear = 128 * (128 // 8) * (128 // 8)  # Adjust based on pooling layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self._to_linear, 512),  # Adjusted input size\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, NUMBER_OF_CLASSES),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKu2NIc0Jfk5"
      },
      "source": [
        "# Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "39j089tSJfk5"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def find_num_cluster(clusters):\n",
        "    return len(set(clusters))\n",
        "\n",
        "def load_torch_model(node_id):\n",
        "    checkpoint_path = f\"./node_{node_id}.pth\"\n",
        "    state_dict = torch.load(checkpoint_path)\n",
        "    model = Net()\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    return model\n",
        "\n",
        "class Clustering:\n",
        "    def __init__(self, clients, trainLoaders, percentage):\n",
        "        self.clients = clients\n",
        "        self.num_nodes = len(clients)\n",
        "        self.percentage = percentage\n",
        "        self.Mask_Number = 0\n",
        "        self.maskIds = []\n",
        "        self.grads = []\n",
        "        self.load_and_calculate_sensitivity(trainLoaders)\n",
        "        self.distances = self.calculate_distance()\n",
        "        self.Clusters = self.make_clusters()\n",
        "\n",
        "    def assign_save_ids_to_weights(self, model):\n",
        "        weight_id_map = {}\n",
        "        weight_id = 0\n",
        "        for name, parameter in model.named_parameters():\n",
        "            weight_id_map[name] = {}\n",
        "            num_weights = parameter.numel()\n",
        "            for i in range(num_weights):\n",
        "                weight_id_map[name][i] = weight_id\n",
        "                weight_id += 1\n",
        "        filename = \"weight_to_id.csv\"\n",
        "        if not os.path.exists(filename):\n",
        "            with open(filename, \"w\", newline=\"\") as csvfile:\n",
        "                writer = csv.writer(csvfile)\n",
        "                writer.writerow([\"Layer\", \"Weight Index\", \"Weight ID\"])\n",
        "                for layer_name, indices in weight_id_map.items():\n",
        "                    for index, weight_id in indices.items():\n",
        "                        writer.writerow([layer_name, index, weight_id])\n",
        "        return weight_id_map\n",
        "\n",
        "    def load_and_calculate_sensitivity(self, trainLoaders):\n",
        "        \"\"\"\n",
        "        Calculate sensitivity for each client and store the results in the object.\n",
        "        \"\"\"\n",
        "        for cid in self.clients:\n",
        "            model = load_torch_model(cid).to(DEVICE)\n",
        "            model.eval()\n",
        "            sensitivity_value = self.calculate_sensitivity(model, trainLoaders[int(cid)])\n",
        "            weight_id_map = self.assign_save_ids_to_weights(model)\n",
        "\n",
        "            mask_ID, weights = self.get_maskIds(sensitivity_value, weight_id_map, self.percentage)\n",
        "            print(f\"Model weights and sensitivity data for client #{cid} processed.\")\n",
        "\n",
        "            self.maskIds.append(mask_ID)\n",
        "            self.grads.append(weights)\n",
        "\n",
        "    def calculate_sensitivity(self, model, dataloader):\n",
        "        model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        gradient_sums = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            gradient_sums[name] = 0.0\n",
        "            param.requires_grad_(True)\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            sensitivities = {}\n",
        "            for name, parameter in model.named_parameters():\n",
        "                grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
        "                for i, grad in enumerate(grads):\n",
        "                    sensitivities[(name, i)] = grad\n",
        "            return sensitivities\n",
        "\n",
        "    def get_maskIds(self, sensitivity_values_node, weight_id_map, sensitive_percentage):\n",
        "        num_weights = len(sensitivity_values_node)\n",
        "        top_k = int(np.ceil(sensitive_percentage * num_weights / 100))\n",
        "        self.Mask_Number = top_k\n",
        "        sorted_weights = sorted(sensitivity_values_node.items(), key=lambda item: item[1], reverse=True)[:top_k]\n",
        "        weights = [weight for (layer, index), weight in sensitivity_values_node.items()]\n",
        "        top_weight_ids = [weight_id_map[layer][index] for (layer, index), _ in sorted_weights]\n",
        "        return top_weight_ids, weights\n",
        "\n",
        "    def calculate_common_ids(self, index1, index2):\n",
        "        arr1 = self.maskIds[index1]\n",
        "        arr2 = self.maskIds[index2]\n",
        "        sarr1 = set(arr1)\n",
        "        sarr2 = set(arr2)\n",
        "        inter = sarr1.intersection(sarr2)\n",
        "        similarity1 = len(inter)\n",
        "        return similarity1\n",
        "\n",
        "    def calculate_distance(self):\n",
        "        similarity_matrix = np.zeros((self.num_nodes, self.num_nodes))\n",
        "\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(i + 1, self.num_nodes):\n",
        "                if DISTANCE_METRIC == \"coordinate\":\n",
        "                    similarity = self.calculate_common_ids(i, j)\n",
        "                elif DISTANCE_METRIC == \"cosine\":\n",
        "                    if JUST_COMPARE_SIGNIFICANCE:\n",
        "                        np_grad_i = np.array(self.grads[i])\n",
        "                        np_grad_j = np.array(self.grads[j])\n",
        "                        grad_i_significant_indices = self.get_significant_weights_indices(np_grad_i)\n",
        "                        grad_j_significant_indices = self.get_significant_weights_indices(np_grad_j)\n",
        "                        grad_i_significant_weights = np_grad_i[grad_i_significant_indices]\n",
        "                        grad_j_significant_weights = np_grad_j[grad_j_significant_indices]\n",
        "                        similarity = 1 - cosine(grad_i_significant_weights, grad_j_significant_weights)\n",
        "                    else:\n",
        "                        similarity = 1 - cosine(self.grads[i], self.grads[j])\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported distance metric: {DISTANCE_METRIC}\")\n",
        "                similarity_matrix[i, j] = similarity\n",
        "                similarity_matrix[j, i] = similarity\n",
        "            similarity_matrix[i, i] = self.Mask_Number\n",
        "        distances = self.Mask_Number - similarity_matrix\n",
        "\n",
        "        self.save_distances_to_csv(distances)\n",
        "        print(distances)\n",
        "        self.plot_distance_matrix(distances)\n",
        "\n",
        "        return distances\n",
        "\n",
        "    def plot_distance_matrix(self, distances):\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(distances, annot=True, fmt=\".4f\", cmap=\"YlOrRd\",\n",
        "                    xticklabels=range(self.num_nodes), yticklabels=range(self.num_nodes),\n",
        "                    vmin=0, vmax=np.max(distances))\n",
        "        plt.title(\"Distance Matrix\")\n",
        "        plt.xlabel(\"Client Index\")\n",
        "        plt.ylabel(\"Client Index\")\n",
        "        plt.show()\n",
        "\n",
        "    def make_clusters(self):\n",
        "        normal_distances = (self.distances + self.distances.T) / 2\n",
        "        np.fill_diagonal(normal_distances, 0)\n",
        "        affinity_propagation = AffinityPropagation(affinity=\"precomputed\", random_state=0)\n",
        "        normal_distances = -normal_distances\n",
        "        clusters = affinity_propagation.fit_predict(normal_distances)\n",
        "        print(f\"cluster results:{clusters}\")\n",
        "        max_label = max(clusters)\n",
        "        noise_indices = clusters == -1\n",
        "        unique_noise_labels = np.arange(max_label + 1, max_label + 1 + np.sum(noise_indices))\n",
        "        clusters[noise_indices] = unique_noise_labels\n",
        "        cluster_list = [np.where(clusters == cluster_id)[0].tolist() for cluster_id in range(find_num_cluster(clusters))]\n",
        "        cluster_list = self.index_to_value(cluster_list)\n",
        "        return cluster_list\n",
        "\n",
        "    def save_distances_to_csv(self, distances):\n",
        "        filename = f\"distances_{DISTANCE_METRIC}.csv\"\n",
        "        with open(filename, mode=\"w\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Node\"] + [f\"Node_{i}\" for i in range(self.num_nodes)])\n",
        "            for i, row in enumerate(distances):\n",
        "                writer.writerow([f\"Node_{i}\"] + row.tolist())\n",
        "        print(f\"Distance matrix saved to {filename}\")\n",
        "\n",
        "    def get_significant_weights_indices(self, arr):\n",
        "        num_elements = len(arr)\n",
        "        num_significant = int(np.ceil(num_elements * self.percentage / 100))\n",
        "        if num_significant == 0:\n",
        "            return np.array([], dtype=int)\n",
        "        significant_indices = np.argpartition(-arr, num_significant - 1)[:num_significant]\n",
        "        significant_indices = significant_indices[np.argsort(-arr[significant_indices])]\n",
        "        return significant_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EwRd5hTvHkUU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def model_parameters_to_numpy(path):\n",
        "    # Load the model's state dictionary\n",
        "    model = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Initialize an empty list to store parameters\n",
        "    params = []\n",
        "\n",
        "    # Iterate through the model to extract parameters\n",
        "    for name, param in model.items():\n",
        "        if 'bias' not in name:  # Exclude bias terms (optional)\n",
        "            params.append(param.detach().cpu().numpy())  # Convert to numpy array\n",
        "\n",
        "    # Return the parameters as a numpy array\n",
        "    return np.array(params, dtype=object)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7cdf9aYYPkpI"
      },
      "outputs": [],
      "source": [
        "def top_to_one_other_zero(arr, P):\n",
        "    flat_arr = arr.flatten()\n",
        "    threshold_value = np.percentile(flat_arr, P * 100)\n",
        "\n",
        "    # Create a new array where values below the threshold are 0 and others are 1\n",
        "    result = np.where(arr <= threshold_value, 0, 1)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7zXeVDAJqXJf"
      },
      "outputs": [],
      "source": [
        "def group_clients_by_cluster(labels):\n",
        "    clusters = {}\n",
        "    for client_id, cluster_id in enumerate(labels):\n",
        "        if cluster_id not in clusters:\n",
        "            clusters[cluster_id] = []\n",
        "        clusters[cluster_id].append(client_id)\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QW_AqkkAuPOv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "def cluster_to_list(arr):\n",
        "    cluster_dict = defaultdict(list)\n",
        "    for index, cluster in enumerate(arr):\n",
        "        cluster_dict[cluster].append(index)\n",
        "    clusters = [indices for _, indices in sorted(cluster_dict.items())]\n",
        "\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRkxao3oDQ64"
      },
      "source": [
        "## Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Fxe_HfwIsiQs"
      },
      "outputs": [],
      "source": [
        "# N = len(params)\n",
        "# print(\"Number of parameters (N):\", N)\n",
        "\n",
        "# Cosine_similarity = np.zeros((N, N))\n",
        "\n",
        "# for i in range(N):\n",
        "#     for j in range(i + 1, N):\n",
        "#         # Reshape the 1D arrays to 2D arrays\n",
        "#         param_i = params[i].reshape(1, -1)\n",
        "#         param_j = params[j].reshape(1, -1)\n",
        "#         # Extract the scalar value from the 2D array returned by cosine_similarity\n",
        "#         Cosine_similarity[i][j] = cosine_similarity(param_i, param_j).item()\n",
        "\n",
        "# # Make the matrix symmetric (copy upper triangle to lower triangle)\n",
        "# Cosine_similarity = Cosine_similarity + Cosine_similarity.T\n",
        "\n",
        "# # Set diagonal elements to 1 (a vector is perfectly similar to itself)\n",
        "# np.fill_diagonal(Cosine_similarity, 1)\n",
        "\n",
        "# # Plot the heatmap\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# sns.heatmap(Cosine_similarity, annot=True, fmt=\".4f\", cmap=\"YlGnBu\",\n",
        "#             xticklabels=range(N), yticklabels=range(N), vmin=-1, vmax=1)\n",
        "# plt.title(\"Cosine Similarity Matrix\")\n",
        "# plt.xlabel(\"Parameter Index\")\n",
        "# plt.ylabel(\"Parameter Index\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VSw4T-Falaq1"
      },
      "outputs": [],
      "source": [
        "# ap = AffinityPropagation(affinity='precomputed', random_state=0).fit(Cosine_similarity)\n",
        "# cosine_labels = ap.labels_\n",
        "\n",
        "# clusters = group_clients_by_cluster(cosine_labels)\n",
        "\n",
        "# print(\"Clients clustering based on their dataset:\", clusters)\n",
        "# print(\"Cluster labels for each parameter:\", cosine_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0nhsVmVM9q"
      },
      "source": [
        "**Coordinate-Based**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-vACQUtVBgg",
        "outputId": "fc9b75b4-7c40-4a8d-8caf-6baef2251d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-e1adfd1caae3>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights and sensitivity data for client #0 processed.\n",
            "Model weights and sensitivity data for client #1 processed.\n",
            "Model weights and sensitivity data for client #2 processed.\n",
            "Model weights and sensitivity data for client #3 processed.\n",
            "Model weights and sensitivity data for client #4 processed.\n",
            "Model weights and sensitivity data for client #5 processed.\n"
          ]
        }
      ],
      "source": [
        "# coordinates = [top_to_one_other_zero(params[i], P) for i in range(N)]\n",
        "# for i in range(N):\n",
        "#   tops=top_to_one_other_zero(params[i], P)\n",
        "#   coordinates.append(tops)\n",
        "# ID_similarity=np.zeros((N,N))\n",
        "# for i in range(N):\n",
        "#   for j in range(i+1,N):\n",
        "#     ID_similarity[i][j]=cosine_similarity(coordinates[i].reshape(1, -1),coordinates[j].reshape(1, -1))\n",
        "\n",
        "# ID_distance = -ID_similarity\n",
        "\n",
        "\n",
        "# ID_similarity = np.zeros((N, N))\n",
        "\n",
        "# # Compute cosine similarity for each pair of coordinates\n",
        "# for i in range(N):\n",
        "#     for j in range(i + 1, N):\n",
        "#         similarity = cosine_similarity(\n",
        "#             coordinates[i].reshape(1, -1),\n",
        "#             coordinates[j].reshape(1, -1)\n",
        "#         )\n",
        "#         ID_similarity[i][j] = similarity.item()  # Use .item() to extract the scalar value\n",
        "\n",
        "# Make the matrix symmetric (copy upper triangle to lower triangle)\n",
        "# ID_similarity = ID_similarity + ID_similarity.T\n",
        "\n",
        "clusters = Clustering([0,1,2,3,4,5,6,7,8,9], train_loaders, SENSITIVITY_PERCENTAGE).Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vj_bDZqJfk6"
      },
      "outputs": [],
      "source": [
        "# ap = AffinityPropagation(affinity=\"precomputed\", random_state=0).fit(ID_distance)\n",
        "# ID_labels = ap.labels_\n",
        "# # ID_similarity_show = np.round(ID_similarity, 2)\n",
        "# print(ID_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se8kQnINYQeo"
      },
      "outputs": [],
      "source": [
        "# Cosine_similarity_show=np.round(Cosine_similarity, 2)\n",
        "# print(cosine_labels)\n",
        "# Cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "854OX-qVYTzu"
      },
      "outputs": [],
      "source": [
        "# print(ID_labels)\n",
        "# ID_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB7qTGHbaqAA"
      },
      "outputs": [],
      "source": [
        "# matrix1=Cosine_similarity.flatten()\n",
        "# matrix2=ID_similarity.flatten()\n",
        "# from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# corr_pearson, _ = pearsonr(matrix1, matrix2)\n",
        "# corr_spearman, _ = spearmanr(matrix1, matrix2)\n",
        "# mae = np.mean(np.abs(matrix1 - matrix2))\n",
        "# diff=matrix1- matrix2\n",
        "# min_,max_,avg_=np.min(diff),np.max(diff),np.average(diff)\n",
        "# corr_pearson, corr_spearman, mae, min_,max_,avg_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0L9mGTkedtt"
      },
      "outputs": [],
      "source": [
        "# matrix2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYVVdJtNh84X"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# def find_regression_coefficients(x, y):\n",
        "#     x = np.array(x).reshape(-1, 1)\n",
        "#     y = np.array(y)\n",
        "\n",
        "#     # Create and fit the regression model\n",
        "#     model = LinearRegression()\n",
        "#     model.fit(x, y)\n",
        "\n",
        "#     return model.coef_[0], model.intercept_\n",
        "# slope, intercept = find_regression_coefficients(matrix1, matrix2)\n",
        "# cofficient=f\"cosine(x,y)={round(slope,3)} ID_sim(x,y) {round(intercept,3)}\"\n",
        "# cofficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCnubZLxZ1as"
      },
      "outputs": [],
      "source": [
        "# # Filter non-zero values for both matrices\n",
        "# non_zero_indices_x = np.nonzero(matrix1)\n",
        "# non_zero_indices_y = np.nonzero(matrix2)\n",
        "\n",
        "# # Get non-zero values\n",
        "# x_non_zero = matrix1[non_zero_indices_x]\n",
        "# y_non_zero = matrix2[non_zero_indices_y]\n",
        "\n",
        "# # Create scatter plot for non-zero values\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# # Plot X values (Cosine Similarity) in blue\n",
        "# plt.scatter(range(len(x_non_zero)), x_non_zero, color='blue', alpha=0.7, label='Cosine Similarity (X)')\n",
        "\n",
        "# # Plot Y values (Approximation Similarity) in red\n",
        "# plt.scatter(range(len(y_non_zero)), y_non_zero, color='red', alpha=0.7, label='Approximation Similarity (Y)')\n",
        "\n",
        "# # Add labels and title\n",
        "# plt.xlabel('Data Index', fontsize=12)\n",
        "# plt.ylabel('Similarity Values', fontsize=12)\n",
        "# plt.title(f\"Pearson Correlation: {round(corr_pearson,3)} Spearman Correlation: {round(corr_spearman,3)} \"+cofficient, fontsize=14)\n",
        "# plt.legend()\n",
        "# plt.grid(alpha=0.4)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A__UOfDccF4y"
      },
      "source": [
        "## **Clustering and Silouhette**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB7lxnU5cEvk"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.metrics import silhouette_score\n",
        "# from sklearn.cluster import AffinityPropagation\n",
        "# from sklearn.metrics import pairwise_distances\n",
        "# data = np.array([\n",
        "#     [6000, 0, 3000, 0, 0, 0, 0, 0, 0, 0],\n",
        "#     [0, 1500, 0, 0, 0, 0, 0, 0, 0, 3000],\n",
        "#     [0, 1500, 3000, 0, 0, 0, 0, 0, 0, 0],\n",
        "#     [0, 0, 0, 3000, 3000, 0, 0, 0, 0, 0],\n",
        "#     [0, 1500, 0, 0, 3000, 0, 0, 0, 0, 0],\n",
        "#     [0, 0, 0, 0, 0, 6000, 0, 2000, 0, 0],\n",
        "#     [0, 0, 0, 0, 0, 0, 3000, 2000, 0, 0],\n",
        "#     [0, 0, 0, 0, 0, 0, 3000, 2000, 0, 0],     # Added rows assuming the pattern.\n",
        "#     [0, 0, 0, 3000, 0, 0, 0, 0, 6000, 0],\n",
        "#     [0, 1500, 0, 0, 0, 0, 0, 0, 0, 3000]\n",
        "# ])\n",
        "\n",
        "# # Calculate cosine similarity\n",
        "# cosine_dist_opt = pairwise_distances(data, metric='cosine')\n",
        "# cosine_similarities_opt = -cosine_dist_opt  # Convert distances to negative similarities for AP\n",
        "\n",
        "# # Determine the preference based on the cosine similarity matrix\n",
        "# preference = np.median(cosine_similarities_opt)\n",
        "\n",
        "# # Affinity Propagation with cosine similarity\n",
        "# clustering = AffinityPropagation(affinity='precomputed', preference=preference, random_state=42).fit(cosine_similarities_opt)\n",
        "\n",
        "# cluster_labels = clustering.labels_\n",
        "# # Calculate the silhouette score\n",
        "\n",
        "\n",
        "# silhouette_avg_opt = silhouette_score(data[:9], cluster_labels, metric='cosine')\n",
        "# silhouette_avg_cosine = silhouette_score(data, cosine_labels, metric='cosine')\n",
        "# silhouette_avg_method = silhouette_score(data, ID_labels, metric='cosine')\n",
        "\n",
        "\n",
        "# # Organizing the final clusters as [[], [], ...]\n",
        "# num_clusters = len(np.unique(cluster_labels))\n",
        "# clusters = [[] for _ in range(num_clusters)]\n",
        "# for index, label in enumerate(cluster_labels):\n",
        "#     clusters[label].append(index)\n",
        "\n",
        "# # Output the clusters and silhouette score\n",
        "# print(f\"Silhouette Score with[{clusters}]: {silhouette_avg_opt}\")\n",
        "# print(f\"Silhouette Score_cosine with [{cluster_to_list(cosine_labels)}]: {silhouette_avg_cosine}\")\n",
        "# print(f\"Silhouette Score_ID method with [{cluster_to_list(ID_labels)}]: {silhouette_avg_method}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39XCdb7mKcIH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR-54vdiHiRY"
      },
      "source": [
        "## Others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzmvazTDb6rj"
      },
      "outputs": [],
      "source": [
        "# similarity_vector=[]\n",
        "# for p in range (0,100):\n",
        "#     similarity_vector.append(cosine_similarity(params[1], array_prune(params[1], p/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Zd8r-ls87z"
      },
      "outputs": [],
      "source": [
        "# similarity_vector_ID=[]\n",
        "# for p in range (1,100):\n",
        "#     similarity_vector_ID.append(cosine_similarity(params[1], top_to_one_other_zero(params[1], p/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsaAc_1Cb7Vz"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# values = np.random.rand(100)\n",
        "# plt.figure(figsize=(10, 5))  # Optional: Adjust the figure size\n",
        "# plt.plot(similarity_vector, marker='o', linestyle='-', label='similarity of prun')\n",
        "# plt.plot(similarity_vector_ID, marker='o', linestyle='-', label='similarity of ID')\n",
        "# plt.title('Plot of 100 Values')\n",
        "# plt.xlabel('Index')\n",
        "# plt.ylabel('Value')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}