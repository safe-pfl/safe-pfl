{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1OA8n1V3Jt_"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Install Pacakges</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:29.029663Z",
     "iopub.status.busy": "2025-01-07T19:26:29.029371Z",
     "iopub.status.idle": "2025-01-07T19:26:33.546384Z",
     "shell.execute_reply": "2025-01-07T19:26:33.545297Z",
     "shell.execute_reply.started": "2025-01-07T19:26:29.029639Z"
    },
    "id": "bRRfcrFG3JuA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets lxml TinyImageNet --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oO1OslR3JuA"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Import Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:33.547911Z",
     "iopub.status.busy": "2025-01-07T19:26:33.547623Z",
     "iopub.status.idle": "2025-01-07T19:26:39.942778Z",
     "shell.execute_reply": "2025-01-07T19:26:39.942121Z",
     "shell.execute_reply.started": "2025-01-07T19:26:33.547873Z"
    },
    "id": "IWgcTDs4vXBk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import tarfile\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cosine, euclidean, jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tinyimagenet import TinyImageNet\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.model_zoo import tqdm\n",
    "from torchvision.datasets import (CIFAR10, CIFAR100, MNIST, STL10, SVHN,\n",
    "                                  DatasetFolder, FashionMNIST, ImageFolder)\n",
    "from torchvision.datasets.utils import (check_integrity,\n",
    "                                        download_file_from_google_drive)\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChmAsGJP3JuB"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Garbage Collection</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:39.944476Z",
     "iopub.status.busy": "2025-01-07T19:26:39.944044Z",
     "iopub.status.idle": "2025-01-07T19:26:40.076617Z",
     "shell.execute_reply": "2025-01-07T19:26:40.075837Z",
     "shell.execute_reply.started": "2025-01-07T19:26:39.944452Z"
    },
    "id": "JzVjIyuE3JuB",
    "outputId": "592440ec-262a-4a15-f7e2-60e31cfb616b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before memory cleaning:\n",
      "\n",
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n",
      "after memory cleaning:\n",
      "\n",
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "def print_gpu_memory():\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "\n",
    "print(\"before memory cleaning:\\n\")\n",
    "print_gpu_memory()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "print(\"after memory cleaning:\\n\")\n",
    "print_gpu_memory()\n",
    "\n",
    "# ----------- manually clear memory in case of any error\n",
    "#!sudo fuser -v /dev/nvidia* or nvidia-smi\n",
    "# remove all python process ids from gpu\n",
    "#!sudo kill -9 PID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0GQ2etG3JuB"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Make Directories</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.078233Z",
     "iopub.status.busy": "2025-01-07T19:26:40.077961Z",
     "iopub.status.idle": "2025-01-07T19:26:40.338079Z",
     "shell.execute_reply": "2025-01-07T19:26:40.337152Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.078212Z"
    },
    "id": "xCdedy7p3JuB",
    "outputId": "3433e7a0-910f-4264-ce78-226fe36591c1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir models\n",
    "!mkdir models/before_aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-XrkWV93JuB"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Configs</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.339254Z",
     "iopub.status.busy": "2025-01-07T19:26:40.339043Z",
     "iopub.status.idle": "2025-01-07T19:26:40.400118Z",
     "shell.execute_reply": "2025-01-07T19:26:40.399264Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.339236Z"
    },
    "id": "_X_jTe9C3JuB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"darkgrid\", font_scale=1.5, rc={\"axes.unicode_minus\": False}\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# to produce reproducible results (like random.seed())\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.401359Z",
     "iopub.status.busy": "2025-01-07T19:26:40.401049Z",
     "iopub.status.idle": "2025-01-07T19:26:40.406443Z",
     "shell.execute_reply": "2025-01-07T19:26:40.405775Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.401329Z"
    },
    "id": "qVX67JHf3JuB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CLUSTERING_PERIOD = 1           # Set to `1` to run simple Federated Learning with out clustering\n",
    "FEDERATED_LEARNING_ROUNDS = 1   # The round in with Federated Learning will be executed\n",
    "\"\"\"\n",
    "|MODEL_TYPE |  DATASET_TYPE    | NUMBER_OF_CLASSES| PARTITION      | ROUND_EPOCHS| SENSITIVITY_PERCENTAGE   | TRAIN/TEST_BATCH_SIZE | TRANSFORM_INPUT_SIZE  |\n",
    "|-----------|------------------|------------------|----------------|-------------|--------------------------|-----------------------|-----------------------|\n",
    "|cnn        |  fmnist          | 10               | noniid-#label2 | 1           | 10                       | 128                   | 128                   |\n",
    "|resnet18   |  cifar10         | 10               | noniid-#label2 | 1           | 10                       | 128                   | 128                   |\n",
    "|resnet50   |  cifar100        | 100              | noniid-#label20| 5           | 10                       | 128                   | 32                    |\n",
    "|mobilenet  |  svhn            | 10               | noniid-#label2 | 1           | 10                       | 64                    | 224                   |\n",
    "|vgg16      |  stl10           | 10               | noniid-#label2 | 10          | 20                       | 16                    | 128                   |\n",
    "|alexnet    |  tinyimagenet    | 200              | noniid-#label10| 10          | 20                       | 128                   | 64                    |\n",
    "|-----------|------------------|------------------|----------------|-------------|--------------------------|-----------------------|-----------------------|\n",
    "\"\"\"\n",
    "MODEL_TYPE = \"alexnet\"\n",
    "DATASET_TYPE = \"svhn\"\n",
    "\n",
    "TRANSFORM_INPUT_SIZE=64    # just works for svhn/stl10 dataset transformer\n",
    "TRAIN_BATCH_SIZE=128\n",
    "TEST_BATCH_SIZE=128\n",
    "# by default set to 0.001 and for AlexNet set to 0.0001\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY=1e-4\n",
    "NUMBER_OF_CLASSES = 10\n",
    "NUMBER_OF_CLIENTS = 10\n",
    "# the second part accepted format is: \"labeldir\" (Dirichlet) or \"#label20\"\n",
    "PARTITION = \"noniid-\" + \"#label2\"\n",
    "# set to 10 for AlexNet\n",
    "ROUND_EPOCHS = 6\n",
    "DIRICHLET_BETA=0.1\n",
    "SENSITIVITY_PERCENTAGE = 10\n",
    "\"\"\"\n",
    "DISTANCE_METRIC values are:\n",
    "- coordinate\n",
    "- cosine\n",
    "- euclidean\n",
    "- jensen-shannon\n",
    "- wasserstein\n",
    "\"\"\"\n",
    "DISTANCE_METRIC = \"cosine\"\n",
    "# cosine similarity options\n",
    "JUST_COMPARE_SIGNIFICANCE=False\n",
    "ZERO_INSIGNIFICANT_IN_BOTH=False\n",
    "COMPARE_MOST_SIGNIFICANCE_ONE=False\n",
    "COMPARE_LESS_SIGNIFICANCE_ZERO=False   # Set to True for `Selective Parameter Cosine` when `DISTANCE_METRIC` is `cosine` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.407373Z",
     "iopub.status.busy": "2025-01-07T19:26:40.407165Z",
     "iopub.status.idle": "2025-01-07T19:26:40.425838Z",
     "shell.execute_reply": "2025-01-07T19:26:40.425126Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.407348Z"
    },
    "id": "uu3Fu3A3qnPR",
    "outputId": "45cda9ce-b5d6-4d22-8419-861beac9014a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: The Model=alexnet-Dataset=svhn-N=noniid-#label2-P=10_on=cosine_at=2025-01-09_00.log will be truncated at each run\n"
     ]
    }
   ],
   "source": [
    "log_path = None\n",
    "\n",
    "log_path = datetime.now().strftime(f\"Model={MODEL_TYPE}-Dataset={DATASET_TYPE}-N={PARTITION}-P={SENSITIVITY_PERCENTAGE}_on={DISTANCE_METRIC}_at=%Y-%m-%d_%H\")\n",
    "\n",
    "log_file = log_path + \".log\"\n",
    "print(f\"ATTENTION: The {log_file} will be truncated at each run\")\n",
    "open(log_file,  \"w\").close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSl3rZx23JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Model Network</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.428321Z",
     "iopub.status.busy": "2025-01-07T19:26:40.428076Z",
     "iopub.status.idle": "2025-01-07T19:26:40.441904Z",
     "shell.execute_reply": "2025-01-07T19:26:40.441145Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.428301Z"
    },
    "id": "evEmrviBwIoH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        if MODEL_TYPE == \"resnet18\":\n",
    "            self.resnet = models.resnet18(pretrained=False)\n",
    "            if DATASET_TYPE == \"mnist\":\n",
    "                self.resnet.conv1 = nn.Conv2d(\n",
    "                    1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "                )\n",
    "            self.resnet.fc = nn.Linear(\n",
    "                self.resnet.fc.in_features, NUMBER_OF_CLASSES\n",
    "            )\n",
    "        elif MODEL_TYPE == \"resnet50\":\n",
    "            self.resnet = models.resnet50(pretrained=False)\n",
    "            self.resnet.fc = nn.Linear(self.resnet.fc.in_features, NUMBER_OF_CLASSES)\n",
    "        elif MODEL_TYPE == \"cnn\":\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        elif MODEL_TYPE == \"mobilenet\":\n",
    "            self.mobilenet_v3_large = models.mobilenet_v3_large(pretrained=False)\n",
    "            self.mobilenet_v3_large.classifier[3] = nn.Linear(self.mobilenet_v3_large.classifier[3].in_features, NUMBER_OF_CLASSES)\n",
    "\n",
    "        elif MODEL_TYPE == \"vgg16\":\n",
    "            self.vgg16 = models.vgg11(pretrained=False)\n",
    "            self.vgg16.classifier[6] = nn.Linear(4096, NUMBER_OF_CLASSES)\n",
    "\n",
    "        elif MODEL_TYPE == \"alexnet\":\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Output: 64x32x32\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 64x16x16\n",
    "                nn.Conv2d(64, 192, kernel_size=3, padding=1),  # Output: 192x16x16\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 192x8x8\n",
    "                nn.Conv2d(192, 384, kernel_size=3, padding=1),  # Output: 384x8x8\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384, 256, kernel_size=3, padding=1),  # Output: 256x8x8\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Output: 256x8x8\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 256x4x4\n",
    "            )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 4 * 4, 4096),  # Updated input size to 4096\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, NUMBER_OF_CLASSES),  # Output size matches CIFAR-10 classes (10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "\n",
    "        if MODEL_TYPE in [\"resnet18\", \"resnet50\"]:\n",
    "            out = self.resnet(x)\n",
    "        elif MODEL_TYPE == \"cnn\":\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(x.size(0), 16 * 4 * 4)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            out = x\n",
    "\n",
    "        elif MODEL_TYPE == \"mobilenet\":\n",
    "            out = self.mobilenet_v3_large(x)\n",
    "\n",
    "        elif MODEL_TYPE == \"vgg16\":\n",
    "            out = self.vgg16(x)\n",
    "\n",
    "        elif MODEL_TYPE == \"alexnet\":\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            out = x\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiowr9l83JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Learning</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.443366Z",
     "iopub.status.busy": "2025-01-07T19:26:40.443168Z",
     "iopub.status.idle": "2025-01-07T19:26:40.460713Z",
     "shell.execute_reply": "2025-01-07T19:26:40.460052Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.443342Z"
    },
    "id": "cCM4LUpzwTXE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "def train(net, node_id, train_loader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # if MODEL_TYPE != \"alexnet\": \n",
    "    if True: \n",
    "        optimizer = torch.optim.Adam(\n",
    "            net.parameters(),\n",
    "            lr=LEARNING_RATE,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-7,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Return the final accuracy and loss\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "def test(net, test_loader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVgowNUE3JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Client</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.461782Z",
     "iopub.status.busy": "2025-01-07T19:26:40.461519Z",
     "iopub.status.idle": "2025-01-07T19:26:40.480520Z",
     "shell.execute_reply": "2025-01-07T19:26:40.479857Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.461754Z"
    },
    "id": "pZKNLgYs3JuC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, net, node_id, train_loader, test_loader):\n",
    "        self.net = net.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.node_id = node_id\n",
    "        self.train_acc, self.test_acc = 0.0, 0.0\n",
    "        self.global_net = Net().to(DEVICE)\n",
    "\n",
    "    def set_bias(self, pref, bias):\n",
    "        self.bias = bias\n",
    "        self.pref = pref\n",
    "\n",
    "    def set_shard(self, shard):\n",
    "        self.shard = shard\n",
    "\n",
    "    def get_global_net(self):\n",
    "        return self.global_net\n",
    "\n",
    "    def setting_parameters(self, parameters: List[np.ndarray]):\n",
    "        params_dict = zip(self.net.state_dict().items(), parameters)\n",
    "        state_dict = OrderedDict(\n",
    "            {k: torch.Tensor(v).to(DEVICE) for k, v in params_dict}\n",
    "        )\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def getting_parameters(self) -> List[np.ndarray]:\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters):\n",
    "        self.setting_parameters(parameters)\n",
    "        train(self.net, self.node_id, self.train_loader, epochs=ROUND_EPOCHS)\n",
    "        return self.getting_parameters(), len(self.train_loader), {}\n",
    "\n",
    "    def evaluate(self, parameters):\n",
    "        self.setting_parameters(parameters)\n",
    "        loss, accuracy = test(self.net, self.test_loader)\n",
    "        return float(loss), len(self.test_loader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    def Train_test_and_return_acc(self):\n",
    "        self.train_acc, _ = train(self.net, self.node_id, self.train_loader, ROUND_EPOCHS)\n",
    "        self.test_acc, _ = test(self.net, self.test_loader)\n",
    "        return self.train_acc, self.test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0snFUi-3JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Server</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.481402Z",
     "iopub.status.busy": "2025-01-07T19:26:40.481169Z",
     "iopub.status.idle": "2025-01-07T19:26:40.498106Z",
     "shell.execute_reply": "2025-01-07T19:26:40.497534Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.481383Z"
    },
    "id": "0SW7jKZNwbhJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def divide_nested_list(nested_list, divisor):\n",
    "    for i in range(len(nested_list)):\n",
    "        if isinstance(nested_list[i], list):\n",
    "            divide_nested_list(nested_list[i], divisor)\n",
    "        else:\n",
    "            nested_list[i] /= divisor\n",
    "    return nested_list\n",
    "\n",
    "\n",
    "def zero_nested_list(nested_list):\n",
    "    for i in range(len(nested_list)):\n",
    "        if isinstance(nested_list[i], list):\n",
    "            zero_nested_list(nested_list[i])\n",
    "        else:\n",
    "            nested_list[i] = 0\n",
    "    return nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.499202Z",
     "iopub.status.busy": "2025-01-07T19:26:40.498958Z",
     "iopub.status.idle": "2025-01-07T19:26:40.516301Z",
     "shell.execute_reply": "2025-01-07T19:26:40.515458Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.499173Z"
    },
    "id": "mw8QL1Qn3JuC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "\n",
    "    def append_model(self, model: nn.Module):\n",
    "        if not isinstance(model, nn.Module):\n",
    "            raise TypeError(\"Only instances of nn.Module can be appended\")\n",
    "        self.models.append(model)\n",
    "\n",
    "    def aggregate(self):\n",
    "        if not self.models:\n",
    "            raise ValueError(\"No models added to the server.\")\n",
    "        print(\"model numbers:\", len(self.models))\n",
    "        device = next(self.models[0].parameters()).device\n",
    "        for model in self.models:\n",
    "            model.to(device)\n",
    "        avg_model = Net().to(device)\n",
    "        with torch.no_grad():\n",
    "            for param_name, avg_param in avg_model.named_parameters():\n",
    "                temp = torch.zeros_like(avg_param)\n",
    "                for model in self.models:\n",
    "                    model_param = dict(model.named_parameters())[param_name]\n",
    "                    temp += model_param.data\n",
    "                avg_param.copy_(temp / len(self.models))\n",
    "        return avg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5a5ikHf3JuC"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Clustering</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.517305Z",
     "iopub.status.busy": "2025-01-07T19:26:40.517050Z",
     "iopub.status.idle": "2025-01-07T19:26:40.543938Z",
     "shell.execute_reply": "2025-01-07T19:26:40.543108Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.517276Z"
    },
    "id": "asSZtfDAwmrd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_num_cluster(clusters):\n",
    "    num_cluster = []\n",
    "    for item in clusters:\n",
    "        if item not in num_cluster:\n",
    "            num_cluster.append(item)\n",
    "    return len(num_cluster)\n",
    "\n",
    "\n",
    "class Clustering:\n",
    "    def __init__(self, clients, trainLoaders, percentage):\n",
    "        self.clients = clients\n",
    "        self.num_nodes = len(clients)\n",
    "        self.percentage = percentage\n",
    "        self.Mask_Number = 0\n",
    "        self.maskIds = []\n",
    "        self.grads = []\n",
    "        self.load_and_calculate_sensitivity(trainLoaders)\n",
    "        self.distances = self.calculate_distance()\n",
    "        self.Clusters = self.make_clusters()\n",
    "\n",
    "    def assign_save_ids_to_weights(self, model):\n",
    "        weight_id_map = {}\n",
    "        weight_id = 0\n",
    "        for name, parameter in model.named_parameters():\n",
    "            weight_id_map[name] = {}\n",
    "            num_weights = parameter.numel()\n",
    "            for i in range(num_weights):\n",
    "                weight_id_map[name][i] = weight_id\n",
    "                weight_id += 1\n",
    "        filename = \"weight_to_id.csv\"\n",
    "        if not os.path.exists(filename):\n",
    "            with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([\"Layer\", \"Weight Index\", \"Weight ID\"])\n",
    "                for layer_name, indices in weight_id_map.items():\n",
    "                    for index, weight_id in indices.items():\n",
    "                        writer.writerow([layer_name, index, weight_id])\n",
    "        return weight_id_map\n",
    "\n",
    "    def load_and_calculate_sensitivity(self, trainLoaders):\n",
    "        \"\"\"\n",
    "        Calculate sensitivity for each client and store the results in the object.\n",
    "        \"\"\"\n",
    "        for cid in self.clients:\n",
    "            model = load_torch_model(cid).to(DEVICE)\n",
    "            # testing\n",
    "            model.eval()\n",
    "            sensitivity_value = self.calculate_sensitivity(\n",
    "                model, trainLoaders[int(cid)]\n",
    "            )\n",
    "            weight_id_map = self.assign_save_ids_to_weights(\n",
    "                load_torch_model(0).to(DEVICE)\n",
    "            )\n",
    "\n",
    "            mask_ID, weights = self.get_maskIds(\n",
    "                sensitivity_value, weight_id_map, self.percentage\n",
    "            )  # top sensitive weights will filter here\n",
    "            print(f\"Model weights and sensitivity data for client #{cid} processed.\")\n",
    "\n",
    "            self.maskIds.append(mask_ID)\n",
    "            self.grads.append(weights)\n",
    "\n",
    "    def calculate_sensitivity(self, model, dataloader):\n",
    "        # model.train()\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        gradient_sums = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            gradient_sums[name] = 0.0\n",
    "            param.requires_grad_(True)\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sensitivities = {}\n",
    "            for name, parameter in model.named_parameters():\n",
    "                grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
    "                for i, grad in enumerate(grads):\n",
    "                    sensitivities[(name, i)] = grad\n",
    "            return sensitivities\n",
    "\n",
    "    def get_maskIds(self, sensitivity_values_node, weight_id_map, sensitive_percentage):\n",
    "        num_weights = len(sensitivity_values_node)\n",
    "        top_k = int(np.ceil(sensitive_percentage * num_weights / 100))\n",
    "        self.Mask_Number = top_k\n",
    "        sorted_weights = sorted(\n",
    "            sensitivity_values_node.items(), key=lambda item: item[1], reverse=True\n",
    "        )[:top_k]\n",
    "        weights = [weight for (layer, index), weight in sensitivity_values_node.items()]\n",
    "        top_weight_ids = [\n",
    "            weight_id_map[layer][index] for (layer, index), _ in sorted_weights\n",
    "        ]\n",
    "        return top_weight_ids, weights\n",
    "\n",
    "    def normalize(self, distances, sensitive):\n",
    "        normal_distances = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        for i in range(self.num_nodes):\n",
    "            normal_distances[i][i] = 0\n",
    "            for j in range(i + 1, self.num_nodes):\n",
    "                normal_distances[i][j] = normal_distances[j][i] = distances[i][j] / len(\n",
    "                    sensitive\n",
    "                )\n",
    "        return normal_distances\n",
    "\n",
    "    def calculate_common_ids(self, index1, index2):\n",
    "        arr1 = self.maskIds[index1]\n",
    "        arr2 = self.maskIds[index2]\n",
    "        sarr1 = set(arr1)\n",
    "        sarr2 = set(arr2)\n",
    "        inter = sarr1.intersection(sarr2)\n",
    "        similarity1 = len(inter)\n",
    "        return similarity1\n",
    "\n",
    "    def calculate_distance(\n",
    "        self,\n",
    "    ):\n",
    "        similarity_matrix = np.zeros((self.num_nodes, self.num_nodes))\n",
    "\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(i + 1, self.num_nodes):\n",
    "\n",
    "                if DISTANCE_METRIC == \"coordinate\":\n",
    "                    similarity = self.calculate_common_ids(i, j)\n",
    "                elif DISTANCE_METRIC == \"cosine\":\n",
    "                    if JUST_COMPARE_SIGNIFICANCE:\n",
    "                        np_grad_i = np.array(self.grads[i])\n",
    "                        np_grad_j = np.array(self.grads[j])\n",
    "                        grad_i_significant_indices = (\n",
    "                            self.get_significant_weights_indices(np_grad_i)\n",
    "                        )\n",
    "                        grad_j_significant_indices = (\n",
    "                            self.get_significant_weights_indices(np_grad_j)\n",
    "                        )\n",
    "                        grad_i_significant_weights = np_grad_i[\n",
    "                            grad_i_significant_indices\n",
    "                        ]\n",
    "                        grad_j_significant_weights = np_grad_j[\n",
    "                            grad_j_significant_indices\n",
    "                        ]\n",
    "                        similarity = 1 - cosine(\n",
    "                            grad_i_significant_weights, grad_j_significant_weights\n",
    "                        )\n",
    "                    elif ZERO_INSIGNIFICANT_IN_BOTH:\n",
    "                        modified_grads_i, modified_grads_j = (\n",
    "                            self.zero_insignificant_in_both(\n",
    "                                np.array(self.grads[i]), np.array(self.grads[j])\n",
    "                            )\n",
    "                        )\n",
    "                        similarity = 1 - cosine(modified_grads_i, modified_grads_j)\n",
    "                    elif COMPARE_MOST_SIGNIFICANCE_ONE:\n",
    "                        grad_i = np.array(self.grads[i])\n",
    "                        grad_j = self.set_top_percent_to_one(np.array(self.grads[j]))\n",
    "                        similarity = 1 - cosine(grad_i, grad_j)\n",
    "                    elif COMPARE_LESS_SIGNIFICANCE_ZERO:\n",
    "                        grad_i = np.array(self.grads[i])\n",
    "                        grad_j = self.set_least_significant_to_zero(\n",
    "                            np.array(self.grads[j])\n",
    "                        )\n",
    "                        similarity = 1 - cosine(grad_i, grad_j)\n",
    "                    else:\n",
    "                        similarity = 1 - cosine(self.grads[i], self.grads[j])\n",
    "                elif DISTANCE_METRIC == \"euclidean\":\n",
    "                    # Euclidean distance\n",
    "                    similarity = -euclidean(\n",
    "                        self.grads[i], self.grads[j]\n",
    "                    )  # Negative for clustering\n",
    "                elif DISTANCE_METRIC == \"jensen-shannon\":\n",
    "                    # Jensen-Shannon divergence\n",
    "                    similarity = -jensenshannon(\n",
    "                        self.grads[i], self.grads[j]\n",
    "                    )  # Negative for clustering\n",
    "                elif DISTANCE_METRIC == \"wasserstein\":\n",
    "                    # Wasserstein distance\n",
    "                    similarity = -wasserstein_distance(\n",
    "                        self.grads[i], self.grads[j]\n",
    "                    )  # Negative for clustering\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported distance metric: {DISTANCE_METRIC}\")\n",
    "                similarity_matrix[i, j] = similarity\n",
    "                similarity_matrix[j, i] = similarity\n",
    "            similarity_matrix[i, i] = self.Mask_Number\n",
    "        distances = self.Mask_Number - similarity_matrix\n",
    "\n",
    "        self.save_distances_to_csv(distances)\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(\"\\n Start of the Similarity matrix\")\n",
    "            f.write(f\"\\n{distances}\")\n",
    "            f.write(\"\\n End of Similarity matrix\")\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def index_to_value(self, groups):\n",
    "        value_groups = []\n",
    "        for group in groups:\n",
    "            list1 = []\n",
    "            for index in group:\n",
    "                list1.append(self.clients[index])\n",
    "            value_groups.append(list1)\n",
    "        return value_groups\n",
    "\n",
    "    def make_clusters(self):\n",
    "        normal_distances = (self.distances + self.distances.T) / 2\n",
    "        np.fill_diagonal(normal_distances, 0)\n",
    "        affinity_propagation = AffinityPropagation(affinity=\"precomputed\")\n",
    "        normal_distances = -normal_distances\n",
    "        clusters = affinity_propagation.fit_predict(normal_distances)\n",
    "        print(f\"cluster results:{clusters}\")\n",
    "        # Find the maximum cluster label from the assigned labels\n",
    "        max_label = max(clusters)\n",
    "        # Assign unique positive labels to noise points (initially labeled as -1)\n",
    "        noise_indices = clusters == -1\n",
    "        unique_noise_labels = np.arange(\n",
    "            max_label + 1, max_label + 1 + np.sum(noise_indices)\n",
    "        )\n",
    "        clusters[noise_indices] = unique_noise_labels\n",
    "        cluster_list = [\n",
    "            np.where(clusters == cluster_id)[0].tolist()\n",
    "            for cluster_id in range(find_num_cluster(clusters))\n",
    "        ]\n",
    "        cluster_list = self.index_to_value(cluster_list)\n",
    "        return cluster_list\n",
    "\n",
    "    def save_distances_to_csv(self, distances):\n",
    "        \"\"\"\n",
    "        Save the distance matrix to a CSV file.\n",
    "        \"\"\"\n",
    "        filename = f\"distances_{DISTANCE_METRIC}.csv\"\n",
    "        with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Node\"] + [f\"Node_{i}\" for i in range(self.num_nodes)])\n",
    "            for i, row in enumerate(distances):\n",
    "                writer.writerow([f\"Node_{i}\"] + row.tolist())\n",
    "\n",
    "        print(f\"Distance matrix saved to {filename}\")\n",
    "\n",
    "    def set_top_percent_to_one(self, arr):\n",
    "        modified_array = np.copy(arr)\n",
    "        num_elements_to_set = int(len(arr) * self.percentage / 100)\n",
    "        if num_elements_to_set == 0:\n",
    "            return modified_array\n",
    "        indices_to_set = np.argpartition(modified_array, -num_elements_to_set)[\n",
    "            -num_elements_to_set:\n",
    "        ]\n",
    "        modified_array[indices_to_set] = 1\n",
    "        return modified_array\n",
    "\n",
    "    def set_least_significant_to_zero(self, arr):\n",
    "        modified_array = np.copy(arr)\n",
    "        num_elements_to_zero = int(len(arr) * (100 - self.percentage) / 100)\n",
    "        if num_elements_to_zero == 0:\n",
    "            return modified_array\n",
    "        indices_to_zero = np.argpartition(modified_array, num_elements_to_zero)[\n",
    "            :num_elements_to_zero\n",
    "        ]\n",
    "        modified_array[indices_to_zero] = 0\n",
    "        return modified_array\n",
    "\n",
    "    def get_significant_weights_indices(self, arr):\n",
    "        num_elements = len(arr)\n",
    "        num_significant = int(np.ceil(num_elements * self.percentage / 100))\n",
    "        if num_significant == 0:\n",
    "            return np.array([], dtype=int)\n",
    "        significant_indices = np.argpartition(-arr, num_significant - 1)[\n",
    "            :num_significant\n",
    "        ]\n",
    "        significant_indices = significant_indices[np.argsort(-arr[significant_indices])]\n",
    "        return significant_indices\n",
    "\n",
    "    def zero_insignificant_in_both(self, arr_i, arr_j):\n",
    "        num_params = len(arr_i)\n",
    "        significant_indices_i = self.get_significant_weights_indices(arr_i)\n",
    "        significant_indices_j = self.get_significant_weights_indices(arr_j)\n",
    "        all_indices = set(range(num_params))\n",
    "        insignificant_in_i = all_indices - set(significant_indices_i)\n",
    "        insignificant_in_j = all_indices - set(significant_indices_j)\n",
    "        insignificant_in_both = insignificant_in_i.intersection(insignificant_in_j)\n",
    "        modified_arr_i = np.copy(arr_i)\n",
    "        modified_arr_j = np.copy(arr_j)\n",
    "        insignificant_in_both = np.array(list(insignificant_in_both), dtype=int)\n",
    "        modified_arr_i[insignificant_in_both] = 0\n",
    "        modified_arr_j[insignificant_in_both] = 0\n",
    "        return modified_arr_i, modified_arr_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAturGl13JuD"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Federated Learning</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.544994Z",
     "iopub.status.busy": "2025-01-07T19:26:40.544700Z",
     "iopub.status.idle": "2025-01-07T19:26:40.565567Z",
     "shell.execute_reply": "2025-01-07T19:26:40.564860Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.544967Z"
    },
    "id": "DyY6UPxMw0EA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FL:\n",
    "    def __init__(\n",
    "        self,\n",
    "        clients,\n",
    "        client_initial_models,\n",
    "        round_number,\n",
    "        train_loaders,\n",
    "        test_loaders,\n",
    "        SENSITIVITY_PERCENTAGE,\n",
    "    ):\n",
    "        self.clients = clients\n",
    "        self.NUMBER_OF_CLIENTS = len(clients)\n",
    "        self.client_initial_models = client_initial_models\n",
    "        self.SENSITIVITY_PERCENTAGE = SENSITIVITY_PERCENTAGE\n",
    "        self.train_loaders = train_loaders\n",
    "        self.test_loaders = test_loaders\n",
    "        self.round_number = round_number\n",
    "        self.global_model = None\n",
    "        self.clustering_result = None\n",
    "        self.client_obj_list = []\n",
    "        self.accuracies = {}\n",
    "        self.training()\n",
    "\n",
    "    def training(self):\n",
    "        for cid in self.clients:\n",
    "            print(\"cid is:\", cid)\n",
    "            client = Client(\n",
    "                self.client_initial_models[self.clients.index(int(cid))],\n",
    "                cid,\n",
    "                self.train_loaders[int(cid)],\n",
    "                self.test_loaders[int(cid)],\n",
    "            )\n",
    "            self.client_obj_list.append(client)\n",
    "        global_model = Net()\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        start_time = datetime.now()\n",
    "        for r in range(self.round_number):\n",
    "            print(f\"\\nRound {r+1}/{self.round_number}\")\n",
    "            server = Server()\n",
    "            global_accuracy = 0\n",
    "            for cid in self.clients:\n",
    "                train_acc, test_acc = self.client_obj_list[\n",
    "                    self.clients.index(cid)\n",
    "                ].Train_test_and_return_acc()\n",
    "                print(\n",
    "                    \"_____________________________________________________________________________________________________________\"\n",
    "                )\n",
    "                print(f\"node {cid}: train_acc: {train_acc}, test_acc:{test_acc}\")\n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"\\nNode {cid} - Round {r+1}: Train Accuracy: {train_acc}%, Test Accuracy: {test_acc}%\"\n",
    "                    )\n",
    "                global_accuracy += test_acc\n",
    "                server.append_model(self.client_obj_list[self.clients.index(cid)].net)\n",
    "            global_model = server.aggregate()\n",
    "            # global_model = server.aggregate_prox(global_model)\n",
    "            end_time = datetime.now()\n",
    "            execution_time = end_time - start_time\n",
    "            print(\"time\", execution_time)\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(f\"\\n Exe FL Round Time: {execution_time}\")\n",
    "            # global_model, c = server.aggregate_scaffold(global_model, client_controls, c)\n",
    "            print(\"global acc:\", global_accuracy / self.NUMBER_OF_CLIENTS)\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(\n",
    "                    f\"\\nGlobal Model of {self.NUMBER_OF_CLIENTS}- Round {r+1}: Test Accuracy is: {global_accuracy/self.NUMBER_OF_CLIENTS}%\"\n",
    "                )\n",
    "            for cid in self.clients:\n",
    "                model_path = f\"models/before_aggregation/node_{cid}.pth\"\n",
    "                torch.save(\n",
    "                    self.client_obj_list[self.clients.index(cid)].net.state_dict(),\n",
    "                    model_path,\n",
    "                )\n",
    "                self.client_obj_list[self.clients.index(cid)].net = copy.deepcopy(\n",
    "                    global_model\n",
    "                )\n",
    "        self.global_model = global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSKd2tLw3JuD"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Loading & Saving</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.566415Z",
     "iopub.status.busy": "2025-01-07T19:26:40.566182Z",
     "iopub.status.idle": "2025-01-07T19:26:40.583010Z",
     "shell.execute_reply": "2025-01-07T19:26:40.582367Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.566397Z"
    },
    "id": "LazN3rY5xDiZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_torch_model(node_id):\n",
    "    model_path = f\"models/node_{node_id}.pth\"\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_torch_model(model, node_id):\n",
    "    model_path = f\"models/node_{node_id}.pth\"\n",
    "    torch.save(model, model_path)\n",
    "\n",
    "\n",
    "def save_model_param(model, node_id, round_number):\n",
    "    model_path = f\"models/node_{node_id}_round_{round_number}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq920RVv3JuD"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Non-IID Distribution</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.584135Z",
     "iopub.status.busy": "2025-01-07T19:26:40.583854Z",
     "iopub.status.idle": "2025-01-07T19:26:40.652012Z",
     "shell.execute_reply": "2025-01-07T19:26:40.651320Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.584109Z"
    },
    "id": "eGjDwC9x3JuD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "IMG_EXTENSIONS = (\n",
    "    \".jpg\",\n",
    "    \".jpeg\",\n",
    "    \".png\",\n",
    "    \".ppm\",\n",
    "    \".bmp\",\n",
    "    \".pgm\",\n",
    "    \".tif\",\n",
    "    \".tiff\",\n",
    "    \".webp\",\n",
    ")\n",
    "\n",
    "\n",
    "def mkdirs(dirpath):\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except Exception as _:\n",
    "        pass\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, \"rb\") as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert(\"RGB\")\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "\n",
    "    if get_image_backend() == \"accimage\":\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "class CustomTensorDataset(data.TensorDataset):\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors) + (index,)\n",
    "\n",
    "\n",
    "class MNIST_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        mnist_dataobj = MNIST(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = mnist_dataobj.data\n",
    "        target = mnist_dataobj.targets\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class FashionMNIST_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        mnist_dataobj = FashionMNIST(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = mnist_dataobj.data\n",
    "        target = mnist_dataobj.targets\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class SVHN_custom(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "        if self.train is True:\n",
    "\n",
    "            svhn_dataobj = SVHN(\n",
    "                self.root, \"train\", self.transform, self.target_transform, self.download\n",
    "            )\n",
    "            data = svhn_dataobj.data\n",
    "            target = svhn_dataobj.labels\n",
    "        else:\n",
    "            svhn_dataobj = SVHN(\n",
    "                self.root, \"test\", self.transform, self.target_transform, self.download\n",
    "            )\n",
    "            data = svhn_dataobj.data\n",
    "            target = svhn_dataobj.labels\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "# torchvision CelebA\n",
    "class CelebA_custom(VisionDataset):\n",
    "    \"\"\"`Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where images are downloaded to.\n",
    "        split (string): One of {'train', 'valid', 'test', 'all'}.\n",
    "            Accordingly dataset is selected.\n",
    "        target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
    "            or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
    "            The targets represent:\n",
    "                ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
    "                ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
    "                ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
    "                ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
    "                    righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
    "            Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "\n",
    "    base_folder = \"celeba\"\n",
    "    # There currently does not appear to be a easy way to extract 7z in python (without introducing additional\n",
    "    # dependencies). The \"in-the-wild\" (not aligned+cropped) images are only in 7z, so they are not available\n",
    "    # right now.\n",
    "    file_list = [\n",
    "        # File ID                         MD5 Hash                            Filename\n",
    "        (\n",
    "            \"0B7EVK8r0v71pZjFTYXZWM3FlRnM\",\n",
    "            \"00d2c5bc6d35e252742224ab0c1e8fcb\",\n",
    "            \"img_align_celeba.zip\",\n",
    "        ),\n",
    "        # (\"0B7EVK8r0v71pbWNEUjJKdDQ3dGc\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_align_celeba_png.7z\"),\n",
    "        # (\"0B7EVK8r0v71peklHb0pGdDl6R28\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_celeba.7z\"),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pblRyaVFSWGxPY0U\",\n",
    "            \"75e246fa4810816ffd6ee81facbd244c\",\n",
    "            \"list_attr_celeba.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\",\n",
    "            \"32bd1bd63d3c78cd57e08160ec5ed1e2\",\n",
    "            \"identity_CelebA.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pbThiMVRxWXZ4dU0\",\n",
    "            \"00566efa6fedff7a56946cd1c10f1c16\",\n",
    "            \"list_bbox_celeba.txt\",\n",
    "        ),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pd0FJY3Blby1HUTQ\",\n",
    "            \"cc24ecafdb5b50baae59b03474781f8c\",\n",
    "            \"list_landmarks_align_celeba.txt\",\n",
    "        ),\n",
    "        # (\"0B7EVK8r0v71pTzJIdlJWdHczRlU\", \"063ee6ddb681f96bc9ca28c6febb9d1a\", \"list_landmarks_celeba.txt\"),\n",
    "        (\n",
    "            \"0B7EVK8r0v71pY0NSMzRuSXJEVkk\",\n",
    "            \"d32c9cbf5e040fd4025c592c306e6668\",\n",
    "            \"list_eval_partition.txt\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        split=\"train\",\n",
    "        target_type=\"attr\",\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "        import pandas\n",
    "\n",
    "        super(CelebA_custom, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.split = split\n",
    "        if isinstance(target_type, list):\n",
    "            self.target_type = target_type\n",
    "        else:\n",
    "            self.target_type = [target_type]\n",
    "\n",
    "        if not self.target_type and self.target_transform is not None:\n",
    "            raise RuntimeError(\"target_transform is specified but target_type is empty\")\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found or corrupted.\"\n",
    "                + \" You can use download=True to download it\"\n",
    "            )\n",
    "\n",
    "        split_map = {\n",
    "            \"train\": 0,\n",
    "            \"valid\": 1,\n",
    "            \"test\": 2,\n",
    "            \"all\": None,\n",
    "        }\n",
    "        split = split_map[split.lower()]\n",
    "\n",
    "        fn = partial(os.path.join, self.root, self.base_folder)\n",
    "        splits = pandas.read_csv(\n",
    "            fn(\"list_eval_partition.txt\"),\n",
    "            delim_whitespace=True,\n",
    "            header=None,\n",
    "            index_col=0,\n",
    "        )\n",
    "        identity = pandas.read_csv(\n",
    "            fn(\"identity_CelebA.txt\"), delim_whitespace=True, header=None, index_col=0\n",
    "        )\n",
    "        bbox = pandas.read_csv(\n",
    "            fn(\"list_bbox_celeba.txt\"), delim_whitespace=True, header=1, index_col=0\n",
    "        )\n",
    "        landmarks_align = pandas.read_csv(\n",
    "            fn(\"list_landmarks_align_celeba.txt\"), delim_whitespace=True, header=1\n",
    "        )\n",
    "        attr = pandas.read_csv(\n",
    "            fn(\"list_attr_celeba.txt\"), delim_whitespace=True, header=1\n",
    "        )\n",
    "\n",
    "        mask = slice(None) if split is None else (splits[1] == split)\n",
    "\n",
    "        self.filename = splits[mask].index.values\n",
    "        self.identity = torch.as_tensor(identity[mask].values)\n",
    "        self.bbox = torch.as_tensor(bbox[mask].values)\n",
    "        self.landmarks_align = torch.as_tensor(landmarks_align[mask].values)\n",
    "        self.attr = torch.as_tensor(attr[mask].values)\n",
    "        self.attr = (self.attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
    "        self.attr_names = list(attr.columns)\n",
    "        self.gender_index = self.attr_names.index(\"Male\")\n",
    "        self.dataidxs = dataidxs\n",
    "        if self.dataidxs is None:\n",
    "            self.target = self.attr[\n",
    "                :, self.gender_index : self.gender_index + 1\n",
    "            ].reshape(-1)\n",
    "        else:\n",
    "            self.target = self.attr[\n",
    "                self.dataidxs, self.gender_index : self.gender_index + 1\n",
    "            ].reshape(-1)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        for _, md5, filename in self.file_list:\n",
    "            fpath = os.path.join(self.root, self.base_folder, filename)\n",
    "            _, ext = os.path.splitext(filename)\n",
    "            # Allow original archive to be deleted (zip and 7z)\n",
    "            # Only need the extracted images\n",
    "            if ext not in [\".zip\", \".7z\"] and not check_integrity(fpath, md5):\n",
    "                return False\n",
    "\n",
    "        # Should check a hash of the images\n",
    "        return os.path.isdir(\n",
    "            os.path.join(self.root, self.base_folder, \"img_align_celeba\")\n",
    "        )\n",
    "\n",
    "    def download(self):\n",
    "        import zipfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print(\"Files already downloaded and verified\")\n",
    "            return\n",
    "\n",
    "        for file_id, md5, filename in self.file_list:\n",
    "            download_file_from_google_drive(\n",
    "                file_id, os.path.join(self.root, self.base_folder), filename, md5\n",
    "            )\n",
    "\n",
    "        with zipfile.ZipFile(\n",
    "            os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\"\n",
    "        ) as f:\n",
    "            f.extractall(os.path.join(self.root, self.base_folder))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataidxs is None:\n",
    "            X = PIL.Image.open(\n",
    "                os.path.join(\n",
    "                    self.root,\n",
    "                    self.base_folder,\n",
    "                    \"img_align_celeba\",\n",
    "                    self.filename[index],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            target = []\n",
    "            for t in self.target_type:\n",
    "                if t == \"attr\":\n",
    "                    target.append(self.attr[index, self.gender_index])\n",
    "                elif t == \"identity\":\n",
    "                    target.append(self.identity[index, 0])\n",
    "                elif t == \"bbox\":\n",
    "                    target.append(self.bbox[index, :])\n",
    "                elif t == \"landmarks\":\n",
    "                    target.append(self.landmarks_align[index, :])\n",
    "                else:\n",
    "                    # TODO: refactor with utils.verify_str_arg\n",
    "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
    "        else:\n",
    "            X = PIL.Image.open(\n",
    "                os.path.join(\n",
    "                    self.root,\n",
    "                    self.base_folder,\n",
    "                    \"img_align_celeba\",\n",
    "                    self.filename[self.dataidxs[index]],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            target = []\n",
    "            for t in self.target_type:\n",
    "                if t == \"attr\":\n",
    "                    target.append(self.attr[self.dataidxs[index], self.gender_index])\n",
    "                elif t == \"identity\":\n",
    "                    target.append(self.identity[self.dataidxs[index], 0])\n",
    "                elif t == \"bbox\":\n",
    "                    target.append(self.bbox[self.dataidxs[index], :])\n",
    "                elif t == \"landmarks\":\n",
    "                    target.append(self.landmarks_align[self.dataidxs[index], :])\n",
    "                else:\n",
    "                    # TODO: refactor with utils.verify_str_arg\n",
    "                    raise ValueError('Target type \"{}\" is not recognized.'.format(t))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        # print(\"target[0]:\", target[0])\n",
    "        if target:\n",
    "            target = tuple(target) if len(target) > 1 else target[0]\n",
    "\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "        else:\n",
    "            target = None\n",
    "        # print(\"celeba target:\", target)\n",
    "        return X, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.dataidxs is None:\n",
    "            return len(self.attr)\n",
    "        else:\n",
    "            return len(self.dataidxs)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
    "        return \"\\n\".join(lines).format(**self.__dict__)\n",
    "\n",
    "\n",
    "class STL10_truncated(data.Dataset):\n",
    "    def __init__(self, root, dataidxs=None, split=\"train\", transform=None, target_transform=None, download=False):\n",
    "        \"\"\"\n",
    "        Custom STL10 dataset with support for data indexing.\n",
    "        Args:\n",
    "            root (str): Dataset root directory.\n",
    "            dataidxs (list, optional): Indices for data partitioning. Defaults to None.\n",
    "            split (str, optional): Dataset split ('train', 'test', 'unlabeled'). Defaults to 'train'.\n",
    "            transform (callable, optional): Transformations for the input data. Defaults to None.\n",
    "            target_transform (callable, optional): Transformations for the target labels. Defaults to None.\n",
    "            download (bool, optional): Whether to download the dataset. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "        stl10_dataobj = STL10(\n",
    "            self.root, split=self.split, transform=self.transform, target_transform=self.target_transform, download=self.download\n",
    "        )\n",
    "        data = stl10_dataobj.data\n",
    "        target = np.array(stl10_dataobj.labels)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is the class index.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        # Ensure the image has the correct shape and dtype for PIL\n",
    "        img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "        img = img.astype(np.uint8)          # Ensure dtype is uint8 for PIL compatibility\n",
    "        img = Image.fromarray(img)          # Convert to PIL Image\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class CIFAR10_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        cifar_dataobj = CIFAR10(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        data = cifar_dataobj.data\n",
    "        target = np.array(cifar_dataobj.targets)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def truncate_channel(self, index):\n",
    "        for i in range(index.shape[0]):\n",
    "            gs_index = index[i]\n",
    "            self.data[gs_index, :, :, 1] = 0.0\n",
    "            self.data[gs_index, :, :, 2] = 0.0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "\n",
    "        # print(\"cifar10 img:\", img)\n",
    "        # print(\"cifar10 target:\", target)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def gen_bar_updater() -> Callable[[int, int, int], None]:\n",
    "    pbar = tqdm(total=None)\n",
    "\n",
    "    def bar_update(count, block_size, total_size):\n",
    "        if pbar.total is None and total_size:\n",
    "            pbar.total = total_size\n",
    "        progress_bytes = count * block_size\n",
    "        pbar.update(progress_bytes - pbar.n)\n",
    "\n",
    "    return bar_update\n",
    "\n",
    "\n",
    "def download_url(\n",
    "    url: str, root: str, filename: Optional[str] = None, md5: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"Download a file from a url and place it in root.\n",
    "    Args:\n",
    "        url (str): URL to download file from\n",
    "        root (str): Directory to place downloaded file in\n",
    "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
    "        md5 (str, optional): MD5 checksum of the download. If None, do not check\n",
    "    \"\"\"\n",
    "    import urllib\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "\n",
    "    # check if file is already present locally\n",
    "    if check_integrity(fpath, md5):\n",
    "        print(\"Using downloaded and verified file: \" + fpath)\n",
    "    else:  # download the file\n",
    "        try:\n",
    "            print(\"Downloading \" + url + \" to \" + fpath)\n",
    "            urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
    "        except (urllib.error.URLError, IOError) as e:  # type: ignore[attr-defined]\n",
    "            if url[:5] == \"https\":\n",
    "                url = url.replace(\"https:\", \"http:\")\n",
    "                print(\n",
    "                    \"Failed download. Trying https -> http instead.\"\n",
    "                    \" Downloading \" + url + \" to \" + fpath\n",
    "                )\n",
    "                urllib.request.urlretrieve(url, fpath, reporthook=gen_bar_updater())\n",
    "            else:\n",
    "                raise e\n",
    "        # check integrity of downloaded file\n",
    "        if not check_integrity(fpath, md5):\n",
    "            raise RuntimeError(\"File not found or corrupted.\")\n",
    "\n",
    "\n",
    "def _is_tarxz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar.xz\")\n",
    "\n",
    "\n",
    "def _is_tar(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar\")\n",
    "\n",
    "\n",
    "def _is_targz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tar.gz\")\n",
    "\n",
    "\n",
    "def _is_tgz(filename: str) -> bool:\n",
    "    return filename.endswith(\".tgz\")\n",
    "\n",
    "\n",
    "def _is_gzip(filename: str) -> bool:\n",
    "    return filename.endswith(\".gz\") and not filename.endswith(\".tar.gz\")\n",
    "\n",
    "\n",
    "def _is_zip(filename: str) -> bool:\n",
    "    return filename.endswith(\".zip\")\n",
    "\n",
    "\n",
    "def extract_archive(\n",
    "    from_path: str, to_path: Optional[str] = None, remove_finished: bool = False\n",
    ") -> None:\n",
    "    if to_path is None:\n",
    "        to_path = os.path.dirname(from_path)\n",
    "\n",
    "    if _is_tar(from_path):\n",
    "        with tarfile.open(from_path, \"r\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_targz(from_path) or _is_tgz(from_path):\n",
    "        with tarfile.open(from_path, \"r:gz\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_tarxz(from_path):\n",
    "        with tarfile.open(from_path, \"r:xz\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "\n",
    "                abs_directory = os.path.abspath(directory)\n",
    "                abs_target = os.path.abspath(target)\n",
    "\n",
    "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
    "\n",
    "                return prefix == abs_directory\n",
    "\n",
    "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
    "\n",
    "                for member in tar.getmembers():\n",
    "                    member_path = os.path.join(path, member.name)\n",
    "                    if not is_within_directory(path, member_path):\n",
    "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "\n",
    "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
    "\n",
    "            safe_extract(tar, path=to_path)\n",
    "    elif _is_gzip(from_path):\n",
    "        to_path = os.path.join(\n",
    "            to_path, os.path.splitext(os.path.basename(from_path))[0]\n",
    "        )\n",
    "        with open(to_path, \"wb\") as out_f, gzip.GzipFile(from_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "    elif _is_zip(from_path):\n",
    "        with zipfile.ZipFile(from_path, \"r\") as z:\n",
    "            z.extractall(to_path)\n",
    "    else:\n",
    "        raise ValueError(\"Extraction of {} not supported\".format(from_path))\n",
    "\n",
    "    if remove_finished:\n",
    "        os.remove(from_path)\n",
    "\n",
    "\n",
    "def download_and_extract_archive(\n",
    "    url: str,\n",
    "    download_root: str,\n",
    "    extract_root: Optional[str] = None,\n",
    "    filename: Optional[str] = None,\n",
    "    md5: Optional[str] = None,\n",
    "    remove_finished: bool = False,\n",
    ") -> None:\n",
    "    download_root = os.path.expanduser(download_root)\n",
    "    if extract_root is None:\n",
    "        extract_root = download_root\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "\n",
    "    download_url(url, download_root, filename, md5)\n",
    "\n",
    "    archive = os.path.join(download_root, filename)\n",
    "    print(\"Extracting {} to {}\".format(archive, extract_root))\n",
    "    extract_archive(archive, extract_root, remove_finished)\n",
    "\n",
    "\n",
    "class FEMNIST(MNIST):\n",
    "    \"\"\"\n",
    "    This dataset is derived from the Leaf repository\n",
    "    (https://github.com/TalwalkarLab/leaf) pre-processing of the Extended MNIST\n",
    "    dataset, grouping examples by writer. Details about Leaf were published in\n",
    "    \"LEAF: A Benchmark for Federated Settings\" https://arxiv.org/abs/1812.01097.\n",
    "    \"\"\"\n",
    "\n",
    "    resources = [\n",
    "        (\n",
    "            \"https://raw.githubusercontent.com/tao-shen/FEMNIST_pytorch/master/femnist.tar.gz\",\n",
    "            \"59c65cec646fc57fe92d27d83afdf0ed\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "        super(MNIST, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.train = train\n",
    "        self.dataidxs = dataidxs\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found.\" + \" You can use download=True to download it\"\n",
    "            )\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "\n",
    "        self.data, self.targets, self.users_index = torch.load(\n",
    "            os.path.join(self.processed_folder, data_file)\n",
    "        )\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            self.data = self.data[self.dataidxs]\n",
    "            self.targets = self.targets[self.dataidxs]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.numpy(), mode=\"F\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the FEMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        import shutil\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        mkdirs(self.raw_folder)\n",
    "        mkdirs(self.processed_folder)\n",
    "\n",
    "        # download files\n",
    "        for url, md5 in self.resources:\n",
    "            filename = url.rpartition(\"/\")[2]\n",
    "            download_and_extract_archive(\n",
    "                url, download_root=self.raw_folder, filename=filename, md5=md5\n",
    "            )\n",
    "\n",
    "        # process and save as torch files\n",
    "        print(\"Processing...\")\n",
    "        shutil.move(\n",
    "            os.path.join(self.raw_folder, self.training_file), self.processed_folder\n",
    "        )\n",
    "        shutil.move(\n",
    "            os.path.join(self.raw_folder, self.test_file), self.processed_folder\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(\n",
    "            check_integrity(\n",
    "                os.path.join(\n",
    "                    self.raw_folder,\n",
    "                    os.path.splitext(os.path.basename(url))[0]\n",
    "                    + os.path.splitext(os.path.basename(url))[1],\n",
    "                )\n",
    "            )\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "\n",
    "class Generated(MNIST):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "        super(MNIST, self).__init__(\n",
    "            root, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.train = train\n",
    "        self.dataidxs = dataidxs\n",
    "\n",
    "        if self.train:\n",
    "            self.data = np.load(\"data/generated/X_train.npy\")\n",
    "            self.targets = np.load(\"data/generated/y_train.npy\")\n",
    "        else:\n",
    "            self.data = np.load(\"data/generated/X_test.npy\")\n",
    "            self.targets = np.load(\"data/generated/y_test.npy\")\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            self.data = self.data[self.dataidxs]\n",
    "            self.targets = self.targets[self.dataidxs]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.data[index], self.targets[index]\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class genData(MNIST):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.data[index], self.targets[index]\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class CIFAR100_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "    ):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        cifar_dataobj = CIFAR100(\n",
    "            self.root, self.train, self.transform, self.target_transform, self.download\n",
    "        )\n",
    "\n",
    "        if torchvision.__version__ == \"0.2.1\":\n",
    "            if self.train:\n",
    "                data, target = cifar_dataobj.train_data, np.array(\n",
    "                    cifar_dataobj.train_labels\n",
    "                )\n",
    "            else:\n",
    "                data, target = cifar_dataobj.test_data, np.array(\n",
    "                    cifar_dataobj.test_labels\n",
    "                )\n",
    "        else:\n",
    "            data = cifar_dataobj.data\n",
    "            target = np.array(cifar_dataobj.targets)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "        img = Image.fromarray(img)\n",
    "        # print(\"cifar10 img:\", img)\n",
    "        # print(\"cifar10 target:\", target)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class ImageFolder_custom(DatasetFolder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        dataidxs=None,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        imagefolder_obj = ImageFolder(self.root, self.transform, self.target_transform)\n",
    "        self.loader = imagefolder_obj.loader\n",
    "        if self.dataidxs is not None:\n",
    "            self.samples = np.array(imagefolder_obj.samples)[self.dataidxs]\n",
    "        else:\n",
    "            self.samples = np.array(imagefolder_obj.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index][0]\n",
    "        target = self.samples[index][1]\n",
    "        target = int(target)\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.dataidxs is None:\n",
    "            return len(self.samples)\n",
    "        else:\n",
    "            return len(self.dataidxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.652842Z",
     "iopub.status.busy": "2025-01-07T19:26:40.652666Z",
     "iopub.status.idle": "2025-01-07T19:26:40.698529Z",
     "shell.execute_reply": "2025-01-07T19:26:40.697682Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.652827Z"
    },
    "id": "27nyJr8n3JuE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mkdirs(dirpath):\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except Exception as _:\n",
    "        pass\n",
    "\n",
    "\n",
    "def load_mnist_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train_ds = MNIST_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    mnist_test_ds = MNIST_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
    "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_fmnist_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train_ds = FashionMNIST_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    mnist_test_ds = FashionMNIST_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
    "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_svhn_data(datadir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    svhn_train_ds = SVHN_custom(datadir, train=True, download=True, transform=transform)\n",
    "    svhn_test_ds = SVHN_custom(datadir, train=False, download=True, transform=transform)\n",
    "    X_train, y_train = svhn_train_ds.data, svhn_train_ds.target\n",
    "    X_test, y_test = svhn_test_ds.data, svhn_test_ds.target\n",
    "    # X_train = X_train.data.numpy()\n",
    "    # y_train = y_train.data.numpy()\n",
    "    # X_test = X_test.data.numpy()\n",
    "    # y_test = y_test.data.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_cifar10_data(datadir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    cifar10_train_ds = CIFAR10_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    cifar10_test_ds = CIFAR10_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = cifar10_train_ds.data, cifar10_train_ds.target\n",
    "    X_test, y_test = cifar10_test_ds.data, cifar10_test_ds.target\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_celeba_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    celeba_train_ds = CelebA_custom(\n",
    "        datadir, split=\"train\", target_type=\"attr\", download=True, transform=transform\n",
    "    )\n",
    "    celeba_test_ds = CelebA_custom(\n",
    "        datadir, split=\"test\", target_type=\"attr\", download=True, transform=transform\n",
    "    )\n",
    "    gender_index = celeba_train_ds.attr_names.index(\"Male\")\n",
    "    y_train = celeba_train_ds.attr[:, gender_index : gender_index + 1].reshape(-1)\n",
    "    y_test = celeba_test_ds.attr[:, gender_index : gender_index + 1].reshape(-1)\n",
    "    # y_train = y_train.numpy()\n",
    "    # y_test = y_test.numpy()\n",
    "    return (None, y_train, None, y_test)\n",
    "\n",
    "\n",
    "def load_femnist_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train_ds = FEMNIST(datadir, train=True, transform=transform, download=True)\n",
    "    mnist_test_ds = FEMNIST(datadir, train=False, transform=transform, download=True)\n",
    "    X_train, y_train, u_train = (\n",
    "        mnist_train_ds.data,\n",
    "        mnist_train_ds.targets,\n",
    "        mnist_train_ds.users_index,\n",
    "    )\n",
    "    X_test, y_test, u_test = (\n",
    "        mnist_test_ds.data,\n",
    "        mnist_test_ds.targets,\n",
    "        mnist_test_ds.users_index,\n",
    "    )\n",
    "    X_train = X_train.data.numpy()\n",
    "    y_train = y_train.data.numpy()\n",
    "    u_train = np.array(u_train)\n",
    "    X_test = X_test.data.numpy()\n",
    "    y_test = y_test.data.numpy()\n",
    "    u_test = np.array(u_test)\n",
    "    return (X_train, y_train, u_train, X_test, y_test, u_test)\n",
    "\n",
    "\n",
    "def load_cifar100_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    cifar100_train_ds = CIFAR100_truncated(\n",
    "        datadir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    cifar100_test_ds = CIFAR100_truncated(\n",
    "        datadir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    X_train, y_train = cifar100_train_ds.data, cifar100_train_ds.target\n",
    "    X_test, y_test = cifar100_test_ds.data, cifar100_test_ds.target\n",
    "    # y_train = y_train.numpy()\n",
    "    # y_test = y_test.numpy()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def load_tinyimagenet_data(datadir):\n",
    "    split = \"val\"\n",
    "    TinyImageNet(datadir, split=split)\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "        transforms.RandomRotation(15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "    # transform = transforms.Compose([transforms.ToTensor()])\n",
    "    xray_train_ds = ImageFolder_custom(\n",
    "        datadir + \"tiny-imagenet-200/train/\", transform=transform_train\n",
    "    )\n",
    "    xray_test_ds = ImageFolder_custom(\n",
    "        datadir + \"tiny-imagenet-200/val/\", transform=transform_test\n",
    "    )\n",
    "    X_train, y_train = np.array([s[0] for s in xray_train_ds.samples]), np.array(\n",
    "        [int(s[1]) for s in xray_train_ds.samples]\n",
    "    )\n",
    "    X_test, y_test = np.array([s[0] for s in xray_test_ds.samples]), np.array(\n",
    "        [int(s[1]) for s in xray_test_ds.samples]\n",
    "    )\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "def load_stl10_data(datadir):\n",
    "    transform_train = transforms.Compose([\n",
    "    transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    stl10_train_ds = STL10_truncated(datadir, split=\"train\", transform=transform_train, download=True)\n",
    "    stl10_test_ds = STL10_truncated(datadir, split=\"test\", transform=transform_test, download=True)\n",
    "\n",
    "    X_train, y_train = stl10_train_ds.data, stl10_train_ds.target\n",
    "    X_test, y_test = stl10_test_ds.data, stl10_test_ds.target\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def record_net_data_stats(y_train, net_dataidx_map, logdir):\n",
    "    net_cls_counts = {}\n",
    "    for net_i, dataidx in net_dataidx_map.items():\n",
    "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
    "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
    "        net_cls_counts[net_i] = tmp\n",
    "    logger.info(\"Data statistics: %s\" % str(net_cls_counts))\n",
    "    return net_cls_counts\n",
    "\n",
    "\n",
    "def partition_data(dataset, datadir, logdir, partition, n_parties, beta=DIRICHLET_BETA):\n",
    "    # Optional: set random seeds for reproducibility\n",
    "    # np.random.seed(2020)\n",
    "    # torch.manual_seed(2020)\n",
    "    # Initialize test data index map\n",
    "    test_dataidx_map = {}\n",
    "    # Load dataset\n",
    "    if dataset == \"mnist\":\n",
    "        X_train, y_train, X_test, y_test = load_mnist_data(datadir)\n",
    "    elif dataset == \"fmnist\":\n",
    "        X_train, y_train, X_test, y_test = load_fmnist_data(datadir)\n",
    "    elif dataset == \"cifar10\":\n",
    "        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)\n",
    "    elif dataset == \"svhn\":\n",
    "        X_train, y_train, X_test, y_test = load_svhn_data(datadir)\n",
    "    elif dataset == \"celeba\":\n",
    "        X_train, y_train, X_test, y_test = load_celeba_data(datadir)\n",
    "    elif dataset == \"femnist\":\n",
    "        X_train, y_train, u_train, X_test, y_test, u_test = load_femnist_data(datadir)\n",
    "    elif dataset == \"cifar100\":\n",
    "        X_train, y_train, X_test, y_test = load_cifar100_data(datadir)\n",
    "    elif dataset == \"tinyimagenet\":\n",
    "        X_train, y_train, X_test, y_test = load_tinyimagenet_data(datadir)\n",
    "    elif dataset == \"stl10\":\n",
    "        X_train, y_train, X_test, y_test = load_stl10_data(datadir)\n",
    "    elif dataset == \"generated\":\n",
    "        # Code for generated dataset (omitted for brevity)\n",
    "        pass\n",
    "    # Add other datasets if needed\n",
    "    n_train = y_train.shape[0]\n",
    "    # Partition the data\n",
    "    if partition == \"homo\":\n",
    "        # Homogeneous data partition\n",
    "        idxs = np.random.permutation(n_train)\n",
    "        batch_idxs = np.array_split(idxs, n_parties)\n",
    "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
    "    # elif partition == \"noniid-labeldir\":\n",
    "    #     min_size = 0\n",
    "    #     min_require_size = 10\n",
    "    #     K = 10\n",
    "    #     if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
    "    #         K = 2\n",
    "    #     if dataset == 'cifar100':\n",
    "    #         K = 100\n",
    "    #     elif dataset == 'tinyimagenet':\n",
    "    #         K = 200\n",
    "\n",
    "    #     N = y_train.shape[0]\n",
    "    #     net_dataidx_map = {}\n",
    "\n",
    "    #     while min_size < min_require_size:\n",
    "    #         idx_batch = [[] for _ in range(n_parties)]\n",
    "    #         for k in range(K):\n",
    "    #             idx_k = np.where(y_train == k)[0]\n",
    "    #             np.random.shuffle(idx_k)\n",
    "    #             proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
    "    #             proportions = np.array([p * (len(idx_j) < N / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n",
    "    #             proportions = proportions / proportions.sum()\n",
    "    #             proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "    #             idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "    #             min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "    #     for j in range(n_parties):\n",
    "    #         np.random.shuffle(idx_batch[j])\n",
    "    #         net_dataidx_map[j] = idx_batch[j]\n",
    "    #     print(\"map\",net_dataidx_map)\n",
    "\n",
    "    elif partition == \"noniid-labeldir\":\n",
    "        min_size = 0\n",
    "        min_require_size = 10  # Minimum number required for each party\n",
    "        K = 10  # Number of classes\n",
    "\n",
    "        N = y_train.shape[0]\n",
    "        net_dataidx_map = {}\n",
    "        test_dataidx_map = {}  # Make sure to initialize this\n",
    "        \n",
    "        while min_size < min_require_size:\n",
    "            idx_batch = [[] for _ in range(n_parties)]\n",
    "            for k in range(K):\n",
    "                idx_k = np.where(y_train == k)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
    "                proportions = np.array([p * (len(idx_j) < N / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n",
    "                proportions = proportions / proportions.sum()  # Normalize\n",
    "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "\n",
    "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "\n",
    "        for j in range(n_parties):\n",
    "            np.random.shuffle(idx_batch[j])\n",
    "            net_dataidx_map[j] = idx_batch[j]\n",
    "\n",
    "            # Initialize test_dataidx_map for current party\n",
    "            test_dataidx_map[j] = []\n",
    "\n",
    "            # Gather test indices for current party based on labels in net_dataidx_map[j]\n",
    "            for k in range(K):\n",
    "                if k in y_train[net_dataidx_map[j]]:\n",
    "                    # Access test indices for class k\n",
    "                    idx_test_k = np.where(y_test == k)[0]\n",
    "                    np.random.shuffle(idx_test_k)\n",
    "\n",
    "                    # The number of sample for each party based on training set size\n",
    "                    n_samples = int(len(net_dataidx_map[j]) * len(idx_test_k) / N)\n",
    "                    test_dataidx_map[j].extend(idx_test_k[:n_samples])\n",
    "\n",
    "            test_dataidx_map[j] = np.array(test_dataidx_map[j])\n",
    "\n",
    "        # Cleanup to avoid empty concatenation error\n",
    "        for j in range(n_parties):\n",
    "            if len(test_dataidx_map[j]) == 0:\n",
    "                test_dataidx_map[j] = np.array([])  # Set to an empty array to avoid errors later\n",
    "    elif partition.startswith(\"noniid-#label\") and partition[13:].isdigit():\n",
    "        num = int(partition[13:])\n",
    "        if dataset in (\"celeba\", \"covtype\", \"a9a\", \"rcv1\", \"SUSY\"):\n",
    "            num = 1\n",
    "            K = 2\n",
    "        else:\n",
    "            if dataset == \"cifar100\":\n",
    "                K = 100\n",
    "            elif dataset == \"tinyimagenet\":\n",
    "                K = 200\n",
    "            else:\n",
    "                K = 10\n",
    "        if num == K:\n",
    "            # IID partition\n",
    "            net_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            for i in range(K):\n",
    "                idx_k = np.where(y_train == i)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                split = np.array_split(idx_k, n_parties)\n",
    "                for j in range(n_parties):\n",
    "                    net_dataidx_map[j] = np.append(net_dataidx_map[j], split[j])\n",
    "        else:\n",
    "            times = [0 for _ in range(K)]\n",
    "            contain = []\n",
    "            for i in range(n_parties):\n",
    "                current = [i % K]\n",
    "                times[i % K] += 1\n",
    "                j = 1\n",
    "                while j < num:\n",
    "                    ind = random.randint(0, K - 1)\n",
    "                    if ind not in current:\n",
    "                        j += 1\n",
    "                        current.append(ind)\n",
    "                        times[ind] += 1\n",
    "                contain.append(current)\n",
    "            net_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            test_dataidx_map = {\n",
    "                i: np.ndarray(0, dtype=np.int64) for i in range(n_parties)\n",
    "            }\n",
    "            for i in range(K):\n",
    "                if times[i] > 0:\n",
    "                    idx_k = np.where(y_train == i)[0]\n",
    "                    idx_t = np.where(y_test == i)[0]\n",
    "                    np.random.shuffle(idx_k)\n",
    "                    np.random.shuffle(idx_t)\n",
    "                    split = np.array_split(idx_k, times[i])\n",
    "                    splitt = np.array_split(idx_t, times[i])\n",
    "                    ids = 0\n",
    "                    for j in range(n_parties):\n",
    "                        if i in contain[j]:\n",
    "                            net_dataidx_map[j] = np.append(\n",
    "                                net_dataidx_map[j], split[ids]\n",
    "                            )\n",
    "                            test_dataidx_map[j] = np.append(\n",
    "                                test_dataidx_map[j], splitt[ids]\n",
    "                            )\n",
    "                            ids += 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown partition method: {partition}\")\n",
    "    traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)\n",
    "    return (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        net_dataidx_map,\n",
    "        test_dataidx_map,\n",
    "        traindata_cls_counts,\n",
    "    )\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0, net_id=None, total=0):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.net_id = net_id\n",
    "        self.num = int(sqrt(total))\n",
    "        if self.num * self.num < total:\n",
    "            self.num = self.num + 1\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if self.net_id is None:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            tmp = torch.randn(tensor.size())\n",
    "            filt = torch.zeros(tensor.size())\n",
    "            size = int(28 / self.num)\n",
    "            row = int(self.net_id / size)\n",
    "            col = self.net_id % size\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    filt[:, row * size + i, col * size + j] = 1\n",
    "            tmp = tmp * filt\n",
    "            return tensor + tmp * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"(mean={0}, std={1})\".format(\n",
    "            self.mean, self.std\n",
    "        )\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    dataset,\n",
    "    datadir,\n",
    "    train_bs,\n",
    "    test_bs,\n",
    "    dataidxs=None,\n",
    "    testidxs=None,\n",
    "    noise_level=0,\n",
    "    net_id=None,\n",
    "    total=0,\n",
    "):\n",
    "    if dataset in (\n",
    "        \"mnist\",\n",
    "        \"femnist\",\n",
    "        \"fmnist\",\n",
    "        \"cifar10\",\n",
    "        \"svhn\",\n",
    "        \"generated\",\n",
    "        \"covtype\",\n",
    "        \"a9a\",\n",
    "        \"rcv1\",\n",
    "        \"SUSY\",\n",
    "        \"cifar100\",\n",
    "        \"tinyimagenet\",\n",
    "        \"stl10\"\n",
    "    ):\n",
    "        if dataset == \"mnist\":\n",
    "            dl_obj = MNIST_truncated\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"femnist\":\n",
    "            dl_obj = FEMNIST\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"fmnist\":\n",
    "            dl_obj = FashionMNIST_truncated\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"svhn\":\n",
    "            dl_obj = SVHN_custom\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.Resize((TRANSFORM_INPUT_SIZE, TRANSFORM_INPUT_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "\n",
    "        elif dataset == \"cifar10\":\n",
    "            print(\"in cifar10\")\n",
    "            dl_obj = CIFAR10_truncated\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    # transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Lambda(\n",
    "                        lambda x: F.pad(\n",
    "                            Variable(x.unsqueeze(0), requires_grad=False),\n",
    "                            (4, 4, 4, 4),\n",
    "                            mode=\"reflect\",\n",
    "                        ).data.squeeze()\n",
    "                    ),\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.RandomCrop(32),\n",
    "                    transforms.ToTensor(),\n",
    "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "            # data prep for test set\n",
    "            transform_test = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    AddGaussianNoise(0.0, noise_level, net_id, total),\n",
    "                ]\n",
    "            )\n",
    "        elif dataset == \"cifar100\":\n",
    "            print(\"in 100\")\n",
    "            dl_obj = CIFAR100_truncated\n",
    "            normalize = transforms.Normalize(\n",
    "                mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n",
    "                std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404],\n",
    "            )\n",
    "\n",
    "            transform_train = transforms.Compose(\n",
    "                [\n",
    "                    # transforms.ToPILImage(),\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomRotation(15),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ]\n",
    "            )\n",
    "            # data prep for test set\n",
    "            transform_test = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "        elif dataset == \"tinyimagenet\":\n",
    "            dl_obj = ImageFolder_custom\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(64, padding=4),  # Random cropping with padding\n",
    "                transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "                transforms.RandomRotation(15),  # Random rotation\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),  # Normalization\n",
    "            ])\n",
    "\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
    "            ])\n",
    "        elif dataset == \"stl10\":\n",
    "            dl_obj = STL10_truncated\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomCrop(96, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        else:\n",
    "            dl_obj = Generated\n",
    "            transform_train = None\n",
    "            transform_test = None\n",
    "        if dataset == \"tinyimagenet\":\n",
    "            train_ds = dl_obj(\n",
    "                datadir + \"tiny-imagenet-200/train/\",\n",
    "                dataidxs=dataidxs,\n",
    "                transform=transform_train,\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir + \"tiny-imagenet-200/val/\",\n",
    "                dataidxs=testidxs,\n",
    "                transform=transform_test\n",
    "            )\n",
    "        elif dataset == \"stl10\":\n",
    "            train_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=dataidxs,\n",
    "                split=\"train\",\n",
    "                transform=transform_train,\n",
    "                download=True\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=testidxs,\n",
    "                split=\"test\",\n",
    "                transform=transform_test,\n",
    "                download=True\n",
    "            )\n",
    "        else:\n",
    "            print(\"dir\", datadir)\n",
    "            train_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=dataidxs,\n",
    "                train=True,\n",
    "                transform=transform_train,\n",
    "                download=True,\n",
    "            )\n",
    "            test_ds = dl_obj(\n",
    "                datadir,\n",
    "                dataidxs=testidxs,\n",
    "                train=False,\n",
    "                transform=transform_test,\n",
    "                download=True,\n",
    "            )\n",
    "        train_dl = data.DataLoader(\n",
    "            dataset=train_ds, batch_size=train_bs, shuffle=True, drop_last=False\n",
    "        )\n",
    "        test_dl = data.DataLoader(\n",
    "            dataset=test_ds, batch_size=test_bs, shuffle=False, drop_last=False\n",
    "        )\n",
    "        print(train_ds, \"train ds\")\n",
    "    return train_dl, test_dl, train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.699641Z",
     "iopub.status.busy": "2025-01-07T19:26:40.699388Z",
     "iopub.status.idle": "2025-01-07T19:26:40.717803Z",
     "shell.execute_reply": "2025-01-07T19:26:40.717181Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.699617Z"
    },
    "id": "eizGyXaA3JuE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_loaders(NUMBER_OF_CLIENTS):\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        net_dataidx_map,\n",
    "        test_dataidx_map,\n",
    "        traindata_cls_counts,\n",
    "    ) = partition_data(\n",
    "        dataset=DATASET_TYPE,\n",
    "        datadir=\"./data/\",\n",
    "        logdir=\"./logs/\",\n",
    "        partition=PARTITION,\n",
    "        n_parties=10,\n",
    "    )\n",
    "    print(\"shapes\", X_train.shape, y_train.shape)\n",
    "    train_loaders = []\n",
    "    test_loaders = []\n",
    "    for client_id in range(NUMBER_OF_CLIENTS):\n",
    "\n",
    "        dataidxs = net_dataidx_map[client_id]\n",
    "        testidxs = test_dataidx_map[client_id]\n",
    "\n",
    "        train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(\n",
    "            dataset=DATASET_TYPE,\n",
    "            datadir=\"./data/\",\n",
    "            train_bs=TRAIN_BATCH_SIZE,\n",
    "            test_bs=TEST_BATCH_SIZE,\n",
    "            dataidxs=dataidxs,\n",
    "            testidxs=testidxs,\n",
    "        )\n",
    "        train_loaders.append(train_dl_local)\n",
    "        test_loaders.append(test_dl_local)\n",
    "\n",
    "    return train_loaders, test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.718664Z",
     "iopub.status.busy": "2025-01-07T19:26:40.718475Z",
     "iopub.status.idle": "2025-01-07T19:26:40.736747Z",
     "shell.execute_reply": "2025-01-07T19:26:40.736120Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.718646Z"
    },
    "id": "-IvzdpYcxGZx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    train_loaders, test_loaders = get_loaders(10)\n",
    "    return train_loaders, test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:26:40.737616Z",
     "iopub.status.busy": "2025-01-07T19:26:40.737430Z",
     "iopub.status.idle": "2025-01-07T19:27:25.899302Z",
     "shell.execute_reply": "2025-01-07T19:27:25.898445Z",
     "shell.execute_reply.started": "2025-01-07T19:26:40.737598Z"
    },
    "id": "ORJsNkg1xMY4",
    "outputId": "9769a96f-c6b6-46c1-ebf6-2eff0f483bf2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data statistics: {0: {np.int64(0): np.int64(4948), np.int64(2): np.int64(5293)}, 1: {np.int64(1): np.int64(3466), np.int64(9): np.int64(2330)}, 2: {np.int64(1): np.int64(3465), np.int64(2): np.int64(5292)}, 3: {np.int64(3): np.int64(4249), np.int64(4): np.int64(3729)}, 4: {np.int64(1): np.int64(3465), np.int64(4): np.int64(3729)}, 5: {np.int64(5): np.int64(6882), np.int64(7): np.int64(1865)}, 6: {np.int64(6): np.int64(2864), np.int64(7): np.int64(1865)}, 7: {np.int64(6): np.int64(2863), np.int64(7): np.int64(1865)}, 8: {np.int64(3): np.int64(4248), np.int64(8): np.int64(5045)}, 9: {np.int64(1): np.int64(3465), np.int64(9): np.int64(2329)}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (73257, 3, 32, 32) (73257,)\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c71bf80> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c71bb60> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c71b770> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c71b2f0> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81d573aa0> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c6c0ec0> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81d9f1c70> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81d952090> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81d929a30> train ds\n",
      "dir ./data/\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "<__main__.SVHN_custom object at 0x71d81c6f91c0> train ds\n"
     ]
    }
   ],
   "source": [
    "train_loaders, test_loaders = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CrFoxva3JuE"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Visualization</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:27:25.900374Z",
     "iopub.status.busy": "2025-01-07T19:27:25.900127Z",
     "iopub.status.idle": "2025-01-07T19:27:25.908038Z",
     "shell.execute_reply": "2025-01-07T19:27:25.907241Z",
     "shell.execute_reply.started": "2025-01-07T19:27:25.900352Z"
    },
    "id": "uySBR7Ez3JuE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, train_loaders):\n",
    "        self.train_loaders = train_loaders\n",
    "\n",
    "    def count_classes(self):\n",
    "        class_counts = []\n",
    "        for loader in self.train_loaders:\n",
    "            counts = np.zeros(10, dtype=int)\n",
    "            for _, labels in loader:\n",
    "                for label in labels:\n",
    "                    counts[label] += 1\n",
    "            class_counts.append(counts)\n",
    "        return class_counts\n",
    "\n",
    "    def plot_class_distribution(\n",
    "        self,\n",
    "        DATASET_TYPE=\"Train\",\n",
    "    ):\n",
    "        class_counts = self.count_classes()\n",
    "        num_classes = NUMBER_OF_CLASSES\n",
    "        labels = [\n",
    "            \"airplane\",\n",
    "            \"automobile\",\n",
    "            \"bird\",\n",
    "            \"cat\",\n",
    "            \"deer\",\n",
    "            \"dog\",\n",
    "            \"frog\",\n",
    "            \"horse\",\n",
    "            \"ship\",\n",
    "            \"truck\",\n",
    "        ]\n",
    "        num_nodes = len(class_counts)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        width = 0.6\n",
    "\n",
    "        counts = np.array(class_counts)\n",
    "        x = np.arange(num_nodes)\n",
    "\n",
    "        colors = plt.cm.tab10.colors\n",
    "\n",
    "        bottom = np.zeros(num_nodes)\n",
    "        for i in range(num_classes):\n",
    "            counts_per_class = counts[:, i]\n",
    "            ax.bar(\n",
    "                x,\n",
    "                counts_per_class,\n",
    "                width,\n",
    "                bottom=bottom,\n",
    "                label=labels[i],\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"white\",\n",
    "            )\n",
    "            bottom += counts_per_class\n",
    "        ax.set_xlabel(\"Nodes\")\n",
    "        ax.set_ylabel(\"Number of Samples\")\n",
    "        ax.set_title(f\"Distribution of {DATASET_TYPE} Classes Across Different Nodes\")\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f\"{i+1}\" for i in range(num_nodes)], rotation=0)\n",
    "        ax.legend(\n",
    "            title=\"Classes\",\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "            borderaxespad=0.0,\n",
    "            frameon=False,\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:27:25.909051Z",
     "iopub.status.busy": "2025-01-07T19:27:25.908795Z",
     "iopub.status.idle": "2025-01-07T19:27:25.927293Z",
     "shell.execute_reply": "2025-01-07T19:27:25.926500Z",
     "shell.execute_reply.started": "2025-01-07T19:27:25.909029Z"
    },
    "id": "KS4EpcfYxOK6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizer(train_loaders).plot_class_distribution()\n",
    "# Visualizer(test_loaders).plot_class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:27:25.930357Z",
     "iopub.status.busy": "2025-01-07T19:27:25.930140Z",
     "iopub.status.idle": "2025-01-07T19:27:25.944741Z",
     "shell.execute_reply": "2025-01-07T19:27:25.943944Z",
     "shell.execute_reply.started": "2025-01-07T19:27:25.930332Z"
    },
    "id": "TigBlX7z3JuE",
    "outputId": "31693f42-3347-4e01-e61c-3ab36ebfbdfb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def calculate_label_distribution(dataloader):\n",
    "#     label_counts = np.zeros(NUMBER_OF_CLASSES)\n",
    "#     for _, labels in dataloader:\n",
    "#         for label in labels.numpy():\n",
    "#             label_counts[label] += 1\n",
    "            \n",
    "#     print(f\"Label distribution is: {label_counts}\")\n",
    "#     return label_counts\n",
    "\n",
    "# def plot_client_distributions(distributions):\n",
    "#     num_clients = len(distributions)\n",
    "#     cols = 3  # Number of columns for subplots\n",
    "#     rows = (num_clients + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "#     axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "#     for i, label_counts in enumerate(distributions):\n",
    "#         axes[i].bar(range(NUMBER_OF_CLASSES), label_counts, color='skyblue')\n",
    "#         axes[i].set_xlabel('Class Labels')\n",
    "#         axes[i].set_ylabel('Number of Samples')\n",
    "#         axes[i].set_title(f'Client {i}')\n",
    "#         axes[i].set_xticks(range(NUMBER_OF_CLASSES))\n",
    "#         axes[i].set_xticklabels([f'Class {j}' for j in range(NUMBER_OF_CLASSES)])\n",
    "#         axes[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "#     # Hide any unused subplots\n",
    "#     for j in range(i + 1, len(axes)):\n",
    "#         fig.delaxes(axes[j])\n",
    "\n",
    "#     plt.suptitle('Label Distribution for Each Client')\n",
    "#     plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for the title\n",
    "#     plt.show()\n",
    "\n",
    "# def compute_similarity_matrix(distributions):\n",
    "#     similarity_matrix = cosine_similarity(distributions)\n",
    "#     return similarity_matrix\n",
    "\n",
    "# def cluster_clients(similarity_matrix):\n",
    "#     clustering = AffinityPropagation(affinity='precomputed', random_state=42)\n",
    "#     clustering.fit(similarity_matrix)\n",
    "#     return clustering.labels_\n",
    "\n",
    "# def group_clients_by_cluster(labels):\n",
    "#     clusters = {}\n",
    "#     for client_id, cluster_id in enumerate(labels):\n",
    "#         if cluster_id not in clusters:\n",
    "#             clusters[cluster_id] = []\n",
    "#         clusters[cluster_id].append(client_id)\n",
    "#     return clusters\n",
    "\n",
    "# def save_similarity_matrix_to_csv(similarity_matrix, filename=\"similarity_matrix.csv\"):\n",
    "#     with open(filename, mode='w', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\"Client\"] + [f\"Client_{i}\" for i in range(len(similarity_matrix))])\n",
    "#         for i, row in enumerate(similarity_matrix):\n",
    "#             writer.writerow([f\"Client_{i}\"] + row.tolist())\n",
    "#     print(f\"Similarity matrix saved to {filename}\")\n",
    "\n",
    "# def compute_silhouette_score(similarity_matrix, cluster_labels):\n",
    "#     distance_matrix = 2 - (similarity_matrix + 1)\n",
    "#     score = silhouette_score(distance_matrix, cluster_labels, metric='precomputed')\n",
    "#     return score\n",
    "\n",
    "# # Main execution\n",
    "# label_distributions = [calculate_label_distribution(loader) for loader in train_loaders]\n",
    "\n",
    "# # New function call to plot the distributions\n",
    "# plot_client_distributions(label_distributions)\n",
    "\n",
    "# similarity_matrix = compute_similarity_matrix(label_distributions)\n",
    "# save_similarity_matrix_to_csv(similarity_matrix, filename=\"clients_datasets_similarity_matrix.csv\")\n",
    "\n",
    "# cluster_labels = cluster_clients(similarity_matrix)\n",
    "# clusters = group_clients_by_cluster(cluster_labels)\n",
    "\n",
    "# print(\"Clients clustering based on their dataset: \", clusters)\n",
    "# print(\"Clients clustering label based on their dataset: \", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T19:27:25.946079Z",
     "iopub.status.busy": "2025-01-07T19:27:25.945792Z",
     "iopub.status.idle": "2025-01-07T19:27:25.961345Z",
     "shell.execute_reply": "2025-01-07T19:27:25.960626Z",
     "shell.execute_reply.started": "2025-01-07T19:27:25.946052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# silhouette_cosine = compute_silhouette_score(similarity_matrix, [0, 1, 0, 2, 2, 3, 3, 3, 2, 1])\n",
    "# print(f\"Silhouette score for data clustering is: {silhouette_cosine}\")\n",
    "\n",
    "# silhouette_cosine = compute_silhouette_score(similarity_matrix, [0, 3, 0, 1, 1, 3, 2, 2, 3, 3,])\n",
    "# print(f\"Silhouette score for cosine is: {silhouette_cosine}\")\n",
    "\n",
    "# silhouette_cosine_less_sig_pruned = compute_silhouette_score(similarity_matrix, [0, 3, 0, 1, 1, 3, 2, 2, 3, 3,])\n",
    "# print(f\"Silhouette score for cosine (optimal) common less sig pruned is: {silhouette_cosine_less_sig_pruned}\")\n",
    "\n",
    "# silhouette_coordinate = compute_silhouette_score(similarity_matrix, [0, 3, 0, 1, 1, 3, 2, 2, 0, 3,])\n",
    "# print(f\"Silhouette score for coordinate is: {silhouette_coordinate}\")\n",
    "\n",
    "# silhouette_euclidean = compute_silhouette_score(similarity_matrix, [3, 0, 3, 1, 0, 3, 3, 3, 2, 0,])\n",
    "# print(f\"Silhouette score for euclidean is: {silhouette_euclidean}\")\n",
    "\n",
    "# silhouette_wasserstein = compute_silhouette_score(similarity_matrix, [2, 0, 2, 2, 2, 0, 2, 2, 1, 0,])\n",
    "# print(f\"Silhouette score for wasserstein is: {silhouette_wasserstein}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFgZGqbk3JuE"
   },
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Executing</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T19:27:25.962303Z",
     "iopub.status.busy": "2025-01-07T19:27:25.962075Z"
    },
    "id": "KTKWmDCUxXfO",
    "outputId": "60e5a5cb-29f4-41b0-84a7-a203fa0c2503",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------Clustering step 0\n",
      "-------------in initial genertaio\n",
      "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "len_client_models(should be 10): 0\n",
      " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "cid is: 0\n",
      "cid is: 1\n",
      "cid is: 2\n",
      "cid is: 3\n",
      "cid is: 4\n",
      "cid is: 5\n",
      "cid is: 6\n",
      "cid is: 7\n",
      "cid is: 8\n",
      "cid is: 9\n",
      "\n",
      "Round 1/1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x16384 and 4096x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m cluster_initial_models\u001b[38;5;241m=\u001b[39mgenerate_initial_models(step,cluster,client_ids,client_copy_models)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ---in making new FL----cluster models len:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cluster_initial_models),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, client_ids)\n\u001b[0;32m---> 36\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mFL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcluster_initial_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43mFEDERATED_LEARNING_ROUNDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSENSITIVITY_PERCENTAGE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m FL_list\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mclient_obj_list:\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mFL.__init__\u001b[0;34m(self, clients, client_initial_models, round_number, train_loaders, test_loaders, SENSITIVITY_PERCENTAGE)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_obj_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracies \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 44\u001b[0m, in \u001b[0;36mFL.training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m global_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients:\n\u001b[1;32m     42\u001b[0m     train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_obj_list\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain_test_and_return_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_____________________________________________________________________________________________________________\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test_acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m, in \u001b[0;36mClient.Train_test_and_return_acc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain_test_and_return_acc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_acc, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mROUND_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_acc, _ \u001b[38;5;241m=\u001b[39m test(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_acc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_acc\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, node_id, train_loader, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(DEVICE), labels\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 84\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m     83\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     out \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x16384 and 4096x4096)"
     ]
    }
   ],
   "source": [
    "\n",
    "clusters=[]\n",
    "initial = [i for i in range(NUMBER_OF_CLIENTS)]\n",
    "clusters.append(initial)\n",
    "\n",
    "\n",
    "def generate_initial_models(step,cluster,client_ids,client_Models):\n",
    "    print(\"-------------in initial genertaio\")\n",
    "    print(\"cluster\", cluster)\n",
    "    print(\"clientIDs\", client_ids)\n",
    "    print(\"len_client_models(should be 10):\",len(client_Models))\n",
    "    list1=[]\n",
    "\n",
    "    if step==0:\n",
    "        for member in range(len(cluster)):\n",
    "            list1.append(Net())\n",
    "    else:\n",
    "        for index in cluster:\n",
    "            list1.append(client_Models[client_ids.index(index)])\n",
    "    return list1\n",
    "\n",
    "\n",
    "client_Models=[]\n",
    "client_copy_models = []\n",
    "\n",
    "for step in range(CLUSTERING_PERIOD):\n",
    "    client_copy_models=copy.deepcopy(client_Models)\n",
    "    client_Models=[]\n",
    "    print(\"\\n\\n---------Clustering step\", step)\n",
    "    FL_list=[]\n",
    "    client_ids=[]\n",
    "    for cluster in clusters:\n",
    "        for Id in cluster:\n",
    "            client_ids.append(Id)\n",
    "        cluster_initial_models=generate_initial_models(step,cluster,client_ids,client_copy_models)\n",
    "        print(\" ---in making new FL----cluster models len:\", len(cluster_initial_models),\"cluster IDs:\", client_ids)\n",
    "        f = FL(cluster,cluster_initial_models,FEDERATED_LEARNING_ROUNDS, train_loaders, test_loaders, SENSITIVITY_PERCENTAGE)\n",
    "        FL_list.append(f)\n",
    "        for member in f.client_obj_list:\n",
    "            client_Models.append(member.net)\n",
    "        for cid in client_ids:\n",
    "            save_torch_model(client_Models[client_ids.index(cid)], cid)\n",
    "            # save_model_param(client_Models[client_ids.index(cid)], cid, step)\n",
    "\n",
    "    print(\"----------------------Info before clustering-------------\")\n",
    "    print(\"model_len:\", len(client_Models))\n",
    "    print(\"Client IDS:\",client_ids )\n",
    "    start_cluster_time = datetime.now()\n",
    "    clusters = Clustering(client_ids, train_loaders, SENSITIVITY_PERCENTAGE).Clusters\n",
    "    end_cluster_time = datetime.now()\n",
    "    exe_cluster_time = end_cluster_time - start_cluster_time\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"\\n Exe Cluster Time: {exe_cluster_time}\")\n",
    "        f.write(f\"\\n The Clusters are: {clusters}\")\n",
    "    print(\"new clustering:\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Models Distance</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def zero_smallest_p_percent_simple(array, P):\n",
    "#     if not (0 <= P <= 100):\n",
    "#         raise ValueError(\"P must be between 0 and 100.\")\n",
    "\n",
    "#     array = np.array(array)\n",
    "#     n_elements = array.size\n",
    "\n",
    "#     if P == 0:\n",
    "#         return array.copy()\n",
    "#     if P == 100:\n",
    "#         return np.zeros_like(array)\n",
    "\n",
    "#     num_to_zero = int(np.floor((P / 100) * n_elements))\n",
    "#     if num_to_zero == 0:\n",
    "#         num_to_zero = 1\n",
    "\n",
    "#     smallest_indices = np.argpartition(array, num_to_zero - 1)[:num_to_zero]\n",
    "\n",
    "#     modified_array = array.copy()\n",
    "#     modified_array[smallest_indices] = 0\n",
    "\n",
    "#     return modified_array\n",
    "# def remove_batchnorm_params(state_dict):\n",
    "#     filtered_state_dict = {\n",
    "#         key: value\n",
    "#         for key, value in state_dict.items()\n",
    "#         if \"running_mean\" not in key and \"running_var\" not in key and \"bn\" not in key\n",
    "#     }\n",
    "\n",
    "#     # print(\"Removed BatchNorm parameters:\")\n",
    "#     # for key in state_dict.keys():\n",
    "#     #     if \"running_mean\" in key or \"running_var\" in key or \"bn\" in key:\n",
    "#     #         print(f\"  - {key}\")\n",
    "\n",
    "#     return filtered_state_dict\n",
    "# def model_parameters_to_numpy(path):\n",
    "#     model = torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "#     params = []\n",
    "\n",
    "#     model = remove_batchnorm_params(model)\n",
    "#     for name, param in model.items():\n",
    "#         if 'bias' not in name:\n",
    "#             params.append(param.detach().cpu().numpy())\n",
    "\n",
    "#     return np.array(params, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border-radius:10px; border:#f4af03 solid; padding: 15px; background-color: #506886; font-size:100%; text-align:center\">Pruning</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# pruned_params_dict = {}\n",
    "\n",
    "# for P in range(0, 101, 10):\n",
    "#     params = []\n",
    "#     prunes = []\n",
    "    \n",
    "#     for i in range(NUMBER_OF_CLIENTS):\n",
    "#         node = model_parameters_to_numpy(f\"./models/before_aggregation/node_{i}.pth\")\n",
    "#         param = np.concatenate([p.ravel() for p in node])\n",
    "        \n",
    "#         params.append(param)\n",
    "        \n",
    "#         if P == 0:\n",
    "#             prune = param  # the original model\n",
    "#         else:\n",
    "#             prune = zero_smallest_p_percent_simple(param, P)\n",
    "        \n",
    "#         prunes.append(prune)\n",
    "    \n",
    "#     pruned_params_dict[P] = prunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, test_loaders):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loaders:\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pruning Levels:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Extract the original parameters (P=0)\n",
    "# original_params = pruned_params_dict[0]\n",
    "\n",
    "# # Initialize dictionaries to store similarity matrices and cluster labels for each P\n",
    "# similarity_matrices = {\n",
    "#     'cosine': {},\n",
    "#     'euclidean': {},\n",
    "#     'wasserstein': {}\n",
    "# }\n",
    "\n",
    "# cluster_labels_dict = {\n",
    "#     'cosine': {},\n",
    "#     'euclidean': {},\n",
    "#     'wasserstein': {}\n",
    "# }\n",
    "\n",
    "# # Loop through each P value (excluding P=0, since it's the original parameters)\n",
    "# for P in tqdm(range(10, 101, 10), desc=\"Processing Pruning Levels\"):  # Add progress bar for pruning levels\n",
    "#     # Get the pruned parameters for the current P\n",
    "#     pruned_params = pruned_params_dict[P]\n",
    "    \n",
    "#     # Initialize similarity matrices for each metric\n",
    "#     N = len(pruned_params)  # Number of clients\n",
    "#     cosine_sim_matrix = np.zeros((N, N))\n",
    "#     euclidean_dist_matrix = np.zeros((N, N))\n",
    "#     wasserstein_dist_matrix = np.zeros((N, N))\n",
    "    \n",
    "#     # Calculate cosine similarity, Euclidean distance, and Wasserstein distance\n",
    "#     for i in tqdm(range(N), desc=f\"Calculating Similarities for P={P}\", leave=False):  # Add progress bar for clients\n",
    "#         for j in range(N):\n",
    "#             # Cosine similarity\n",
    "#             cosine_sim_matrix[i][j] = cosine_similarity([pruned_params[i]], [original_params[j]])[0][0]\n",
    "            \n",
    "#             # Euclidean distance\n",
    "#             euclidean_dist_matrix[i][j] = euclidean(pruned_params[i], original_params[j])\n",
    "            \n",
    "#             # Wasserstein distance\n",
    "#             wasserstein_dist_matrix[i][j] = wasserstein_distance(pruned_params[i], original_params[j])\n",
    "    \n",
    "#     # Normalize the similarity matrices to be between 0 and 1\n",
    "#     cosine_sim_matrix = (cosine_sim_matrix - np.min(cosine_sim_matrix)) / (np.max(cosine_sim_matrix) - np.min(cosine_sim_matrix))\n",
    "#     euclidean_dist_matrix = (euclidean_dist_matrix - np.min(euclidean_dist_matrix)) / (np.max(euclidean_dist_matrix) - np.min(euclidean_dist_matrix))\n",
    "#     wasserstein_dist_matrix = (wasserstein_dist_matrix - np.min(wasserstein_dist_matrix)) / (np.max(wasserstein_dist_matrix) - np.min(wasserstein_dist_matrix))\n",
    "    \n",
    "#     # Store the similarity matrices\n",
    "#     similarity_matrices['cosine'][P] = cosine_sim_matrix\n",
    "#     similarity_matrices['euclidean'][P] = euclidean_dist_matrix\n",
    "#     similarity_matrices['wasserstein'][P] = wasserstein_dist_matrix\n",
    "    \n",
    "#     # Perform Affinity Propagation clustering for each metric\n",
    "#     for metric, matrix in zip(['cosine', 'euclidean', 'wasserstein'], \n",
    "#                               [cosine_sim_matrix, euclidean_dist_matrix, wasserstein_dist_matrix]):\n",
    "#         # Negate the matrix for Affinity Propagation (it uses negative distances)\n",
    "#         neg_matrix = -matrix\n",
    "        \n",
    "#         # Perform clustering\n",
    "#         ap = AffinityPropagation(affinity=\"precomputed\").fit(neg_matrix)\n",
    "#         labels = ap.labels_\n",
    "        \n",
    "#         # Store the cluster labels\n",
    "#         cluster_labels_dict[metric][P] = labels\n",
    "\n",
    "# # Now, let's visualize the similarity matrices using heatmaps\n",
    "# for metric in ['cosine', 'euclidean', 'wasserstein']:\n",
    "#     for P in tqdm(range(10, 101, 10), desc=f\"Generating Heatmaps for {metric}\"):  # Add progress bar for heatmaps\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         sns.heatmap(similarity_matrices[metric][P], annot=True, cmap='viridis', fmt='.2f')\n",
    "#         plt.title(f'{metric.capitalize()} Similarity Matrix for P={P}')\n",
    "#         plt.xlabel('Client ID')\n",
    "#         plt.ylabel('Client ID')\n",
    "#         plt.show()\n",
    "\n",
    "# # Finally, let's evaluate the accuracy of each pruned model on the test data\n",
    "# accuracies = {}\n",
    "# for P in tqdm(range(10, 101, 10), desc=\"Evaluating Model Accuracies\"):  # Add progress bar for accuracy evaluation\n",
    "#     # Load the pruned model\n",
    "#     pruned_model = pruned_params_dict[P]\n",
    "    \n",
    "#     # Evaluate the model on the test data\n",
    "#     accuracy = evaluate_model(pruned_model, test_loaders)\n",
    "#     accuracies[P] = accuracy\n",
    "    \n",
    "#     print(f\"Accuracy for P={P}: {accuracy:.2f}%\")\n",
    "\n",
    "# # Function to evaluate model accuracy\n",
    "# def evaluate_model(model, test_loaders):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loaders:\n",
    "#             # Unpack the data correctly\n",
    "#             if isinstance(data, (list, tuple)):\n",
    "#                 images, labels = data\n",
    "#             else:\n",
    "#                 # If data is not a tuple, assume it's a batch of images and labels\n",
    "#                 images, labels = data['image'], data['label']\n",
    "            \n",
    "#             images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     return 100 * correct / total\n",
    "\n",
    "# # Plot the accuracy of different models in a bar chart\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')\n",
    "# plt.xlabel('Pruning Level (P)')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.title('Model Accuracy for Different Pruning Levels')\n",
    "# plt.xticks(range(10, 101, 10))\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6072062,
     "sourceId": 9887519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
